{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to The Data Science Class","text":""},{"location":"#introduction","title":"Introduction","text":"<p>In this class, we will explore the fundamental concepts and techniques used in the field of data science, including statistical analysis, machine learning, data visualization, and more. You will learn how to extract insights and make predictions from large and complex datasets using a variety of tools and techniques. Whether you are new to the field or have some experience, this class will provide you with the skills and knowledge you need to succeed as a data scientist. </p>"},{"location":"#what-is-data-science","title":"What is Data Science","text":"<p>Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data. It involves the use of various techniques and tools such as machine learning, statistical analysis, and visualization to extract useful information and insights from data. This information can then be used to make decisions, predictions, or to inform research.</p> <p></p> <p>Data science is used in a wide range of fields such as finance, healthcare, retail, marketing, transportation, and many more. It has become increasingly important as the amount of data generated by modern technology continues to grow.</p> <p></p> <p></p>"},{"location":"#planning-of-the-course","title":"Planning of the course","text":"<ul> <li> <p>Python Programming : Python's simplicity, readability, and the availability of powerful libraries and modules make it a great choice for data science tasks, from data manipulation and analysis to building and deploying machine learning models.</p> </li> <li> <p>Data Base Management System : In data science, it is often necessary to work with large amounts of data that are stored in databases. Database management systems (DBMS) provide a way to organize, store, and retrieve data in an efficient and organized way.</p> </li> <li> <p>R Programming : R is particularly useful for data analysis in fields such as genomics, finance, and social sciences.</p> </li> <li> <p>Exploratory Data Analysis : Is an essential step in the data science process. It is the process of analyzing and summarizing the main characteristics of a data set, and is used to uncover patterns, trends, and relationships within the data. EDA helps data scientists to understand the data they are working with, identify any potential issues or biases, and select the appropriate statistical techniques to use for further analysis. It also helps to create a solid foundation for building models and making predictions. </p> </li> <li> <p>Machine Learning :  It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Machine learning focuses on the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions without being explicitly programmed to perform the task</p> </li> <li> <p>Deep Learning : Deep learning is a subfield of machine learning that is inspired by the structure and function of the brain, specifically the neural networks. It involves training large artificial neural networks to perform tasks such as image and speech recognition, natural language processing, and decision making. These neural networks are trained using large amounts of data and are able to learn and improve over time. Deep learning has achieved state-of-the-art results in many areas and has revolutionized the field of artificial intelligence. It is widely used in applications such as computer vision, natural language processing, and self-driving cars.</p> </li> <li> <p>AI models Deployement : AI models deployments refer to the process of taking a trained AI model and making it available for use in a production environment. This can include things like scaling the model to handle large amounts of data, integrating the model with other systems and software, and monitoring the performance of the model in a live setting.</p> </li> <li> <p>Data Visualization using Tableau/Power Bi : Data visualization is the process of creating graphical representations of data in order to effectively communicate insights and findings. Tableau and Power BI are both popular tools used for data visualization. They offer a wide range of interactive visualizations, including maps, charts, and dashboards</p> </li> <li> <p>Capstone Project : The project is designed to apply the knowledge and skills that students have learned throughout the program. It is typically a hands-on, real-world project that requires students to use data science techniques and tools to solve a problem or answer a research question. The project can be based on any topic that is relevant to data science and can include tasks such as data collection, cleaning, exploration, analysis, modeling, and visualization.</p> </li> </ul> <p></p> <p>Let's get started!</p>"},{"location":"basic/","title":"Basic Python Concepts","text":""},{"location":"basic/#basic-python-concepts","title":"Basic Python Concepts","text":""},{"location":"basic/#variables","title":"Variables","text":"<p>Variables are used to store values in Python. They are like containers that hold data, and you can use them to perform operations on that data. Variables are declared using the assignment operator (=) and can be of different types, such as integers, floating-point numbers, strings, and more.</p> <pre><code># Example of variable assignment\nx = 5\ny = \"Hello World\"\nz = [1, 2, 3]\n</code></pre>"},{"location":"basic/#data-types-and-structures","title":"Data types and structures","text":"<p>Python supports several built-in data types, such as integers, floating-point numbers, strings, lists, tuples, and dictionaries. Each data type has its own set of characteristics and methods.</p> <pre><code># Example of different data types\nx = 5 # integer\ny = 3.14 # floating-point number\nz = \"Hello World\" # string\na = [1, 2, 3] # list\nb = (4, 5, 6) # tuple\nc = {\"name\": \"John\", \"age\": 30} # dictionary\n</code></pre>"},{"location":"basic/#operators","title":"Operators","text":"<p>Python supports various types of operators, such as arithmetic operators (+, -, x , /, %), comparison operators (&gt;, &lt;, &gt;=, &lt;=, ==, !=), and logical operators (and, or, not). These operators are used to perform different types of operations on variables and data.</p> <pre><code># Example of operators\nx = 5\ny = 2\n\n# arithmetic operators\nprint(x + y) # 7\nprint(x - y) # 3\nprint(x * y) # 10\nprint(x / y) # 2.5\nprint(x % y) # 1\n\n# comparison operators\nprint(x == y) # False\nprint(x &gt; 2) # True\n\n# logical operators \nprint(x == y and x &gt; 2) # False\nprint(x == y or x &gt; 2) # True\n</code></pre>"},{"location":"basic/#control-flow","title":"Control flow","text":"<p>Control flow or Conditional Statements allows us to control the flow of execution of our program based on certain conditions. For example : </p> <ul> <li>if-elif-else statements </li> </ul> <pre><code>x = 5\nif x &gt; 0:\n    print(\"x is positive\")\nelif x &lt; 0:\n    print(\"x is negative\")\nelse:\n    print(\"x is zero\")\n</code></pre> <ul> <li>for loop</li> </ul> <pre><code>for i in range(5):\n    print(i)\n</code></pre> <ul> <li>while loop  </li> </ul> <pre><code>x = 5\nwhile x &gt; 0:\n    print(x)\n    x -= 1\n</code></pre>"},{"location":"basic/#functions","title":"Functions","text":"<p>Functions are a way to group together a set of instructions to perform a specific task. Functions are defined using the def keyword and can take input arguments and return output values.</p> <pre><code>def add(x, y):\n    return x + y\n\nresult = add(5, 2)\nprint(result) # 7\n</code></pre>"},{"location":"basic/#modules-and-libraries","title":"Modules and Libraries","text":"<p>Python has a large number of built-in modules and libraries that provide a wide range of functionality. You can use these modules to perform various tasks, such as working with the file system, performing mathematical calculations, and more.</p> <pre><code># Example of importing a module\nimport math\n\nresult = math.sqrt(16)\nprint(result) # 4.0\n\n# Example of importing a specific function from a module\nfrom math import sqrt\n\nresult = sqrt(16)\nprint(result) # 4.0\n</code></pre>"},{"location":"basic/#exception-handling","title":"Exception Handling","text":"<p>Python supports exception handling, which allows you to handle errors and exceptions that may occur while running your program. This helps you to write robust code that can handle unexpected situations</p> <pre><code>while True:\n    try:\n        x = int(input(\"Please enter a number: \"))\n        y = int(input(\"Please enter another number: \"))\n        print(\"The result of x/y is:\", x/y)\n        break\n    except ValueError:\n        print(\"Oops! One of the inputs was not a valid number. Try again...\")\n    except ZeroDivisionError:\n        print(\"Oops! You cannot divide by zero. Try again...\")\n</code></pre> <p>In this example, program will handle two types of exception: ValueError and ZeroDivisionError, as the user input may not be valid number and also user may try to divide by zero.</p> <p></p> <p>Now, let's code ! </p>"},{"location":"basic/#things-to-remember","title":"Things to Remember","text":"<ul> <li> <p>Case Sensitivity: Python is a case-sensitive language, so be mindful of the case when naming variables, functions, and classes. This means, Variable and variable are not the same.</p> </li> <li> <p>Each variable, function and class should have a unique name within your code</p> </li> <li> <p>The only variables you need to consider inside your function are the arguments of that function</p> </li> <li> <p>Always give the identifiers a name that makes sense. While c = 10 is a valid name, writing count = 10 would make more sense, and it would be easier to figure out what it represents when you look at your code after a long gap.</p> </li> <li> <p>Multiple words can be separated using an underscore, like this_is_a_long_variable.</p> </li> <li> <p>Comments: Use the pound symbol (#) to denote comments in your code, which will be ignored by the interpreter. In computer programming, comments are hints that we use to make our code more understandable. </p> </li> <li> <p>Quotation Marks: In Python, you can use either single quotes or double quotes to denote strings, but be consistent within your code.</p> </li> <li> <p>Colon (:): Colons are used to denote the start of a new block of code, such as in a for loop, if statement, or function definition.</p> </li> <li> <p>White Space: Be mindful of white space, as it can affect the way your code is interpreted. For example, leading white space is used to denote blocks of code.</p> </li> <li> <p>Parentheses: Parentheses are used to group expressions, to call functions, and to define tuples.</p> </li> <li> <p>Import Statement: Use the import statement to import libraries and modules into your code.</p> </li> <li> <p>print() function: Use the print() function to output text to the console.</p> </li> </ul>"},{"location":"env/","title":"Setting up a Development Environment","text":""},{"location":"env/#setting-up-a-development-environment","title":"Setting up a Development Environment","text":""},{"location":"env/#introduction","title":"Introduction","text":"<p>In this chapter, you will learn how to set up a Python development environment on your computer. A development environment is a software application that provides the necessary tools and resources for writing, testing, and debugging code. By the end of this chapter, you will have a working Python environment that you can use to start writing your own programs.</p>"},{"location":"env/#installing-python","title":"Installing Python","text":"<p>There are several ways to install Python 3, here are some of the most common methods:</p>"},{"location":"env/#using-anaconda","title":"Using Anaconda","text":"<p>Anaconda is a popular distribution of Python and R for data science and machine learning. It comes with a lot of packages and libraries pre-installed, and it also includes the conda package manager, which makes it easy to install additional packages and manage environments. To install Python using Anaconda, you can follow these steps:</p> <ul> <li>Go to the Anaconda Website and download the latest version of Anaconda for your operating system.</li> <li>Once the download is complete, run the installer and follow the prompts to install Anaconda.</li> <li>Once installation is complete, open Anaconda Navigator, which is a graphical user interface that allows you to manage your environments and packages.</li> <li>Create a new environment with Python 3 by clicking the \"Create\" button and selecting \"Python 3\" as the version.</li> </ul>"},{"location":"env/#using-pip","title":"Using pip","text":"<p>pip is the package installer for Python. It allows you to install and manage packages for your Python installation. To install Python 3 and Jupyter Notebook using pip, you can follow these two steps:</p> <ul> <li> <p>Make sure that Python 3 is installed on your system by running the command <code>python3 --version</code> in a terminal or command prompt.</p> </li> <li> <p>If Python 3 is not installed, download the latest version from The Official Python Website.</p> </li> </ul>"},{"location":"env/#using-homebrew-macos-and-linux","title":"Using Homebrew (macOS and Linux)","text":"<p>Homebrew is a package manager for macOS and Linux. It allows you to install and manage packages for your operating system. To install Python 3 using Homebrew, you can follow these steps:</p> <ul> <li>Make sure that Homebrew is installed on your system by running the command <code>brew --version</code> in a terminal.</li> <li>If Homebrew is not installed, you can install it by following the instructions on The Homebrew Website.</li> <li>Once you have Homebrew installed, you can use it to install Python 3 by running the command <code>brew install python3</code> in a terminal.</li> </ul>"},{"location":"env/#using-chocolatey-windows","title":"Using Chocolatey (Windows)","text":"<p>Chocolatey is a package manager for Windows. It allows you to install and manage packages for your operating system. To install Python 3 using Chocolatey, you can follow these steps:</p> <ul> <li>Make sure that Chocolatey is installed on your system by running the command <code>choco --version</code> in a command prompt.</li> <li> <p>If Chocolatey is not installed, you can install it by following the instructions on The Chocolatey Website.</p> </li> <li> <p>Once you have Chocolatey installed, you can use it to install Python 3 by running the command <code>choco install python</code> in a command prompt.</p> </li> </ul> <p>PS : It's also worth noting that many operating systems and Linux distributions come with Python 2 pre-installed, and you may want to install Python 3 alongside it without replacing the pre-installed Python 2. In this case, you should be careful when running pip and python commands, since you may need to use pip3 and python3, respectively, to ensure that you're using the correct version of the software.</p>"},{"location":"env/#choosing-an-ide-or-text-editor","title":"Choosing an IDE or Text Editor","text":"<p>Once you have Python installed, the next step is to choose a text editor or integrated development environment (IDE) to write your code in. An IDE is a software application that provides a comprehensive environment for coding, including features such as syntax highlighting, code completion, and debugging tools. In this class we're using Jupyter. Jupyter is an open-source web-based IDE that allows users to create and share documents that contain live code, equations, visualizations, and narrative text. It is particularly well-suited for data science because it:</p> <ul> <li> <p>Provides an easy way to interact with data: Jupyter allows you to load, visualize, and manipulate data in a variety of formats, such as CSV, JSON, and SQL. This makes it a great tool for data exploration and analysis.</p> </li> <li> <p>Supports multiple programming languages: Jupyter supports many programming languages, including Python, R, and Julia, which makes it easy to use the language that is best suited for your project.</p> </li> <li> <p>Enables reproducible research: Jupyter allows you to organize your code, data, and visualizations in a single document, which makes it easy to reproduce your results and share your work with others.</p> </li> <li> <p>Provides a collaborative environment: Jupyter allows multiple users to work on the same notebook at the same time, which makes it a great tool for collaborative data science projects.</p> </li> <li> <p>Has a large and active community: Jupyter has a large and active community of developers, users, and contributors who provide support, resources, and add-ons that extend its functionality.</p> </li> </ul> <p>To install Jupyter:</p> <ul> <li> <p>Using Anaconda: In your conda enviroment you can install Jupyter Notebook by running the command <code>conda install jupyter</code>. </p> </li> <li> <p>Using pip3: You can install Jupyter using the pip package manager by running the command <code>pip3 install jupyter</code> in your command line. This method requires that you have Python3 and pip3 already installed on your system.</p> </li> </ul> <p>You can then launch Jupyter Notebook by running the command jupyter notebook in a terminal or command prompt.</p> <p></p> <p></p> <p></p> <p>Some popular IDEs for Python include PyCharm, Spyder, and IDLE. Text editors, such as Sublime Text, Atom, or Notepad++, are also popular among Python developers and are preferred by some. I suggest you Install Sublime Text as a second IDE.</p>"},{"location":"env/#installing-additional-libraries-and-packages","title":"Installing Additional Libraries and Packages","text":"<p>Python has a vast collection of libraries and packages that can be used to perform a wide range of tasks. Some popular packages include NumPy and Pandas for data manipulation, Matplotlib and Seaborn for data visualization, and scikit-learn for machine learning. You can install these packages using the pip package manager, which is included with Python.</p> <p></p> <p>Examples : </p> <ul> <li><code>pip3 install numpy</code></li> <li><code>pip3 install pandas</code></li> </ul>"},{"location":"env/#conclusion","title":"Conclusion","text":"<p>By the end of this chapter, you should have a working Python development environment that you can use to start writing your own programs. You will have a Python interpreter, a text editor or IDE, and any additional libraries and packages that you need. In the next chapter, you will learn the basics of Python programming, including data types, variables, and operators.</p>"},{"location":"intro/","title":"Introduction to Python Programming","text":""},{"location":"intro/#introduction-to-python-programming","title":"Introduction to Python Programming","text":"<p>Python is a powerful, high-level programming language that is widely used for web development, data analysis, machine learning, and scientific computing. Its simple, easy-to-read syntax and versatile libraries make it a popular choice for beginners and experienced programmers alike. </p> <p></p> <p>In this course, you will learn the basics of Python programming, including data types, variables, operators, control flow, and functions. You will also explore advanced topics such as data structures, working with data, data visualization, and machine learning. Along the way, you will gain hands-on experience through a variety of exercises and a final project.</p> <p></p> <p>By the end of this course, you will have a solid foundation in Python programming, and the skills to apply it to a wide range of data science and other applications.</p>"},{"location":"intro/#various-recources-for-you-to-practice","title":"Various Recources for you to practice","text":"<ul> <li> <p>Codecademy's Learn Python Track: This interactive course covers all the basics of Python and includes exercises to practice what you've learned.</p> </li> <li> <p>HackerRank's Python Domain: This website offers a wide range of Python coding challenges, from beginners to advanced levels.</p> </li> <li> <p>Python.org's Beginner's Guide: This guide provides a gentle introduction to Python, including tutorials and exercises for beginners.</p> </li> <li> <p>Google's Python Class: This free class, taught by Google engineer Nick Parlante, includes video lectures, slides, and exercises.</p> </li> <li> <p>Full Stack Python : Is a website that provides resources and tutorials on various aspects of the Python programming language, with a focus on web development and data science. Additionally, the website provides a curated list of resources for further learning and a podcast discussing all things Python.</p> </li> <li> <p>Code Signal : Is a website and platform that provides a variety of tools and resources for developers, including a code editor, a test runner, and a code execution environment. It also provides a variety of challenges and assessments to help developers improve their coding skills. </p> </li> </ul>"},{"location":"io/","title":"File Input/Output (I/O) Operations","text":""},{"location":"io/#introduction","title":"Introduction","text":"<p>File Input/Output (I/O) operations in Python allow you to read from and write to files on your local file system. The open function is the main function used for working with files in Python, and it returns a file object that can be used to perform various operations on the file.</p>"},{"location":"io/#opening-a-file","title":"Opening a File","text":"<p>The basic syntax for opening a file in Python is as follows:</p> <pre><code>file = open(\"filename.extension\", \"mode\")\n</code></pre> <p>The first argument is the name of the file, and the second argument is the mode in which you want to open the file. The most common modes are \"r\" for reading, \"w\" for writing, and \"a\" for appending.</p> <p></p> <p>For example, to open a text file called example.txt in read mode, you would write the following code:</p> <pre><code>file = open(\"example.txt\", \"r\")\n</code></pre>"},{"location":"io/#reading-from-a-file","title":"Reading from a File","text":"<p>Once you have opened a file, you can read from it using various methods, such as read, readline, and readlines.</p> <p></p> <p>The read method reads the entire contents of a file as a single string. For example:</p> <pre><code>file = open(\"example.txt\", \"r\")\ncontents = file.read()\nprint(contents)\nfile.close()\n</code></pre> <p>The readline method reads a single line of a file. For example:</p> <pre><code>file = open(\"example.txt\", \"r\")\nfirst_line = file.readline()\nprint(first_line)\nfile.close()\n</code></pre> <p>The readlines method reads all lines of a file as a list of strings, where each string is a single line. For example:</p> <pre><code>file = open(\"example.txt\", \"r\")\nlines = file.readlines()\nprint(lines)\nfile.close()\n</code></pre>"},{"location":"io/#writing-to-a-file","title":"Writing to a File","text":"<p>To write to a file, you can use the write method. The basic syntax for writing to a file is as follows:</p> <pre><code>file = open(\"filename.extension\", \"mode\")\nfile.write(\"data to be written\")\nfile.close()\n</code></pre> <p>For example, to write the string \"Hello, World!\" to a file called example.txt, you would write the following code:</p> <pre><code>file = open(\"example.txt\", \"w\")\nfile.write(\"Hello, World!\")\nfile.close()\n</code></pre> <p>If the file specified in the open function does not exist, it will be created. If the file does exist, its contents will be overwritten by the new data.</p>"},{"location":"io/#appending-to-a-file","title":"Appending to a File","text":"<p>To append data to an existing file, you can open the file in append mode (\"a\") instead of write mode (\"w\"). The basic syntax for appending to a file is as follows:</p> <pre><code>file = open(\"filename.extension\", \"mode\")\nfile.write(\"data to be written\")\nfile.close()\n</code></pre> <p>For example, to append the string \"Hello, World!\" to a file called example.txt, you would write the following code:</p> <pre><code>file = open(\"example.txt\", \"a\")\nfile.write(\"Hello, World!\")\nfile.close()\n</code></pre>"},{"location":"io/#context-manager","title":"Context Manager","text":"<p>One important thing to note when working with files in Python is that you should always close the file when you are done with it. This can be done using the close method, as demonstrated in the previous examples. However, there is a better way to ensure that the file is always closed, even if an error occurs, and that is by using a context manager.</p> <p></p> <p>A context manager is an object that provides a convenient way to manage resources, such as files, that need to be cleaned up after they are used. In Python, the with statement is used to create a context manager. The basic syntax for using a context manager to open a file is as follows:</p> <pre><code>with open(\"filename.extension\", \"mode\") as file:\n    # Perform file I/O operations\n</code></pre> <p>For example, to read the contents of a file called example.txt using a context manager, you would write the following code:</p> <pre><code>with open(\"example.txt\", \"r\") as file:\n    contents = file.read()\n    print(contents)\n</code></pre> <p>With this approach, the file is automatically closed when the with block is exited, even if an error occurs.</p>"},{"location":"io/#csv-library","title":"CSV Library","text":""},{"location":"io/#reading-data-from-a-csv-file","title":"Reading data from a CSV file","text":"<p>To read data from a CSV file, you can use the csv.reader function. This function returns an iterator that you can loop over to access the rows of the CSV file. Here is an example:</p> <pre><code>import csv\n\nwith open('my_file.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n\n    # Loop over each row in the CSV file\n    for row in csv_reader:\n        # Access the values of each row\n        print(row)\n</code></pre> <p>This code opens the my_file.csv file in read mode and creates a csv.reader object using the csv.reader function. Then, it loops over each row in the CSV file and prints out the values of each row.</p>"},{"location":"io/#writing-data-to-a-csv-file","title":"Writing data to a CSV file","text":"<p>To write data to a CSV file, you can use the csv.writer function. This function takes a file object and returns a writer object that you can use to write rows to the CSV file. Here is an example:</p> <pre><code>import csv\n\nwith open('my_file.csv', 'w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n\n    # Write rows to the CSV file\n    csv_writer.writerow(['Title', 'Author', 'Publisher'])\n    csv_writer.writerow(['To Kill a Mockingbird', 'Harper Lee', 'Grand Central Publishing'])\n</code></pre> <p>This code opens the my_file.csv file in write mode and creates a csv.writer object using the csv.writer function. Then, it writes two rows to the CSV file.</p>"},{"location":"io/#appending-data-to-a-csv-file","title":"Appending data to a CSV file","text":"<p>To append data to a CSV file, you can use the csv.writer function with the a mode. This mode will open the file in append mode, which allows you to add new rows to the end of the file. Here is an example:</p> <pre><code>import csv\n\nwith open('my_file.csv', 'a', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n\n    # Append rows to the CSV file\n    csv_writer.writerow(['1984', 'George Orwell', 'Signet Classic'])\n</code></pre> <p>This code opens the my_file.csv file in append mode and creates a csv.writer object using the csv.writer function. Then, it appends a new row to the end of the CSV file.</p>"},{"location":"io/#removing-data-from-a-csv-file","title":"Removing data from a CSV file","text":"<p>To remove data from a CSV file, you will need to read in the entire file, filter out the rows that you don't want, and then write the filtered rows back to the CSV file. Here is an example:</p> <p><pre><code>import csv\n\n# Read in the CSV file and filter out the rows that match a specific criteria\nwith open('my_file.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n\n    filtered_rows = []\n    for row in csv_reader:\n        if row[1] != 'Harper Lee':\n            filtered_rows.append(row)\n\n# Write the filtered rows back to the CSV file\nwith open('my_file.csv', 'w', newline='') as csv_file:\n    csv_writer = csv.writer(csv_file)\n\n    for row in filtered_rows:\n        csv_writer.writerow(row)\n</code></pre> This code reads in the my_file.csv file and filters out the rows where the author is \"Harper Lee\". Then, it opens the same file in write mode and writes the filtered rows back to the CSV file.</p>"},{"location":"numpy/","title":"NumPy","text":"<p>NumPy is short for Numerical Python. It is a Python library/package used for working with arrays which contains classes, functions, variables , a large library of mathematical functions etc for working with scientific calculation. It can be used to create an \u201cn\u201d dimensional array where \u201cn\u201d is any integer.              </p>"},{"location":"numpy/#why-numpy","title":"Why NumPy","text":"<p>In Python we have lists that serve the purpose of arrays, but they are slow. NumPy aims to provide an array object that is up to 50x faster than a traditional Python list.</p> <p></p> <p>The array object in NumPy is called ndarray, it provides a lot of supporting functions that make working with ndarray very easy. Arrays are very frequently used in data science, where speed and resources are very important.     </p> <p></p> <p>What makes NumPy arrays faster than lists: NumPy arrays are stored at one continuous place in memory unlike lists, so processes can access and manipulate them very efficiently. This behavior is called locality of reference. This is the main reason why NumPy is faster than lists. It is also optimized to work with the latest CPU architectures.</p>"},{"location":"numpy/#installing-numpy","title":"Installing NumPy","text":"<p>To install NumPy, you can use pip, the Python package installer. Open your terminal or command prompt and enter the following command:</p> <pre><code>pip3 install numpy\n</code></pre>"},{"location":"numpy/#importing-numpy","title":"Importing NumPy","text":"<p>There are two ways to import NumPy. Code Example : </p> <p><pre><code># this will import the entire NumPy module.\nimport numpy as np\n# this will import all class, objects, variables etc from the NumPy package   \nfrom numpy import*  \n</code></pre> NumPy is usually imported under the np alias. </p> <p></p> <p>alias: In Python aliases are an alternate name for referring to the same thing. </p> <p></p>"},{"location":"numpy/#creating-numpy-arrays","title":"Creating NumPy Arrays","text":"<p>The array object in NumPy is called ndarray. We can create a NumPy ndarray object by using the array() function. NumPy arrays can be created in a number of ways. Here are some of the most common methods:</p> <ul> <li>Using the numpy.array() function to create an array from a list/tuple:</li> </ul> <p><pre><code>a = np.array([1, 2, 3])\n</code></pre> - Using the numpy.zeros() function to create an array filled with zeros:</p> <p><pre><code>b = np.zeros((2, 3))\n</code></pre> - Using the numpy.ones() function to create an array filled with ones:</p> <pre><code>c = np.ones((2, 3))\n</code></pre> <ul> <li>Using the numpy.random.randint(): Returns an array of random integers between the two given numbers <pre><code>d = np.random.randint(0, 10)\n</code></pre></li> <li>Using the numpy.random.rand() function to create an array of random values:</li> </ul> <pre><code>e = np.random.rand(2, 3)\n</code></pre>"},{"location":"numpy/#numpy-array-dimensions","title":"NumPy Array Dimensions","text":"<p>A dimension in arrays is one level of array depth (nested arrays). nested array: are arrays that have arrays as their elements. 0-D Arrays 1-D Arrays 2-D Arrays 3-D Arrays.</p> <p></p> <p>0-D arrays, or Scalars, are the elements in an array. Each value in an array is a 0-D array. </p> <p></p> <p>Code Example:</p> <pre><code>arr=np.array(30) \nprint (arr)\n</code></pre> <p>An array that has 0-D arrays as its elements is called a uni-dimensional or 1-D array. These are the most common types of arrays. </p> <p></p> <p>Code Example :</p> <pre><code> arr=np.array([30,35,38,40,46,52])\n print (arr)\n</code></pre> <p>An array that has 1-D arrays as its elements is called a 2-D array. These are often used to represent matrix or 2nd order tensors. </p> <p></p> <p>Code Example :</p> <pre><code>arr=np.array([[30,35,38,40,46,52],[22,28,39,42,49,52]])\n print (arr)\n</code></pre> <p>An array that has 2-D arrays (matrices) as its elements is called 3-D array. These are often used to represent a 3rd order tensor. </p> <p></p> <p>Code Example : </p> <pre><code>arr=np.array([[[30,35,38,40,46,52],[22,28,39,42,49,52], [71,24,88,64,31,94]]])\nprint (arr)\n</code></pre> <p>NumPy Arrays provides the ndim attribute that returns an integer that tells us how many dimensions the array has. </p> <p></p> <p>Code Example :</p> <p><pre><code>arr=np.array([[[30,35,38,40,46,52],[22,28,39,42,49,52], [71,24,88,64,31,94]]])\nprint (arr.ndim)\n</code></pre> An array can have any number of dimensions. When the array is created, you can define the number of dimensions by using the ndim argument. </p> <p></p> <p>Code Example :  <pre><code>arr=np.array([1,2,3,4],ndmin=6)\nprint (arr.ndim)\nprint (\u201cNumber of dimensions:\u201d, arr.ndim)\n</code></pre></p>"},{"location":"numpy/#arrays-type-and-shape","title":"Arrays type and shape","text":"<p>NumPy Array Data Type :The NumPy array object has a property called dtype that returns the data type of the array.</p> <p></p> <p>Code Example : <pre><code>arr=np.array([1,2,3,4,5]) \nprint (arr.dtype)\n</code></pre> NumPy Array Shape : The shape of an array is the number of elements in each dimension. NumPy arrays have an attribute called shape that returns a tuple with each index having the number of corresponding elements</p> <p></p> <p>Code example : <pre><code>arr=np.array([1,2,3,4,5,6])\nprint (arr.shape)\n</code></pre></p>"},{"location":"numpy/#numpy-array-indexing","title":"NumPy Array Indexing","text":"<p>Array indexing is the same as accessing an array element. You can access an array element by referring to its index number. The indexes in NumPy arrays start with 0, meaning that the first element has index 0, and the second has index 1 etc.</p> <p></p> <p>Code Example :  <pre><code>arr=np.array([1,2,3,4])\nprint (arr[0])\n</code></pre> To access elements from 2-D arrays we can use comma separated integers representing the dimension and the index of the element.</p> <p></p> <p>Code Example :</p> <p><pre><code>arr=np.array([[1,2,3,4],[4,3,2,1]])\nprint (arr[0][1])\n</code></pre> To access elements from 3-D arrays we can use comma separated integers representing the dimensions and the index of the element. </p> <p></p> <p>Code Example : </p> <p><pre><code>arr=np.array([1,2,3,4],[4,3,2,1],[8,6,7,9])\nprint (arr[0][1][0])\n</code></pre> Use negative indexing to access an array from the end Code Example</p> <pre><code>arr=np.array([1,2,3,4],[4,3,2,1],[8,6,7,9])\nprint (arr[0][-1][-2])\n</code></pre>"},{"location":"numpy/#numpy-array-slicing","title":"NumPy Array Slicing","text":"<p>Slicing in python means taking elements from one given index to another given index. We pass slice instead of index like this [start: end]. We can also define the step, like this [start:end:step].</p> <ul> <li>If we don't pass start its considered 0</li> <li>If we don't pass end its considered length of array in that dimension</li> <li>If we don't pass step its considered 1</li> </ul> <p>Note: The result includes the start index, but excludes the end index. Use the minus operator to refer to an index from the end.</p> <p></p> <p>Code Example :</p> <p><pre><code>arr=np.array([1,2,3,4,5])\nprint (arr[0:5]) #slice arrays from index 0 to 5 excluding 5 print (arr[:4]) #slice from beginning to 4 excluding 4\nprint (arr[2:]) #slice from index 2 onwards\nprint (arr[:-3]) #slice from index -3\n</code></pre> Code Example :</p> <pre><code>arr=np.array([1,2,3,4,5])\nprint (arr[:4:1]) #slice from beginning to 4 step of 1 print (arr[0::3]) #slice from index 0 onwards step of 3 print (arr[:-1:2]) #slice from index -1 step of 2\n</code></pre>"},{"location":"numpy/#array-operations-in-numpy","title":"Array Operations in NumPy","text":"<p>Element-wise Operations : NumPy allows you to perform element-wise operations on arrays. Here are some examples:</p> <pre><code>a = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\n# Element-wise addition\nc = a + b\nprint(c)  # Output: [5 7 9]\n\n# Element-wise multiplication\nd = a * b\nprint(d)  # Output: [ 4 10 18]\n</code></pre> <p>Matrix Multiplication : NumPy allows you to perform matrix multiplication using the numpy.dot() function. Here is an example: <pre><code>a = np.array([[1, 2], [3, 4]])\nb = np.array([[5, 6], [7, 8]])\n\n# Matrix multiplication\nc = np.dot(a, b)\nprint(c)\n</code></pre></p> <p>NumPy Array Reshaping : Reshaping means changing the shape of an array. The shape of an array is the number of elements in each dimension. By reshaping we can add or remove dimensions or change number of elements in each dimension.</p> <p></p> <p>Code Example : <pre><code># we can do it this way\narr=np.array([1,2,3,4,5,6,7,8,9,10])\narr2= arr.reshape(5,2)\nprint (arr)\nprint (arr2)\n# or this way\na = np.array([1, 2, 3, 4, 5, 6])\nb = np.reshape(a, (2, 3))\nprint (a)\nprint (b)\n</code></pre></p> <p>Transposing Arrays : NumPy provides a way to transpose arrays using the numpy.transpose() function. Here is an example:</p> <p><pre><code>a = np.array([[1, 2], [3, 4], [5, 6]])\nb = np.transpose(a)\nprint(b)\n</code></pre> Aggregation Functions : NumPy provides several aggregation functions that can be used to compute statistics on arrays. Here are some examples: <pre><code>a = np.array([1, 2, 3, 4, 5])\n\n# Computing the sum of the elements in the array\nprint(np.sum(a))  # Output: 15\n\n# Computing the mean of the elements in the array\nprint(np.mean(a))  # Output: 3.0\n\n# Computing the standard deviation of the elements in the array\nprint(np.std(a))  # Output: 1.41421356\n</code></pre></p>"},{"location":"numpy/#numpy-array-copy-and-view","title":"NumPy Array Copy and View","text":"<p>The main difference between a copy and a view of an array is that the copy is a new array, and the view is just a view, or link to, the original array.</p> <p></p> <p>The copy owns the data and any changes made to the copy will not affect original array, and any changes made to the original array will not affect the copy.</p> <p></p> <p>The view does not own the data and any changes made to the view will affect the original array, and any changes made to the original array will affect the view.</p> <p></p> <p>As mentioned, copies owns the data, and views does not own the data, so how can we check if it owns the data or not?</p> <p></p> <p>Every NumPy array has the attribute base that returns None if the array owns the data. Otherwise, the base attribute refers to the original object</p> <p></p> <p>Code example : <pre><code>import numpy as np\narr=np.array([1,2,3,4,5,6])\narrview=arr.view() #creates a view of the array arrcopy=arr.copy() #creates a copy of the array\nprint (arrview.base) #check if the array owns its data print (arrcopy.base) #check if the array owns its data (should output none)\n</code></pre></p> <p>Documentations NumPy</p>"},{"location":"oop/","title":"Object Oriented Programming in Python","text":""},{"location":"oop/#introduction","title":"Introduction","text":"<p>In the last chapter we learnt the basics of programming, you were shown how to store data in data structures such as lists, strings, integers, dictionaries, and others. And you were shown how to create behavior for your program using keywords, and later using functions to group these keywords. This coding approache is called Logic Programming.</p> <p></p> <p>However, there are different approaches or perspectives in computer programming which we call programming paradigms. They provide various ways of organizing and structuring code to solve a particular problem.</p> <p></p> <p>Each paradigm has its own strengths, weaknesses, and suitability for different types of problems and use cases. Some programming languages may support multiple paradigms, while others may have limited support for one specific paradigm.</p> <p></p> <p>In this course we will get to know the object-oriented programming (OOP), a programming paradigm widely used in Python.</p> <p></p> <p>PS: At this stage of the course, we assume that you know the basics of Python.</p>"},{"location":"oop/#object-oriented-programming-oop","title":"Object-oriented programming (OOP)","text":""},{"location":"oop/#what-is-it","title":"What is it ?","text":"<p>Object-oriented programming (OOP) is an approach that organizes software design based on objects, which are data fields with unique attributes and behaviors, instead of functions and logic. </p>"},{"location":"oop/#why-we-use-it","title":"Why we use it ?","text":"<p>One of the main benefits of OOP is its organization, which makes it easier for developers to collaborate on a project by dividing it into smaller groups. Additionally, OOP offers several other advantages, such as code reusability, scalability, and efficiency.</p>"},{"location":"oop/#oop-basic-concepts","title":"OOP Basic Concepts","text":"<ul> <li> <p>Class: A class is a blueprint for creating objects. It defines a set of attributes (properties) and methods (functions) that the objects created from the class will have. For example, you could create a \"Person\" class with attributes like name, age, and address, and methods like \"introduce\" and \"greet\".</p> </li> <li> <p>Object: An object is an instance of a class. When you create an object from a class, you get a specific \"realization\" of the class, with its own set of attributes and methods. For example, you could create two \"Person\" objects, \"John\" and \"Jane\", each with their own name, age, and address.</p> </li> <li> <p>Attributes: Attributes are the properties or characteristics of an object. They define the state of the object. In the example of the \"Person\" class, the attributes would be name, age, and address.</p> </li> <li> <p>Methods: Methods are the actions or behaviors of an object. They define what the object can do. In the example of the \"Person\" class, the methods would be \"introduce\" and \"greet\".</p> </li> </ul> <p>Here is a simple example of a Python class that defines a \"Person\" object:</p> <p><pre><code>class Person:\n    def __init__(self, name, age, address):\n        self.name = name\n        self.age = age\n        self.address = address\n\n    def introduce(self):\n        return f\"Hi, my name is {self.name} and I am {self.age} years old.\"\n\n    def greet(self, other_person):\n        return f\"Hello {other_person.name}, it's nice to meet you!\"\n</code></pre> And here is how you can create objects from the \"Person\" class and use their attributes and methods:</p> <pre><code>john = Person(\"John\", 30, \"123 Main St.\")\njane = Person(\"Jane\", 25, \"456 Elm St.\")\n\nprint(john.introduce())  # Output: Hi, my name is John and I am 30 years old.\nprint(jane.greet(john))  # Output: Hello John, it's nice to meet you!\n</code></pre>"},{"location":"oop/#when-to-use-it","title":"When to use it ?","text":"<ul> <li> <p>Modeling real-world objects: You can create classes to model real-world objects in Python, such as dogs, cars, or books. For example, you can create a \"Dog\" class with properties like breed, name, and age, and methods like \"bark\", \"eat\", and \"sleep\". This makes it easier to manipulate and work with instances of the class, and to keep track of the state of each object.</p> </li> <li> <p>Building games: OOP is often used in game development to model game objects and their behaviors. For example, you can create a \"Player\" class to represent a player in a game, with properties like position, health, and score, and methods like \"move\", \"attack\", and \"jump\".</p> </li> <li> <p>Database applications: You can use OOP to interact with databases in Python. For example, you can create a \"Record\" class to represent a record in a database table, with properties like id, name, and date, and methods like \"insert\", \"update\", and \"delete\".</p> </li> <li> <p>Web development: OOP is commonly used in web development to build applications and services. For example, you can create a \"User\" class to represent a user of your application, with properties like name, email, and password, and methods like \"register\", \"login\", and \"logout\".</p> </li> <li> <p>Scientific simulations: OOP can be used to create scientific simulations, such as physical simulations or financial models. For example, you can create a \"Particle\" class to represent a particle in a physical simulation, with properties like position, velocity, and mass, and methods like \"move\", \"collide\", and \"absorb\".</p> </li> </ul> <p>These are just a few examples of how OOP can be used in Python. With its powerful and flexible object-oriented features, OOP is a widely used paradigm in Python and can be applied to many different types of projects.</p>"},{"location":"oop/#some-examples","title":"Some examples","text":"<ul> <li>Car: Create a class Car that represents a car. The class should have properties brand, model, and year, and a method drive that makes the car drive (print \"Driving the car !\").</li> </ul> <pre><code>## Class implementation\nclass Car:\n    def __init__(self, brand, model, year):\n        self.brand = brand\n        self.model = model\n        self.year = year\n\n    def drive(self):\n        print(\"Driving the car !\")\n\n## Object declaration\ncar = Car(\"Toyota\", \"Camry\", 2020)\n\nprint(car.drive())\n# Output: Driving the car !\n</code></pre> <ul> <li>Dog: Create a class Dog that represents a dog. The class should have properties name, breed, and age, and a method bark that makes the dog bark (print \"Woof!\").</li> </ul> <pre><code>## Class implementation\nclass Dog:\n    def __init__(self, name, breed, age):\n        self.name = name\n        self.breed = breed\n        self.age = age\n\n    def bark(self):\n        print(\"Woof!\")\n\n## Object declaration\ndog = Dog(\"Max\", \"Labrador\", 5)\nprint(dog.bark())\n# Output: Woof!\n</code></pre> <p>Let's code !</p>"},{"location":"oop/#operator-overloading","title":"Operator overloading","text":"<p>Operator overloading allows objects of user-defined classes to behave like built-in data types. This means that you can use familiar syntax for objects of your classes, making your code more intuitive and easier to read.</p> <p></p> <p>For example, consider a class for a 2D point:</p> <p><pre><code>class Point2D:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __str__(self):\n        return f\"({self.x}, {self.y})\"\n</code></pre> This class defines a 2D point, with x and y coordinates. You can create instances of the class and display them:</p> <p><pre><code>p1 = Point2D(1, 2)\nprint(p1)  # Output: (1, 2)\n</code></pre> Now, if you want to add two points, you can overload the addition operator + by defining the __add__ method:</p> <p><pre><code>class Point2D:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __str__(self):\n        return f\"({self.x}, {self.y})\"\n\n    def __add__(self, other):\n        return Point2D(self.x + other.x, self.y + other.y)\n</code></pre> With this change, you can now add two points:</p> <pre><code>p1 = Point2D(1, 2)\np2 = Point2D(3, 4)\np3 = p1 + p2\nprint(p3)  # Output: (4, 6)\n</code></pre> <p>In this example, the __add__ method takes another Point2D object as its argument and returns a new Point2D object that represents the sum of the two points. This allows you to use the + operator with instances of your class, just like you would with built-in data types.</p> <p></p> <p>You can also overload other operators, such as -, *, /, &lt;, &gt;, and so on, by defining the corresponding special methods, such as __sub__, __mul__, __truediv__, __lt__, __gt__, and so on. </p> <p></p> <p>Here's an example that overloads the subtraction operator:</p> <p><pre><code>class Point2D:\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __str__(self):\n        return f\"({self.x}, {self.y})\"\n\n    def __add__(self, other):\n        return Point2D(self.x + other.x, self.y + other.y)\n\n    def __sub__(self, other):\n        return Point2D(self.x - other.x, self.y - other.y)\n</code></pre> With this change, you can now subtract two points:</p> <pre><code>p1 = Point2D(1, 2)\np2 = Point2D(3, 4)\np3 = p1 - p2\nprint(p3)  # Output: (-2, -2)\n</code></pre>"},{"location":"oop/#cheat-sheet-for-class-special-methods","title":"Cheat sheet for Class Special Methods:","text":"Operator Method String representation __str__ Addition (+) __add__ Subtraction (-) __sub__ Multiplication (*) __mul__ Power (**) __pow__ Division (/) __truediv__ Floor Division (//) __floordiv__ Remainder (modulo)(%) __mod__ Lesser than (&lt;) __lt__ Greater than (&gt;) __gt__ Lesser than or equal (&lt;=) __le__ Greater than or equal (&gt;=) __ge__ Equal (==) __eq__ Not equal (!=) __ne__ Absolute value (abs()) __abs__ Bitwise AND(&amp;) __and__ Bitwise OR (|) __or__ Bitwise NOT(~) __invert__"},{"location":"oop/#inheritance-in-object-oriented-programming","title":"Inheritance in Object-Oriented Programming","text":""},{"location":"oop/#what-is-it_1","title":"What is it ?","text":"<p>Inheritance is a mechanism in Object-Oriented Programming (OOP) that allows a new class to be defined based on an existing class. The new class, known as the subclass, inherits attributes and behavior from the existing class, known as the superclass. This enables code reuse, allowing new classes to be defined with little or no modifications to the existing classes.</p> <p>For example, consider a superclass called Animal which has attributes such as name, species, and age, and a method called make_sound() that returns the sound the animal makes. We can create a subclass of Animal called Dog which inherits all of the attributes and behavior of the Animal class. We can also add additional attributes specific to dogs such as breed and override the make_sound() method to return the specific sound a dog makes, like \"bark\".</p> <pre><code>class Animal:\n    def __init__(self, name, species, age):\n        self.name = name\n        self.species = species\n        self.age = age\n\n    def make_sound(self):\n        return \"Sound made by the animal\"\n\nclass Dog(Animal):\n    def __init__(self, name, breed, age):\n        Animal.__init__(self, name, \"Dog\", age)\n        self.breed = breed\n\n    def make_sound(self):\n        return \"Bark\"\n\ndog = Dog(\"Rufus\", \"Labrador\", 5)\nprint(dog.name) # Rufus\nprint(dog.species) # Dog\nprint(dog.age) # 5\nprint(dog.breed) # Labrador\nprint(dog.make_sound()) # Bark\n</code></pre> <p>In this example, the Dog class inherits the attributes name, species, and age from the Animal class and also adds an additional attribute breed. The method make_sound() is also overridden in the Dog class to return a specific sound for dogs.</p> <p>Inheritance provides a way to model relationships between classes, and is an important concept in OOP for code reuse and organization. In Python, inheritance is an is-a relationship. That is, we use inheritance only if there exists an is-a relationship between two classes. For example,</p> <ul> <li>Car is a Vehicle</li> <li>Student is a Person</li> <li>Cat is an Animal</li> </ul> <p>Here, Car can inherit from Vehicle, Apple can Student from Person, and so on.</p>"},{"location":"oop/#polymorphism-and-abstraction","title":"Polymorphism and Abstraction","text":"<ul> <li> <p>Polymorphism : Is the ability of an object to take on multiple forms. It allows objects of different classes to be treated as objects of the same class. This means that you can write a single function or method that can work with objects of different classes, as long as they implement the same interface.</p> </li> <li> <p>Abstraction : Is a technique that allows you to simplify complex systems by ignoring irrelevant details and focusing on the essential features of an object. It is achieved by defining an interface that exposes the essential features of an object, while hiding the implementation details.</p> </li> </ul> <p>Here's an example in Python to demonstrate the difference between polymorphism and abstraction:</p> <pre><code>from abc import ABC, abstractmethod\n\nclass Shape(ABC):\n    @abstractmethod\n    def area(self):\n        pass\n\nclass Rectangle(Shape):\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n\n    def area(self):\n        return self.width * self.height\n\nclass Circle(Shape):\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return 3.14 * self.radius * self.radius\n\ndef print_area(shape):\n    print(shape.area())\n\nrect = Rectangle(10, 20)\ncirc = Circle(5)\n\nprint_area(rect) # 200\nprint_area(circ) # 78.5\n</code></pre> <p>In this example, the Shape class serves as an abstract class and defines an abstract method area. The Rectangle and Circle classes inherit from Shape and provide their own implementation of the area method. </p> <p></p> <p>This demonstrates polymorphism, as objects of different classes (Rectangle and Circle) can be treated as objects of the same class (Shape). The print_area function demonstrates polymorphism, as it can accept objects of different classes (Rectangle and Circle) as long as they implement the same interface (area method).</p> <p></p> <p>At the same time, the Shape class demonstrates abstraction by defining an interface that exposes the essential features of a shape, while hiding the implementation details. The Rectangle and Circle classes implement the area method, but the details of the implementation are hidden from the user. The user only sees the essential features of the object (the area method).</p>"},{"location":"oop/#multiple-and-multilevel-inheritance","title":"Multiple and Multilevel Inheritance","text":"<ul> <li> <p>Multiple Inheritance: is a feature of Object Oriented Programming (OOP) languages where a class can inherit properties and attributes from more than one parent class. This means that a single class can have multiple base classes and it can inherit properties and attributes from all of them. </p> <p>For example, consider a scenario where you have two classes: Shape and Color. The class Shape defines the properties of a 2-D shape such as its area, perimeter, etc. The class Color defines the color of an object. Now, you want to create a new class Rectangle which is a shape and has a color. You can achieve this by using multiple inheritance. </p> </li> </ul> <p>Here's an example implementation in Python:</p> <pre><code>class Shape:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n\n    def area(self):\n        return self.width * self.height\n\n    def perimeter(self):\n        return 2 * (self.width + self.height)\n\nclass Color:\n    def __init__(self, color):\n        self.color = color\n\nclass Rectangle(Shape, Color):\n    pass\n\nrect = Rectangle(10, 20, 'red')\nprint(rect.area())\nprint(rect.perimeter())\nprint(rect.color)\n</code></pre> <p>In this example, the class Rectangle inherits from both Shape and Color classes. This means that it has all the attributes and methods defined in both the classes.</p> <p></p> <ul> <li> <p>Multilevel Inheritance : is a type of inheritance where a class inherits properties and attributes from its parent class, and the parent class inherits from its parent class, and so on.</p> <p>For example, consider a scenario where you have a class Animal which defines basic properties of an animal such as its name, age, and breed. Another class Mammal inherits from Animal class and adds new properties such as type of fur, etc. Finally, a new class Cat is created which inherits from Mammal class and adds new properties specific to cats such as the type of meow, etc. </p> </li> </ul> <p>Here's an example implementation in Python:</p> <pre><code>class Animal:\n    def __init__(self, name, age, breed):\n        self.name = name\n        self.age = age\n        self.breed = breed\n\nclass Mammal(Animal):\n    def __init__(self, name, age, breed, fur_type):\n        Animal.__init__(self, name, age, breed)\n        self.fur_type = fur_type\n\nclass Cat(Mammal):\n    def __init__(self, name, age, breed, fur_type, meow_type):\n        Mammal.__init__(self, name, age, breed, fur_type)\n        self.meow_type = meow_type\n\ncat = Cat('Tom', 3, 'Siamese', 'short hair', 'loud')\nprint(cat.name)\nprint(cat.age)\nprint(cat.breed)\nprint(cat.fur_type)\nprint(cat.meow_type)\n</code></pre> <p>In this example, the class Cat inherits from the class Mammal which in turn inherits from the class Animal. This creates a hierarchy of classes where each class inherits properties and attributes from its parent class.</p>"},{"location":"pd/","title":"Pandas: Understanding & working with Pandas","text":""},{"location":"pd/#pandas","title":"Pandas","text":"<p>Pandas is a Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data. The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008</p> <p></p> <p>Pandas allows us to :</p> <ul> <li>Analyze big data and make conclusions based on statistical theories.</li> <li>Clean messy data sets, and make them readable and relevant. Relevant data is very important in data science. </li> <li>Pandas gives you answers about the data Such as : Is there a correlation between two or more columns? What is the average value?Max value? Min value?</li> <li>Manage diffrent data sets merging them filtering them etc...</li> </ul> <p></p> <p>Pandas is also able to delete rows that are not relevant, or contain wrong values, like empty or NULL values. This is called cleaning the data.</p> <p></p> <p>There are two ways to import pandas : </p> <pre><code>import pandas #This will import the entire pandas module.\n\nfrom pandas import* # This will import all class, objects, variables etc. from pandas package\n</code></pre>"},{"location":"pd/#pandas-series","title":"Pandas Series","text":"<p>A Pandas Series is like a column in a table. It is a one-dimensional array holding data of any type</p> <pre><code>import pandas as pd\ndataset1=[1,2,3]\ndf1=pd.Series(dataset1)\nprint (df1)\n</code></pre>"},{"location":"pd/#pandas-labels","title":"Pandas Labels","text":"<p>If nothing else is specified, the values are labeled with their index number. The first value has index 0, etc. This label can be used to access a specified value. With the index argument, you can name your own labels. When using labels, you can access an item by using the label. Code example : </p> <pre><code>import pandas as pd\ndataset1=[1,2,3]\ndf1=pd.Series(dataset1, index=[\"a\",\"b\",\"c\"])\nprint (df1)                     \nprint (df1[\"a\"])\n</code></pre>"},{"location":"pd/#pandas-key-value-objects","title":"Pandas Key Value objects","text":"<p>We can also use key/value pair objects like dictionaries when creating a Series</p> <p></p> <p>Note: The keys of the dictionary become the labels</p> <p></p> <p>Code example : <pre><code>import pandas as pd\ndataset1={\"Vehicle number\":1, \"Wheels\":4, \"Doors\":4}\ndf1=pd.Series(dataset1)\nprint (df1)\n</code></pre></p>"},{"location":"pd/#pandas-data-frames","title":"Pandas Data Frames","text":"<p>Data sets in Pandas are usually multi-dimensional tables, called DataFrames. Series can be considered to be like a column in a table, whereas a DataFrame can be considered to be the table. </p> <p></p> <p>We can use the loc attribute to locate one or more rows. Just as with series, we can name indexes of data frames and locate them using the loc attribute</p> <p></p> <p>Code example :</p> <pre><code>import pandas as pd\ndataset1={\"Vehicle number\":[1,2,3], \"Wheels\":[4,2,4], \"Doors\":[4,0,5]}\ndf1=pd.DataFrame(dataset1, index=[\"Car\",\"Motorcycle\",\"Van\"])\nprint(df1)\nprint (df1.loc[\"Car\"])              \n</code></pre>"},{"location":"pd/#reading-csv-files-with-pandas","title":"Reading CSV Files with Pandas","text":"<p>A simple way to store big data sets is to use CSV (Comma Separated Value) files. CSV files contain plain text and are a well know format that can be read by almost all software including Pandas</p> <p></p> <p>If your data sets are stored in a file, Pandas can load them into a DataFrame. Code example :</p> <pre><code>import pandas as pd \ndataframe1=pd.read_csv(\u2018data.csv\u2019)\nprint(dataframe1.to_string())\n</code></pre>"},{"location":"pd/#getting-a-quick-overview-of-the-dataframes-content","title":"Getting a quick overview of the Dataframes content","text":"<ul> <li> <p>One of the most used method for getting a quick overview of the DataFrame, is the head() method. The head() method returns the headers and a specified number of rows, starting from the top. </p> </li> <li> <p>The tail() method returns the last rows of the DataFrame</p> </li> <li> <p>The DataFrame object has a method called info(), that gives you more information about the data set.</p> </li> </ul> <p>Code Example :</p> <pre><code>import pandas as pd \ndataframe1=pd.read_csv(\"data.csv\") \nprint (dataframe1.head())\nprint (dataframe1.tail()) \ndataframe1.info()\n</code></pre>"},{"location":"pd/#data-cleaning-with-pandas","title":"Data Cleaning With pandas","text":"<p>Data cleaning means fixing bad data in your data set Examples of bad data include : </p>"},{"location":"pd/#empty-cells","title":"Empty cells","text":"<p>Empty cells can potentially give you a wrong result when you analyze data. One way to deal with empty cells is to remove rows that contain empty cells. This usually works since data sets can be very large, and removing a few rows will not have a significant impact on the results.</p> <p></p> <p>To remove empty cells, we can use the dropna() method. By default, the dropna() method returns a new DataFrame, and will not change the original. If you want to change the original DataFrame, use the inplace = True argument. Code Example :</p> <p><pre><code>import pandas as pd                     \ndataframe1=pd.read_csv(\"data.csv\")\nprint (dataframe1)\ndataframe1.dropna(inplace=True)\nprint (dataframe1)\n</code></pre> Another way of dealing with empty cells is to insert a new value to replace the empty cell. This way you do not have to delete entire rows just because of some empty cells. The fillna() method allows us to replace empty cells with a value. To only replace empty values for one column, specify the column name for the DataFrame. Code Example :</p> <pre><code>import pandas as pd\ndataframe1=pd.read_csv(\"data.csv\")\ndataframe1.fillna(130, inplace=True)\ndataframe1[\"Calories\"].fillna(130, inplace=True)\nprint(dataframe1.to_string())\n</code></pre> <p>You can also fill in empty cells with the mean, median or mode of the column. Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column</p> <ul> <li>Mean : the mean is the average value (the sum of all values divided by number of values)</li> <li>Median : the median is the value in the middle, after you have sorted all values ascending</li> <li>Mode : the mode is the value that appears most frequently</li> </ul> <p>Code Example : </p> <pre><code>import pandas as pd\n\ndataframe1=pd.read_csv(\"data.csv\")\n\nmeancal=dataframe1[\"Calories\"].mean()\nmediancal=dataframe1[\"Calories\"].median()\nmodecal=dataframe1[\"Calories\"].mode()\n\nprint (\"The mean of calories is\" + str(meancal) + \" The median of calories is \" + str(mediancal) + \" The mode of calories is \" + str(modecal)) \n\nmeandf=dataframe1[\"Calories\"].fillna(meancal)\nmediandf=dataframe1[\"Calories\"].fillna(mediancal)\nmodedf=dataframe1[\"Calories\"].fillna(modecal)\n\nprint(meandf.to_string())\nprint(mediandf.to_string())\nprint(modedf.to_string())\n</code></pre>"},{"location":"pd/#data-in-wrong-format","title":"Data in wrong format","text":"<p>Cells with data of incorrect format can make it difficult, or even impossible, to analyze data.</p> <p></p> <p>To remedy this, you can either remove the rows, or convert all cells in the columns into the same format</p>"},{"location":"pd/#incorrect-data","title":"Incorrect Data","text":"<p>Incorrect data does not have to be empty cells or incorrect format, it can just be incorrect, like if someone entered 199 instead of 1.99. Sometimes you can spot incorrect data by looking at the data set because you have an expectation of what it should be.</p> <p></p> <p>If you take a look at our data set you can see that in row 7 the duration is 450, but for all the other rows the duration is between 30 and 60. It doesn't have to be incorrect, but taking in consideration that this is the data set of someone's workout sessions, we conclude this person did not work out for 450 minutes</p> <p></p> <p>One way to fix wrong values is to replace them with something else. For small data sets you might be able to replace the wrong data one by one, but not for large data sets. To replace wrong data for larger data sets you can create some rules and set some boundaries for legal values, and replace any values that are outside of the boundaries</p> <p></p> <p>Another way of handling incorrect data is to remove the rows that contains incorrect data. This way you do not have to find out what to replace them with, and there is a good chance you do not need them for analysis.</p> <p></p> <p>Code Example</p> <pre><code>import pandas as pd \n\ndataframe1=pd.read_csv(\"data.csv\")\ndataframe2=pd.read_csv(\"data.csv\")\n\nprint(dataframe1.to_string())\nprint(dataframe2.to_string())\n\nfor x in dataframe1.index: #replace all values in duration above 120 with 120 \n    if dataframe1.loc[x, \"Duration\"] &gt; 120:\n        dataframe1.loc[x,\"Duration\"] = 120\n\nfor y in dataframe2.index: #drop all values above 120\n    if dataframe2.loc[y, \"Duration\"] &gt;120:\n        dataframe2.drop(y, inplace = True)\n\nprint(dataframe1.to_string())\nprint(dataframe2.to_string())\n</code></pre>"},{"location":"pd/#wrong-data-duplicates","title":"Wrong data Duplicates","text":"<p>Duplicate rows are rows that have been entered more than once. By taking a look at our test data set, we can assume that row 11 and 12 are duplicates</p> <p></p> <p>To discover duplicates, we can use the duplicated() method The duplicated() method returns a Boolean values for each row To remove duplicates, use the drop_duplicates() method. Code Example :</p> <pre><code>import pandas as pd\ndataframe1=pd.read_csv(\"data.csv\")\n\nprint(dataframe1.duplicated()) #search for duplicates and output true when found \n\ndataframe1.drop_duplicates(inplace = True) #drop all duplicates\n\nprint(dataframe1.to_string()) #find and drop duplicates example\n</code></pre>"},{"location":"pd/#data-analysis-in-pandas","title":"Data Analysis in Pandas","text":""},{"location":"pd/#correlation-in-pandas","title":"Correlation in Pandas","text":"<p>The corr() method calculates the relationship between each column in your data set. The corr() method ignores \"not numeric\" columns. Code Example : </p> <p><pre><code>import pandas as pd\ndataframe1=pd.read_csv(\"data.csv\") \ndataframe1.corr()\n</code></pre> </p> <p>The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns. The number varies from -1 to 1 such as :</p> <ul> <li> <p>1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.</p> </li> <li> <p>0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.</p> </li> <li> <p>-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down</p> </li> <li> <p>0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will</p> </li> </ul> <p>What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation</p> <p></p> <p>Perfect Correlation: We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself.</p> <p>Good Correlation: \"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out</p> <p>Bad Correlation: \"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa</p>"},{"location":"plt/","title":"Plt","text":"<p>plt</p>"},{"location":"sns/","title":"Sns","text":"<p>sns</p>"},{"location":"docker/docker_best_practice/","title":"Best Practices","text":""},{"location":"docker/docker_best_practice/#best-practices-for-design-and-optimize-containers","title":"Best Practices for design and optimize containers","text":""},{"location":"docker/docker_best_practice/#use-an-appropriate-base-image","title":"Use an appropriate base image","text":"<p>The base image you choose can greatly affect the size and security of your final image. Choose a minimal base image and only include what you need to minimize the attack surface and reduce the image size.</p> <p>One popular base image is <code>Alpine</code> Linux. Alpine Linux is a lightweight Linux distribution that is designed to be small and efficient. It is commonly used for Docker images because of its small size, which makes it ideal for running containers with limited resources.</p> <p>Another base image that is commonly used is the <code>slim</code> version of the official images provided by different software vendors. For example, the official Python image has a slim version, which is a smaller image with only the necessary dependencies required to run Python applications. This means that you can reduce the size of your Docker image by using the slim version instead of the full version.</p> <p>However, it is important to keep in mind that using a base image that is too small can sometimes cause issues.</p>"},{"location":"docker/docker_best_practice/#avoid-running-as-root","title":"Avoid running as root","text":"<p>Running containers as the root user is considered bad practice because it poses a security risk. By default, the root user inside a container has the same privileges as the root user on the host machine. This means that if an attacker gains control of a container running as root, they could potentially escalate their privileges to the host machine.</p> <p>To avoid running containers as root, you can specify a non-root user in your Dockerfile using the <code>USER</code> instruction. For example: <pre><code>FROM python:3.9-slim\n# Create a non-root user\nRUN useradd --create-home myuser\nWORKDIR /home/myuser\n# Switch to the non-root user\nUSER myuser\n# Copy application files and install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy the rest of the application code\nCOPY . .\n\n# Run the application\nCMD [\"python\", \"app.py\"]\n</code></pre></p> <p>In this example, we create a non-root user called myuser and switch to that user using the USER instruction. This user is then used to run the application inside the container.</p>"},{"location":"docker/docker_best_practice/#keep-layers-small","title":"Keep layers small","text":"<p>When building a Docker image, each line in the Dockerfile creates a new layer in the final image. Layers are stacked on top of each other to create the final image. Each layer only stores the changes made on top of the previous layer, which results in a more efficient use of disk space and a faster build time.</p> <p>Keeping layers small is important because it can make it easier to update or modify specific parts of the image without rebuilding the entire image. This can be especially important when dealing with large applications that have many dependencies.</p> <p></p> <p>To keep layers small, it is best to group related commands together in a single line in the Dockerfile. For example, instead of installing several packages in separate RUN commands, it is better to install them all in a single RUN command. This will result in fewer layers and a smaller image size.</p> <p>It is also important to clean up any temporary files created during the build process, as these files can add unnecessary weight to the image. The <code>RUN</code> command should be followed by a <code>CLEANUP</code> command to remove any unwanted files and dependencies.</p> <p>Additionally, using the <code>--no-cache</code> flag when building an image can help to reduce the size of layers, as it prevents Docker from caching layers and forces it to rebuild each layer from scratch.</p>"},{"location":"docker/docker_best_practice/#use-multi-stage-builds","title":"Use multi-stage builds","text":"<p>Multi-stage builds are a way to optimize your Docker images and reduce their size. It allows you to use multiple FROM statements in your Dockerfile, each of which specifies a different base image.</p> <p>Here's an example of how you might use multi-stage builds to build a Python application using Flask: <pre><code># Use an official Python runtime as a parent image\nFROM python:3.8-slim-buster AS base\n# Set the working directory to /app\nWORKDIR /app\n# Copy the requirements file to the working directory\nCOPY requirements.txt .\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir --upgrade pip &amp;&amp; \\\npip install --no-cache-dir -r requirements.txt\n\n# Use a smaller image as the final base image\nFROM python:3.8-slim-buster\n# Set the working directory to /app\nWORKDIR /app\n# Copy the requirements file and installed packages from the previous stage\nCOPY --from=base /usr/local/lib/python3.8/site-packages /usr/local/lib/python3.8/site-packages\n\n# Copy the rest of the application code to the working directory\nCOPY . .\n\n# Start the Flask application\nCMD [\"python\", \"app.py\"]\n</code></pre> In this example, the Dockerfile uses two stages. The first stage starts with the official Python 3.8 slim-buster image, sets the working directory to <code>/app</code>, and copies the <code>requirements.txt</code> file to the working directory. It then installs the required packages specified in the <code>requirements.txt</code> file and saves them to the image.</p> <p>The second stage starts with the same <code>Python 3.8 slim-buster</code> image as the final base image. It sets the working directory to <code>/app</code>, copies the installed packages from the first stage to the image, copies the rest of the application code to the working directory, and starts the Flask application.</p> <p>Using multi-stage builds can significantly reduce the size of your Docker images because you only include the necessary files and dependencies in the final image. In this example, the final image only includes the installed Python packages and the application code, which makes it much smaller than if it included the entire Python runtime.</p> <p>Overall, using multi-stage builds is a best practice for optimizing your Docker images and reducing their size.</p>"},{"location":"docker/docker_best_practice/#use-caching-to-speed-up-builds","title":"Use caching to speed up builds","text":"<p>In Docker, every instruction in a Dockerfile creates a layer like we seen before. When a Dockerfile is built, Docker caches each layer, so that if the same instruction is used in a future build, Docker can use the cached layer instead of re-executing the instruction. This can greatly speed up the build process.</p> <p>One way to take advantage of caching is to order the instructions in the Dockerfile such that the ones that change frequently are at the end, while the ones that change less frequently are at the beginning. For example, you might start with a base image, then copy in your application code, and finally install any dependencies.</p> <p>It's also possible to explicitly tell Docker to use a cached layer with the --cache-from flag. This can be useful if you have multiple Dockerfiles that share some of the same layers. For example, if you have a base image that is used by multiple applications, you can build that image once and then use it as the cache for future builds of the applications.</p> <p>Here's an example of how to use caching to speed up a Docker build:</p> <pre><code># Use an official Python runtime as a parent image\nFROM python:3.9-slim-buster\n# Set the working directory to /app\nWORKDIR /app\n# Copy the requirements file into the container\nCOPY requirements.txt .\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the rest of the application code into the container\nCOPY . .\n\n# Expose port 80 for the web application\nEXPOSE 80\n# Start the web application\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>In this example, the <code>COPY requirements.txt .</code> and <code>RUN pip install --no-cache-dir -r requirements.txt</code> instructions are near the beginning of the Dockerfile because they change less frequently than the application code. This means that Docker can cache those layers and reuse them in future builds, even if the application code has changed.</p>"},{"location":"docker/docker_best_practice/#clean-up-after-yourself","title":"Clean up after yourself","text":"<p>Cleaning up after yourself is an important best practice for Docker. This means removing any unused images, containers, volumes, and networks that are no longer needed. Not only does it save disk space, but it also ensures that the Docker environment is not cluttered with unnecessary artifacts that may cause conflicts or security issues.</p> <p>Here are some tips for cleaning up after yourself in Docker:</p> <ol> <li>Remove unused containers: To remove unused containers, use the <code>docker container prune</code> command. This command removes all stopped containers. If you want to remove a specific container, use the <code>docker rm</code> command followed by the container ID.</li> <li>Remove unused images: To remove unused images, use the <code>docker image prune</code> command. This command removes all images that are not associated with any container. If you want to remove a specific image, use the <code>docker rmi</code> command followed by the image ID.</li> <li>Remove unused volumes: To remove unused volumes, use the <code>docker volume prune</code> command. This command removes all volumes that are not associated with any container. If you want to remove a specific volume, use the <code>docker volume rm</code> command followed by the volume name.</li> <li>Remove unused networks: To remove unused networks, use the <code>docker network prune</code> command. This command removes all networks that are not associated with any container. If you want to remove a specific network, use the <code>docker network rm</code> command followed by the network name.</li> <li>Use <code>--rm</code> option: When running containers, use the <code>--rm</code> option to automatically remove the container when it exits. This is especially useful for testing and development environments where you don't need to keep the container around.</li> </ol> <p>By following these best cleaning practices, you can keep your Docker environment clean and avoid cluttering it with unused artifacts.</p>"},{"location":"docker/docker_best_practice/#consider-security","title":"Consider security","text":"<p>Security is an important consideration when it comes to Docker containers. Here are some best practices to keep in mind:</p> <ol> <li>Use the latest version of the base image: It is important to use the latest version of the base image, as this will ensure that any security vulnerabilities in the base image have been patched.</li> <li>Avoid using root user: Running a container as root can be risky, as it can potentially allow an attacker to gain access to the host system. Instead, use a non-root user.</li> <li>Limit container capabilities: By default, containers have access to all capabilities of the host system. It is important to limit the capabilities of the container to only what it needs.</li> <li>Use a minimal base image: Using a minimal base image, such as Alpine, reduces the attack surface of the container by reducing the number of packages installed.</li> <li>Keep containers up to date: It is important to keep containers up to date with security patches and updates.</li> <li>Scan images for vulnerabilities: Use a vulnerability scanner to scan images for known vulnerabilities. This will help to identify any potential security issues.</li> <li>Consider network security: Secure network access to containers by using network segmentation, firewalls, and VPNs. A common practice is to run containers inside your cloud provider's VPC. </li> </ol>"},{"location":"docker/docker_best_practice/#quick-scan-a-container","title":"Quick scan a container","text":"<ol> <li> <p>First, install Trivy by following the installation instructions for your operating system from the official Trivy GitHub page: https://github.com/aquasecurity/trivy</p> </li> <li> <p>Then Pull a Docker image that you want to scan, for example, the official Python image: <pre><code>docker pull python:3.9-slim\n</code></pre></p> </li> <li> <p>Run Trivy against the image: <pre><code>trivy image python:3.9-slim\n</code></pre> This will scan the Python image and report any vulnerabilities found in the image's base image or any installed packages. You can also scan a Dockerfile directly using the --file option: <pre><code>trivy --file Dockerfile\n</code></pre> This will scan the Dockerfile and report any vulnerabilities found in the base image or any installed packages.</p> </li> </ol> <p>Note that scanning Docker images is just one part of a comprehensive security strategy for containerized applications. It's also important to ensure that your containers are configured securely, that you use strong authentication and authorization mechanisms, and that you regularly apply security updates and patches to your container images.</p> <p>By following these best practices, you can help to ensure that your Docker containers are secure and less vulnerable to attack.</p>"},{"location":"docker/docker_best_practice/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":"<ol> <li>Check container logs: Container logs can provide valuable information on what is happening inside the container. Use <code>docker logs &lt;container-id&gt;</code> to view container logs and troubleshoot issues.</li> <li>Use docker exec to troubleshoot running containers: <code>docker exec</code> allows you to run commands inside a running container, which can be useful for troubleshooting issues.</li> <li>Check container health: Use <code>docker ps</code> to check the status of running containers. If a container is not running, use <code>docker ps -a</code> to view all containers, including stopped ones.</li> <li>Check resource utilization: Docker containers can consume a lot of resources. Use <code>docker stats</code> to view resource utilization for running containers.</li> <li>Use the correct Docker command: Use the correct Docker command for the task at hand. For example, <code>docker stop</code> will gracefully stop a container, while <code>docker kill</code> will forcibly stop a container.</li> <li>Check networking: If your container is not communicating with other containers or services, check the networking configuration. Use docker network ls to view available networks and <code>docker network inspect</code> to view details of a specific network.</li> <li>Consider container security: Ensure that your container is running in a secure environment and follow security best practices for your application like we have seen before. </li> </ol> <p>By following best practices for Dockerfile design and container optimization and knowing how to troubleshoot common issues with Docker containers, you can ensure that your Docker containers are running smoothly and securely.</p>"},{"location":"docker/docker_commands/","title":"Docker CLI Commands","text":"<p>The Docker CLI (Command Line Interface) provides a set of commands for working with Docker images and containers. These commands are used to build, run, manage, and interact with Docker images and containers.</p> <p>Here are some of the most common Docker CLI commands:</p>"},{"location":"docker/docker_commands/#docker-build","title":"<code>docker build</code>","text":"<p>This command is used to build a Docker image from a Dockerfile. Example: <pre><code>docker build -t myimage .\n</code></pre> This command builds a Docker image from the Dockerfile in the current directory and tags it with the name <code>myimage</code>. The option <code>-t</code> or <code>--tag</code> : Sets the name and optionally a tag for the Docker image.</p>"},{"location":"docker/docker_commands/#docker-build-options","title":"docker build options","text":""},{"location":"docker/docker_commands/#tag-t","title":"Tag <code>-t</code>","text":"<p>Example: <pre><code>docker build -t myimage:latest .\n</code></pre> or  <pre><code>docker build -t myimage:01 .\n</code></pre></p> <p>This command builds a Docker image from the Dockerfile in the current directory, tags it with the name myimage and the <code>latest</code> or <code>01</code> tags.</p>"},{"location":"docker/docker_commands/#file-f","title":"File <code>-f</code>","text":"<p>The option <code>-f</code>, <code>--file</code> : Specifies the name and location of the Dockerfile to use. Example: <pre><code>docker build -t myimage:latest -f path/to/Dockerfile.dev .\n</code></pre> This command builds a Docker image from the Dockerfile located at <code>path/to/Dockerfile.dev</code>, tags it with the name <code>myimage</code> and the <code>latest</code> tag.</p>"},{"location":"docker/docker_commands/#cache-no-cache","title":"Cache <code>--no-cache</code>","text":"<p><code>--no-cache</code> : Disables caching during the build process. Example: <pre><code>docker build --no-cache -t myimage:latest .\n</code></pre> This command builds a Docker image from the Dockerfile in the current directory, without using any cached layers.</p>"},{"location":"docker/docker_commands/#docker-run","title":"<code>docker run</code>","text":"<p>This command is used to run a Docker container from a Docker image.</p> <p>Example: <pre><code>docker run --name mycontainer myimage\n</code></pre> This command runs a Docker container from the <code>myimage</code> Docker image and names the container <code>mycontainer</code> with the tag <code>--name</code>. </p>"},{"location":"docker/docker_commands/#docker-run-options","title":"docker run options","text":""},{"location":"docker/docker_commands/#tag-d","title":"Tag <code>-d</code>","text":"<p>The option <code>-d</code>, <code>--detach</code> : Runs the container in detached mode, in the background so you can use your terminal as you want is not stuck in the process. Example: <pre><code>docker run -d myimage\n</code></pre> This command runs the <code>myimage</code> Docker image in detached mode, in the background.</p>"},{"location":"docker/docker_commands/#tag-p","title":"Tag <code>-p</code>","text":"<p>The option <code>-p</code>, <code>--publish</code> : Publishes a container's port(s) to the host machine. Example: <pre><code>docker run -p 80:80 myimage\n</code></pre> This command runs the myimage Docker image and maps port <code>80</code> inside the container to port <code>80</code> on the host machine.</p>"},{"location":"docker/docker_commands/#tag-name","title":"Tag <code>--name</code>","text":"<p>The option <code>--name</code>: Assigns a name to the container. Example: <pre><code>docker run --name mycontainer myimage\n</code></pre> This command runs the <code>myimage</code> Docker image and assigns the name <code>mycontainer</code> to the resulting container.</p>"},{"location":"docker/docker_commands/#tag-e","title":"Tag <code>-e</code>","text":"<p>The option  <code>-e</code>, <code>--env</code> : Sets environment variables inside the container. Example: <pre><code>docker run -e MYVAR=myvalue myimage\n</code></pre> This command runs the <code>myimage</code> Docker image and sets the environment variable <code>MYVAR</code> to <code>myvalue</code> inside the container.</p>"},{"location":"docker/docker_commands/#tag-v","title":"Tag <code>-v</code>","text":"<p>The option <code>-v</code>, <code>--volume</code> : Mounts a volume from the host machine into the container. Example: <pre><code>docker run -v /path/on/host:/path/in/container myimage\n</code></pre> This command runs the <code>myimage</code> Docker image and mounts the directory <code>/path/on/host</code> on the host machine to the directory <code>/path/in/container</code> inside the container.</p>"},{"location":"docker/docker_commands/#tag-it","title":"Tag <code>-it</code>","text":"<p>The option <code>-it</code>, <code>--interactive</code> : Runs the container in interactive mode, allowing input from the user. Example: <pre><code>docker run -it myimage /bin/bash\n</code></pre> This command runs the <code>myimage</code> Docker image in interactive mode and starts a bash shell inside the container.</p> <p>You can of course use multiple tags like :  <pre><code>docker run -d --name mycontainer -p 80:80 myimage\n</code></pre> This command runs a Docker container from the myimage Docker image in detached mode (<code>-d</code>), names the container mycontainer (<code>--name</code>), maps port <code>80</code> on the host machine to port <code>80</code> inside the container (<code>-p</code>), and uses the myimage Docker image as the container's base image.</p>"},{"location":"docker/docker_commands/#docker-ps","title":"<code>docker ps</code>","text":"<p>This command is used to list running Docker containers. Example: <pre><code>docker ps\n</code></pre> This command lists all running Docker containers. You can also list the exited container with the <code>-a</code> option , it is very usefull in case you want to debug a container.</p> <pre><code>docker ps -a\n</code></pre>"},{"location":"docker/docker_commands/#docker-stop","title":"<code>docker stop</code>","text":"<p>This command is used to stop a running Docker container. Example: <pre><code>docker stop mycontainer\n</code></pre> This command stops the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-rm","title":"<code>docker rm</code>","text":"<p>This command is used to remove a stopped Docker container. Example: <pre><code>docker rm mycontainer\n</code></pre> This command removes the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-images","title":"<code>docker images</code>","text":"<p>This command is used to list Docker images. Example: <pre><code>docker images\n</code></pre> This command lists all Docker images on the local machine.</p>"},{"location":"docker/docker_commands/#docker-rmi","title":"<code>docker rmi</code>","text":"<p>This command is used to remove a Docker image.</p> <p>Example: <pre><code>docker rmi myimage\n</code></pre> This command removes the myimage Docker image.</p>"},{"location":"docker/docker_commands/#docker-exec","title":"<code>docker exec</code>","text":"<p>This command is used to execute a command inside a running Docker container.</p> <p>Example: <pre><code>docker exec mycontainer ls /app\n</code></pre> This command executes the ls <code>/app</code> command inside the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-logs","title":"<code>docker logs</code>","text":"<p>This command is used to view the logs for a Docker container.</p> <p>Example: <pre><code>docker logs mycontainer\n</code></pre> This command displays the logs for the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-inspect","title":"<code>docker inspect</code>","text":"<p>This command is used to view detailed information about a Docker object, such as a container or image.</p> <p>Example: <pre><code>docker inspect mycontainer\n</code></pre> This command displays detailed information about the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-pull","title":"<code>docker pull</code>","text":"<p>This command is used to pull a Docker image from a registry.</p> <p>Example: <pre><code>docker pull nginx:latest\n</code></pre> This command pulls the latest version of the nginx Docker image from the Docker Hub registry.</p>"},{"location":"docker/docker_commands/#docker-push","title":"<code>docker push</code>","text":"<p>This command is used to push a Docker image to a registry. Example: <pre><code>docker push myregistry/myimage:latest\n</code></pre> This command pushes the myimage Docker image with the latest tag to the myregistry Docker registry.</p>"},{"location":"docker/docker_commands/#wrap-up","title":"Wrap-up","text":"<p>These are just a few of the most common Docker CLI commands. There are many other commands available that can be used for more advanced use cases, such as networking, volumes, and swarm management. By mastering these basic Docker CLI commands, you can get started with Docker and start</p>"},{"location":"docker/docker_compose/","title":"Docker-compose","text":""},{"location":"docker/docker_compose/#what-is-docker-compose-and-why-use-it","title":"What is Docker Compose and Why Use It?","text":"<p>Docker Compose is a tool that allows you to define and run multi-container Docker applications. It makes it easy to start and stop multiple containers with a single command, and provides a way to configure the containers and their relationships to each other.</p> <p>Docker Compose is particularly useful for running complex applications that are made up of multiple services, each with its own requirements and dependencies. By using Docker Compose, you can define the configuration for all of these services in a single file, making it easier to manage and deploy your application.</p>"},{"location":"docker/docker_compose/#yaml-syntax","title":"<code>YAML</code> syntax","text":"<p>YAML (short for \"YAML Ain't Markup Language\") is a human-readable data serialization language. It is often used for configuration files and data exchange between different programming languages. YAML is designed to be easily read by humans and can be used for complex or simple data structures.</p> <p>Docker Compose uses YAML syntax for its configuration files because it is easy to read and write. Docker Compose configuration files define all the services that make up an application, as well as any associated networks, volumes, and environment variables. By using YAML syntax, it allows developers to easily define the relationships between the different parts of an application and deploy it consistently across different environments.</p> <p>Few this to know about <code>yaml</code> syntax : </p> <ul> <li>YAML files use indentation to denote hierarchy, instead of curly braces like JSON or XML.</li> <li>The syntax is strict about indentation, so it's important to use consistent spacing (usually 2 or 4 spaces) for each level of hierarchy.</li> <li>Key-value pairs are written as key: value, with the key and value separated by a colon and a space.</li> <li>Lists are denoted by a dash (-) followed by a space, and can contain any type of value.</li> <li>Comments can be added using the # symbol.</li> </ul> <p>Here's an example YAML file that defines a simple docker-compose web service: <pre><code>version: '3'\nservices:\nweb:\nimage: nginx:latest\nports:\n- \"8080:80\"\n</code></pre></p> <p>In this file:</p> <ul> <li><code>version</code> specifies the Docker Compose file version.</li> <li><code>services</code> is a list of Docker services to be created and run.</li> <li><code>web</code> is the name of the first service.</li> <li><code>image</code> specifies the Docker image to be used for the service.</li> <li><code>ports</code> maps a port on the host machine to a port in the container.</li> <li><code>\"8080:80\"</code> maps port 8080 on the host (your local machine or virtual machine in case you are in a VM) to port 80 in the container.</li> </ul> <p>This is just a basic example, but hopefully it gives you an idea of how the YAML syntax works but it will be helpful for the next part.</p>"},{"location":"docker/docker_compose/#docker-compose-for-a-simple-python-app-and-redis-database","title":"Docker Compose for a simple Python App and Redis database","text":"<p>Let's create a two containers application with a <code>docker-compose.yml</code> file with a python app and a redis database in order to count how many times the page is reload. </p> <p></p> <p>First thing first, write our <code>app.py</code> script : app.py<pre><code>from flask import Flask\nfrom redis import Redis\napp = Flask(__name__)\nredis = Redis(host='redis-container', port=6379)\n@app.route('/')\ndef hello():\nredis.incr('hits')\nreturn ' - - - This basic web page has been viewed {} time(s) - - -'.format(redis.get('hits'))\nif __name__ == \"__main__\":\napp.run(host=\"0.0.0.0\", debug=True)\n</code></pre> and the <code>requirements.txt</code> file :  requirements.txt<pre><code>flask\nredis\n</code></pre> This is a simple Python Flask web application that increments a counter each time the / route is accessed and displays the number of times it has been accessed. The application uses Redis as a datastore to store the hit counter.</p> <p>Here is how our <code>app.py</code> script works:</p> <ol> <li>The Flask library is imported, which allows us to create a web application.</li> <li>The Redis library is imported, which allows us to connect to a Redis instance and manipulate data.</li> <li>The Flask application is created and the Redis client is initialized, connecting to the Redis container named \"redis-container\" at port 6379.</li> <li>A route for the / endpoint is defined. When this route is accessed, the hit counter in Redis is incremented and the current count is displayed on the page.</li> <li>Finally, the application is run, listening on all network interfaces (0.0.0.0) on port 5000 and with debugging enabled.</li> </ol> <p>Then, we must write a <code>Dockerfile</code> :  <pre><code>FROM python:3.6\nWORKDIR /app\nCOPY . .\nRUN pip install -r requirements.txt\nCMD python app.py\n</code></pre> Like before this is a simple <code>Dockerfile</code> for a python application. </p>"},{"location":"docker/docker_compose/#write-the-docker-composeyml-of-our-app","title":"Write the <code>docker-compose.yml</code> of our app","text":"<p>docker-compose.yml<pre><code>version: '3'\nservices:\nweb:\nbuild: ./app\nports:\n- \"5000:5000\"\nvolumes:\n- ./app:/app\ndepends_on:\n- redis-container\nredis-container:\nimage: redis\n</code></pre> This script is a Docker Compose file that describes two services that will be run in Docker containers: a web service and a Redis service.</p> <p>The <code>web</code> service is defined by the <code>web</code> service block. It specifies that the <code>web</code> service should be built from the Dockerfile in the <code>./app</code> directory, and should expose port 5000 on the host machine. The volumes directive maps the <code>./app</code> directory on the host to the <code>/app</code> directory in the container, allowing changes to the code to be immediately reflected in the container. The depends_on directive specifies that the <code>web</code> service should not start until the Redis service is running.</p> <p>The Redis service is defined by the <code>redis-container</code> block. It specifies that the Redis image should be used to create the service. This is the architeture of our project :  <pre><code>.\n|_docker-compose.yml\n|_app\n  |_Dockerfile\n  |_requirements.txt\n  |_app.py\n</code></pre> Together, these services can be started with the <code>docker-compose up</code> command, which will build and start the web and Redis containers, and connect them together on a default Docker network.   </p> <p>You can also run your project in background with <code>-d</code> option then you should see your containers up and running with the command <code>docker ps</code></p>"},{"location":"docker/docker_compose/#docker-compose-for-a-python-app-and-postgresql","title":"Docker Compose for a Python App and PostgreSQL","text":"<p>Now that we understand how two containers works together let's code an application with a more efficient database : postgreSQL. </p>"},{"location":"docker/docker_compose/#what-is-postgresql","title":"What is PostgreSQL","text":"<p>PostgreSQL, also known as Postgres, is a powerful and open-source relational database management system. It uses and extends the SQL language and provides many features such as support for JSON and other NoSQL features, scalability, and extensibility. It can run on various platforms such as Windows, macOS, Linux, and Unix. </p> <p>Many organizations use Postgres for their data storage needs due to its reliability, robustness, and community support.</p>"},{"location":"docker/docker_compose/#set-up-the-project","title":"Set up the project","text":"<p>To create a Docker Compose file for your Python app, you'll need to define the services that make up your application. Each service is defined in the Docker Compose file as a separate block of configuration. In this example we will take the <code>nortwhind</code> database here as base for our database service. </p> <p>Download or <code>git clone</code> the <code>nortwhind</code> database here and open the <code>docker-compose.yml</code> file bellow who define two services, one for a monitoring application <code>pgadmin</code> and one for a PostgreSQL database <code>db</code> :</p> <pre><code>version: '3'\nservices:\ndb:\ncontainer_name: db\nimage: postgres:latest\nenvironment:\nPOSTGRES_DB: northwind\nPOSTGRES_USER: postgres\nPOSTGRES_PASSWORD: postgres\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- postgresql_data:/var/lib/postgresql/data\n- ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n- ./files:/files\nports:\n- 55432:5432\nnetworks:\n- db\npgadmin:\ncontainer_name: pgadmin\nimage: dpage/pgadmin4\nenvironment:\nPGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\nPGADMIN_DEFAULT_PASSWORD: postgres\nPGADMIN_LISTEN_PORT: 5050\nPGADMIN_CONFIG_SERVER_MODE: 'False'\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- pgadmin_root_prefs:/root/.pgadmin\n- pgadmin_working_dir:/var/lib/pgadmin\n- ./files:/files\nports:\n- 5050:5050\nnetworks:\n- db\nnetworks:\ndb:\ndriver: bridge\nvolumes:\npgadmin_root_prefs:\ndriver: local\npgadmin_working_dir:\ndriver: local\npostgresql_data:\ndriver: local\npostgresql_bin:\ndriver: local\n</code></pre> <p>Let's break down this Docker Compose file:</p> <ul> <li>version: '3': This specifies the version of the Docker Compose file format that we're using.</li> <li>services: This is where we define the services that make up our application.<ul> <li><code>db</code>: The Postgres database service.<ul> <li><code>container_name</code>: Sets the name of the container to db.</li> <li><code>image</code>: postgres:latest: Specifies the image to use for the container.</li> <li><code>environment</code>: Sets environment variables for the container.<ul> <li><code>POSTGRES_DB</code>: northwind: Specifies the name of the database to create.</li> <li><code>POSTGRES_USER</code>: postgres: Specifies the username for the database.</li> <li><code>POSTGRES_PASSWORD</code>: postgres: Specifies the password for the database.</li> </ul> </li> <li><code>volumes</code>: Mounts volumes for the container.<ul> <li><code>postgresql_bin:/usr/lib/postgresql</code>: Mounts the PostgreSQL binaries.</li> <li><code>postgresql_data:/var/lib/postgresql/data</code>: Mounts the PostgreSQL data directory.</li> <li><code>./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql</code>: Copies the northwind.sql script into the container for initializing the database.</li> <li><code>./files:/files</code>: Mounts the files directory into the container.</li> </ul> </li> <li><code>ports</code>: Maps ports between the container and the host.<ul> <li><code>55432:5432</code>: Maps port 5432 inside the container to port 55432 on the host.</li> </ul> </li> </ul> </li> <li><code>networks</code>: Specifies the networks to connect the container to.<ul> <li><code>db</code>: Connects the container to the db network.</li> </ul> </li> <li><code>pgadmin</code>: The pgAdmin web interface service in order to visualize our database <ul> <li><code>image : dpage/pgadmin4</code>: Specifies the image to use for the container.</li> <li><code>environment</code>: Sets environment variables for the container.<ul> <li><code>PGADMIN_DEFAULT_EMAIL</code>: pgadmin4@pgadmin.org: Specifies the default email for pgAdmin.</li> <li><code>PGADMIN_DEFAULT_PASSWORD</code>: postgres: Specifies the default password for pgAdmin.</li> <li><code>PGADMIN_LISTEN_PORT: 5050</code>: Specifies the port for pgAdmin to listen on.</li> <li><code>PGADMIN_CONFIG_SERVER_MODE</code>: 'False': Disables server mode for pgAdmin.</li> </ul> </li> <li><code>volumes</code>: Mounts volumes for the container.</li> <li><code>ports</code>: Maps ports between the container and the host.<ul> <li><code>5050:5050</code>: Maps port 5050 inside the container to port 5050 on the host.</li> </ul> </li> </ul> </li> </ul> </li> <li>networks: Specifies the networks to create.<ul> <li><code>db</code>: Creates the db network.</li> <li><code>driver: bridge</code>: Specifies the driver to use for the network, this is the standard driver \ud83e\udd13</li> </ul> </li> <li>volumes: Specifies the volumes to create, see volume part in the table of content for more detailed </li> </ul> <p>Once you've defined your Docker Compose file, you can use the <code>docker-compose up</code> command to start and stop your application. Here are some of the most common commands:</p> <ul> <li><code>docker-compose up</code>: This command starts your application and attaches your terminal to the logs of all running containers. You can use Ctrl+C to stop the containers and exit.</li> <li><code>docker-compose up -d</code>: This command starts your application in detached mode, which means that it runs in the background. You can use docker-compose logs to view the logs of your containers.</li> <li><code>docker-compose down</code>: This command stops and removes all containers, networks, and volumes that were created by docker-compose up.</li> <li><code>docker-compose ps</code>: This command lists all running containers in your Docker Compose application.</li> <li><code>docker-compose build</code>: This command builds the images for all of the services in your Docker Compose file.</li> </ul> <p>By using Docker Compose, you can easily start and stop multiple containers with a single command, and manage the configuration of all of your services in a single file. This makes it easier to manage and deploy complex applications that are made up of multiple services.</p>"},{"location":"docker/docker_compose/#pgadmin-interface","title":"PgAdmin interface","text":"<p>First let's confirm our containers are up and running by taping <code>docker ps</code> command. If you see the container running like :  <pre><code>a76abdcbf8da   dpage/pgadmin4             \"/entrypoint.sh\"         About an hour ago   Up About an hour        80/tcp, 443/tcp, 0.0.0.0:5050-&gt;5050/tcp, :::5050-&gt;5050/tcp\n</code></pre></p> <p>To see our database go to : (localhost:5050)[http://localhost:5050] and write a random password (like root) then register our database by running the following command : </p> <ol> <li>Add a new server in PgAdmin </li> <li>In the general Tab, write the paramater <code>Name = db</code></li> <li>In the Connection Tab write the following parameters :  <pre><code>Host name: db\nUsername: postgres\nPassword: postgres\n</code></pre></li> <li>Then, select database \"northwind\" and you can now see all the tables and metadata \ud83e\udd73</li> </ol>"},{"location":"docker/docker_compose/#add-a-python-app","title":"Add a Python app","text":"<pre><code>from fastapi import FastAPI\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\napp = FastAPI()\nengine = create_engine('postgresql://postgres:postgres@db/northwind')\nSession = sessionmaker(bind=engine)\n@app.get('/')\ndef read_root():\nsession = Session()\nresult = session.execute(text('SELECT customer_id, company_name, contact_name FROM customers LIMIT 10'))\nreturn {'Customers info': [dict(customerid=row[0], companyname=row[1], contactname=row[2]) for row in result]}\n</code></pre> <p>This application uses the FastAPI framework to define a simple endpoint that returns a JSON response with a greeting and a value from a PostgreSQL database.</p> <p>To run this application using Docker Compose, you'll need to save this file as main.py in the same directory as your Dockerfile, and update your Docker Compose file to include the following environment variable for the app service and dependence :</p> <p><pre><code>environment:\nDB_HOST: db\ndepends_on:\n- db\n</code></pre> This environment variable tells the application where to find the PostgreSQL database and tell the application to wait for the lunch of the <code>db</code> service.</p>"},{"location":"docker/docker_compose/#integrate-our-app-to-the-docker-composeyml-file","title":"Integrate our app to the <code>docker-compose.yml</code> file","text":"docker-compose.yml<pre><code>version: '3'\nservices:\ndb:\ncontainer_name: db\nimage: postgres:latest\nenvironment:\nPOSTGRES_DB: northwind\nPOSTGRES_USER: postgres\nPOSTGRES_PASSWORD: postgres\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- postgresql_data:/var/lib/postgresql/data\n- ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n- ./files:/files\nports:\n- 55432:5432\nnetworks:\n- db\npgadmin:\ncontainer_name: pgadmin\nimage: dpage/pgadmin4\nenvironment:\nPGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\nPGADMIN_DEFAULT_PASSWORD: postgres\nPGADMIN_LISTEN_PORT: 5050\nPGADMIN_CONFIG_SERVER_MODE: 'False'\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- pgadmin_root_prefs:/root/.pgadmin\n- pgadmin_working_dir:/var/lib/pgadmin\n- ./files:/files\nports:\n- 5050:5050\nnetworks:\n- db\napp:\nbuild:\ncontext: .\ndockerfile: Dockerfile\nenvironment:\nDB_HOST: db\ndepends_on:\n- db\nports:\n- \"8000:8000\"\nnetworks:\n- db\nnetworks:\ndb:\ndriver: bridge\nvolumes:\npgadmin_root_prefs:\ndriver: local\npgadmin_working_dir:\ndriver: local\npostgresql_data:\ndriver: local\npostgresql_bin:\ndriver: local\n</code></pre> <p>The <code>app</code> service is a container that will host a Python application that uses the <code>northwind</code> database created by the <code>db</code> service. The app container will be built using the Dockerfile located in the same directory as the <code>docker-compose.yml</code> file. The <code>depends_on</code> property indicates that the app container must be started after the <code>db</code> container is running. </p> <p>The environment property sets the <code>DB_HOST</code> environment variable, which is used in the application to connect to the <code>db</code> container. The ports property maps port <code>8000</code> of the <code>app</code> container to port <code>8000</code> of the host machine, allowing access to the FastAPI application from a web browser. The <code>networks</code> property specifies that the <code>app</code> container is connected to the <code>db</code> network, allowing communication between the application and the database.</p> <p>Once you've made these changes, you can start your application using Docker Compose with the following command:</p> <pre><code>docker-compose up --build\n</code></pre> <p>This will start both the <code>db</code> and <code>app</code> services and rebuild it just in case, and you should be able to access the application by visiting http://localhost:8000 in your web browser.</p>"},{"location":"docker/docker_compose/#stop-docker-compose","title":"Stop docker-compose","text":"<p>Stop the server that was launched by docker compose up via <code>Ctrl-C</code> if you are in interactive mode, then remove the containers via: <pre><code>docker-compose down\n</code></pre> or just go to the root of your repository and run <code>docker-compose down</code></p>"},{"location":"docker/docker_https/","title":"Docker and HTTPS","text":""},{"location":"docker/docker_https/#what-is-https","title":"What is HTTPS","text":"<p>HTTPS stands for Hypertext Transfer Protocol Secure, which is an extension of the HTTP protocol used for secure communication over the internet. It is a way of encrypting the data that is transmitted between a web browser and a web server, making it more difficult for attackers to intercept and steal sensitive information, such as login credentials or credit card numbers.</p> <p>To enable HTTPS on a website, you need to obtain an SSL (Secure Sockets Layer) certificate. An SSL certificate is a digital certificate that verifies the identity of a website and encrypts the data transmitted between the web server and the client's browser. SSL certificates are issued by trusted certificate authorities (CA), such as Let's Encrypt, Comodo, and Symantec.</p> <p>There are several ways to get an SSL certificate, depending on your needs and budget. Here are some options:</p> <ul> <li>Let's Encrypt: Let's Encrypt is a free and open certificate authority that provides SSL certificates for websites. It is widely used and trusted, and can be easily integrated with many web servers, including Apache and Nginx.</li> <li>Paid SSL certificates: There are many companies that offer paid SSL certificates, including Comodo, Symantec, and DigiCert. These certificates usually provide a higher level of validation and come with more advanced features, such as extended validation and wildcard certificates.</li> <li>Cloud hosting providers: Many cloud hosting providers, such as AWS, Google Cloud, and Azure, offer SSL certificates as part of their hosting packages. These certificates are often managed by the hosting provider, making it easier to install and renew them.</li> </ul> <p>To obtain an SSL certificate, you typically need to generate a certificate signing request (CSR) on your web server, which contains information about your website and your public key. You then submit the CSR to a certificate authority, which will verify your identity and issue a certificate. Once you receive the certificate, you need to install it on your web server and configure your server to use HTTPS.</p> <p>Keep in mind that SSL certificates have expiration dates and need to be renewed periodically, usually every one or two years. It's also important to ensure that your web server and applications are configured correctly to use HTTPS, and to keep your server and software up to date to address any security vulnerabilities.</p>"},{"location":"docker/docker_https/#add-https-to-our-pythonpostgres-app","title":"Add HTTPS to our Python/Postgres app","text":"<p>Let's take our project from the previous section and add an Nginx service \ud83e\udd13</p>"},{"location":"docker/docker_https/#nginx","title":"Nginx","text":"<p>Nginx is a popular open-source web server that can also function as a reverse proxy, load balancer, and HTTP cache. It is known for its high performance, stability, and ability to handle a large number of simultaneous connections.</p> <p>Developers should be familiar with Nginx because it is commonly used as a frontend web server in production environments. In addition to its performance benefits, Nginx is also highly customizable and can be used to handle complex routing, authentication, and security configurations.</p> <p>Nginx also integrates well with many popular web frameworks and technologies, making it a valuable tool for developers who are building web applications. By leveraging Nginx's features, developers can improve the performance, scalability, and security of their applications.</p>"},{"location":"docker/docker_https/#generate-a-free-ssl-certificate","title":"Generate a free ssl certificate","text":"<p>First go to the root of your project and create a new directory call <code>certs</code> and then run this command : <pre><code>openssl req -x509 -newkey rsa:4096 -keyout certs/key.pem -out certs/cert.pem -days 365 -nodes\n</code></pre> This will create a certs folder and generate a self-signed SSL certificate with a private key (<code>key.pem</code>) and a public certificate (<code>cert.pem</code>) that are valid for 365 days.</p> <p>Then add execution right to the private key in order to be executed by our nginx service inside our <code>Dockerfile</code> with the following command :  <pre><code>chmod +x certs/key.pem\n</code></pre></p>"},{"location":"docker/docker_https/#create-an-nginxconf-file","title":"Create an <code>nginx.conf</code> file","text":"<p>Go to the root of your project and create a new file called <code>nginx.conf</code></p> nginx.conf<pre><code>events {}\nhttp {\nupstream app {\nserver app:8000;\n}\nserver {\nlisten 80;\nlisten [::]:80;\nserver_name yourdomain.com;\nreturn 301 https://$host$request_uri;\n}\nserver {\nlisten 443 ssl http2;\nlisten [::]:443 ssl http2;\nserver_name yourdomain.com;\nssl_certificate /etc/ssl/certs/cert.pem;\nssl_certificate_key /etc/ssl/certs/key.pem;\nlocation / {\nproxy_pass http://app;\nproxy_set_header Host $host;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-Proto https;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n}\n}\n}\n</code></pre> <p>We will not dig in detail this script in this course section just make sure to replace <code>yourdomain.com</code> with your actual domain name, and update the SSL certificate file paths to match your file names and folder locations.</p>"},{"location":"docker/docker_https/#refactor-our-docker-composeyml-file","title":"Refactor our <code>docker-compose.yml</code> file","text":"docker-compose.yml<pre><code>version: '3'\nservices:\ndb:\ncontainer_name: db\nimage: postgres:latest\nenvironment:\nPOSTGRES_DB: northwind\nPOSTGRES_USER: postgres\nPOSTGRES_PASSWORD: postgres\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- postgresql_data:/var/lib/postgresql/data\n- ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n- ./files:/files\nports:\n- 55432:5432\nnetworks:\n- db\npgadmin:\ncontainer_name: pgadmin\nimage: dpage/pgadmin4\nenvironment:\nPGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\nPGADMIN_DEFAULT_PASSWORD: postgres\nPGADMIN_LISTEN_PORT: 5050\nPGADMIN_CONFIG_SERVER_MODE: 'False'\nvolumes:\n- postgresql_bin:/usr/lib/postgresql\n- pgadmin_root_prefs:/root/.pgadmin\n- pgadmin_working_dir:/var/lib/pgadmin\n- ./files:/files\nports:\n- 5050:5050\nnetworks:\n- db\napp:\nbuild:\ncontext: .\ndockerfile: Dockerfile\nenvironment:\nDB_HOST: db\ndepends_on:\n- db\nports:\n- \"8000:8000\"\nnetworks:\n- db\n- mynetwork\nnginx:\nimage: nginx:latest\nports:\n- \"80:80\"\n- \"443:443\"\nvolumes:\n- ./nginx.conf:/etc/nginx/nginx.conf\n- ./certs:/etc/ssl/certs\nnetworks:\n- mynetwork\ndepends_on:\n- app\nrestart: always\nnetworks:\ndb:\ndriver: bridge\nmynetwork:\ndriver: bridge\nvolumes:\npgadmin_root_prefs:\ndriver: local\npgadmin_working_dir:\ndriver: local\npostgresql_data:\ndriver: local\npostgresql_bin:\ndriver: local\n</code></pre> <p>Let's talk about the ppart of the docker-compose file defines a service named <code>nginx</code> that is based on the <code>nginx:latest</code> Docker image. Here is a detailed explanation of each section:</p> <ul> <li><code>image: nginx:latest</code>: This line specifies the Docker image to use for the nginx service, which is <code>nginx:latest</code>.</li> <li><code>ports</code>: This section maps the container ports to the host ports. It exposes the container ports <code>80</code> and <code>443</code> to the host machine.</li> <li><code>volumes</code>: This section maps the host directories or files to the container directories or files. Here, it mounts the <code>nginx.conf</code> file from the current directory into the container's <code>/etc/nginx/nginx.conf</code> path. It also mounts the certs directory from the current directory into the container's <code>/etc/ssl/certs</code> path.</li> <li><code>networks</code>: This section specifies the networks to which this service is attached. In this case, it is attached to the mynetwork network.</li> <li><code>depends_on</code>: This section specifies that the <code>nginx</code> service depends on the <code>app</code> service to start. This means that the <code>app</code> service will be started before the nginx service.</li> <li><code>restart</code>: This line specifies that the container should always be restarted if it stops for any reason.</li> </ul> <p>The <code>networks</code> section defines two networks: <code>db</code> and <code>mynetwork</code>. The networks are bridge driver type</p> <p>Then you can run <code>docker-compose up -d</code> and you should see the nginx forwarding our app and all our container like this :  <pre><code>fe86842a56e1   nginx:latest               \"/docker-entrypoint.\u2026\"   19 seconds ago   Up 18 seconds           0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, :::443-&gt;443/tcp\nd05f1ca65c2f   northwind_psql_app         \"uvicorn app:app --h\u2026\"   19 seconds ago   Up 18 seconds           80/tcp, 0.0.0.0:8000-&gt;8000/tcp, :::8000-&gt;8000/tcp                                                                  northwind_psql_app_1\n51553cc3b247   postgres:latest            \"docker-entrypoint.s\u2026\"   9 hours ago      Up 19 seconds           0.0.0.0:55432-&gt;5432/tcp, :::55432-&gt;5432/tcp                                                                        db\na76abdcbf8da   dpage/pgadmin4             \"/entrypoint.sh\"         9 hours ago      Up 19 seconds           80/tcp, 443/tcp, 0.0.0.0:5050-&gt;5050/tcp, :::5050-&gt;5050/tcp                                                         pgadmin\n</code></pre></p> <p>Congrats our <code>app</code> service is now running in HTTPS \ud83e\udd73</p>"},{"location":"docker/docker_install/","title":"Setting up Docker","text":"<p>The process of installing Docker on your local machine will depend on the operating system you are using. Docker provides installation packages for Windows, macOS, and Linux.</p>"},{"location":"docker/docker_install/#installing-docker-on-macos","title":"Installing Docker on MacOS","text":"<ol> <li> <p>Go to the official docker website and download the appropriate installation package for your operating system. Be aware of your chipset for example if your Apple machine is new install the version apple chip not intel (you can see that chip information if you go on the <code>little \uf8ff on the top left of your screen</code> &gt; <code>about my Mac</code>)</p> </li> <li> <p>Follow the installation instructions </p> </li> <li>Once Docker is successfully installed, open a terminal or command prompt and run the following command to verify that Docker is running: <pre><code>docker version\n</code></pre> If Docker is running correctly, you should see information about the Docker version, API version, and other details like this :  <pre><code>Client:\n Cloud integration: 1.0.14\n Version:           20.10.6\n API version:       1.41\n Go version:        go1.16.3\n Git commit:        370c289\n Built:             Fri Apr  9 22:46:57 2021\nOS/Arch:           darwin/amd64\n Context:           default\n Experimental:      true\nServer: Docker Engine - Community\n Engine:\n  Version:          20.10.6\n  API version:      1.41 (minimum version 1.12)\nGo version:       go1.13.15\n  Git commit:       8728dd2\n  Built:            Fri Apr  9 22:44:56 2021\nOS/Arch:          linux/amd64\n  Experimental:     false\ncontainerd:\n  Version:          1.4.4\n  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e\n runc:\n  Version:          1.0.0-rc93\n  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre></li> </ol>"},{"location":"docker/docker_install/#technical-informations-about-docker-version","title":"Technical informations about docker version","text":"<p>Just in case if you wondering what the output means \ud83e\udd13</p> <ul> <li>Client: This section shows the version and details of the Docker client that is running on your local machine. The client is responsible for issuing commands to the Docker daemon, which manages containers and images.<ul> <li>Cloud integration: This shows the version of the Docker Cloud integration plugin that is installed on your machine. Docker Cloud is a service that provides tools for managing Docker containers in the cloud.</li> <li>Version: This shows the version of the Docker client that is installed on your machine.</li> <li>API version: This shows the version of the Docker API that is supported by the client.</li> <li>Go version: This shows the version of the Go programming language that was used to compile the Docker client.</li> <li>Git commit: This shows the Git commit hash that was used to build the Docker client.</li> <li>Built: This shows the date and time that the Docker client was built.</li> <li>OS/Arch: This shows the operating system and processor architecture that the Docker client is running on.</li> <li>Context: This shows the default Docker context that is currently in use.</li> <li>Experimental: This shows whether experimental features are enabled on the Docker client.</li> </ul> </li> <li>Server: This section shows the version and details of the Docker daemon that is running on your local machine. The daemon is responsible for managing containers and images.<ul> <li>Engine: This shows the version of the Docker engine that is running on your machine.</li> <li>API version: This shows the version of the Docker API that is supported by the engine.</li> <li>Go version: This shows the version of the Go programming language that was used to compile the Docker engine.</li> <li>Git commit: This shows the Git commit hash that was used to build the Docker engine.</li> <li>Built: This shows the date and time that the Docker engine was built.</li> <li>OS/Arch: This shows the operating system and processor architecture that the Docker engine is running on.</li> <li>Experimental: This shows whether experimental features are enabled on the Docker engine.</li> <li>containerd: This shows the version and Git commit of containerd, which is the container runtime used by Docker.</li> <li>runc: This shows the version and Git commit of runc, which is the command-line tool used to run containers.</li> <li>docker-init: This shows the version and Git commit of docker-init, which is the initialization script used by Docker to start containers.</li> </ul> </li> </ul>"},{"location":"docker/docker_install/#how-docker-works-on-our-machine","title":"How Docker works on our machine","text":"<p>As you can see the output of the <code>docker version</code> command is divided into two sections: Client and Server. In the context of Docker, the Docker client and server are two separate components that work together to manage containers and images.</p> <p></p> <p>At the top, we have the client component, which runs on the host machine and interacts with the user. The client sends requests to the server component, which is hosted inside a Docker container.</p> <p>The Docker container is built from an image, which contains the application code and its dependencies. The image is created using a Dockerfile, which specifies the steps to build the image. The image is then pushed to a Docker registry, where it can be accessed by other team members or deployed to production.</p> <p>The Docker container runs on a Docker host, which is a machine that has Docker installed. The Docker host abstracts the underlying hardware and provides a consistent interface for running Docker containers.</p> <p>The Docker container is isolated from other containers and the host machine, which provides a secure and predictable environment for running the application.</p> <p>In this architecture, we can easily scale the server component by creating more Docker containers from the same image. We can also deploy the application to different environments, such as development, staging, and production, by using different Docker images and configurations.</p>"},{"location":"docker/docker_install/#docker-client","title":"Docker client","text":"<p>The Docker client is a command-line interface (CLI) tool that allows you to interact with the Docker daemon. The client sends commands to the daemon, which then executes those commands and manages the containers and images on your system. The Docker client can be used to build and run containers, manage images, and perform other Docker-related tasks.</p>"},{"location":"docker/docker_install/#docker-daemon","title":"Docker Daemon","text":"<p>The Docker server, also known as the Docker daemon, is a background process that manages the containers and images on your system. The daemon listens for commands from the Docker client, executes those commands, and manages the underlying infrastructure needed to run containers, such as networking and storage.</p> <p>The Docker client and server communicate with each other using the Docker API, which is a RESTful API that provides a standardized way to interact with Docker. When you run a command using the Docker client, such as \"docker run\", the client sends a request to the Docker daemon over the Docker API. The daemon then processes the request and executes the command.</p> <p>In summary, the Docker client is a tool for interacting with the Docker daemon, while the Docker daemon is a background process that manages the containers and images on your system. The client and daemon communicate with each other using the Docker API.</p>"},{"location":"docker/docker_intro/","title":"Introduction to Docker","text":"<p>Docker is an open-source platform for building, shipping, and running applications as containers. </p> <p>Docker solves the problem of \"it works on my machine but not in production\" by providing a consistent environment for running applications. </p> <p>Traditionally, developers would build applications on their local machines, which could have different operating systems, libraries, and dependencies than the production environment. This could lead to compatibility issues and errors when the application was deployed to production.</p> <p> </p> <p>With Docker, developers can package their applications and dependencies into a container, which provides a consistent environment for running the application. This means that the container can be run on any machine that has Docker installed, without worrying about differences in the underlying operating system or environment.</p> <p>By using Docker, developers can ensure that their applications will work the same way in development, testing, and production environments. This can help to reduce the risk of compatibility issues and errors when deploying applications to production.</p> <p>Docker also makes it easier to manage and scale applications. Containers can be quickly and easily deployed, scaled up or down, and updated, which helps to reduce the time and effort required to manage applications. This can help to improve the reliability and performance of applications, while also reducing costs and complexity.</p> <p>In summary, Docker provides a consistent and reliable way to package, deploy, and manage applications, which helps to solve the problem of \"it works on my machine but not in production\". By using Docker, developers can ensure that their applications will work the same way in all environments, which can help to improve the reliability and efficiency of application deployment.</p>"},{"location":"docker/docker_intro/#what-is-docker-and-why-use-it","title":"What is Docker and Why Use It?","text":"<p>Docker provides a number of benefits over traditional methods of deploying applications:</p> <ul> <li>Consistency : Docker provides a consistent environment for running your application, regardless of where it is being run. This means that you can build your application once, and then run it in any environment that has Docker installed, without worrying about differences in operating systems, libraries, or dependencies.</li> <li>Portability : Docker containers are lightweight and portable, which means that you can easily move them between machines, or even between different cloud providers. This makes it easy to deploy your application to different environments, such as development, staging, and production.</li> <li>Isolation : Docker containers provide a high degree of isolation between different applications, which reduces the risk of conflicts between different components of your application stack. This means that you can run multiple applications on the same machine, without worrying about interference between them.</li> <li>Resource Efficiency : Docker containers are lightweight and use fewer resources than traditional virtual machines, which means that you can run more containers on the same machine. This can result in significant cost savings for cloud-based applications.</li> </ul>"},{"location":"docker/docker_intro/#docker-vs-virtual-machines","title":"Docker VS Virtual Machines","text":"<p>Let's talk about the difference between a traditional virtual machine (VM) architecture and a containerized architecture for that let's take a look at this schema : </p> <p></p> <p>Starting with the VM architecture on the left, you can see that there is a physical server that hosts a hypervisor layer. The hypervisor layer creates multiple virtual machines, each of which has its own operating system (OS) and runs on top of the hypervisor layer. Each VM also has its own set of resources, such as CPU, memory, and storage, which are isolated from the other VMs.</p> <p>In contrast, the containerized architecture on the right does not have a hypervisor layer. Instead, it has a host operating system that runs on top of the physical server. On top of the host operating system, there is a container runtime, which manages the creation and management of containers. Each container shares the host operating system with other containers, but each container has its own isolated file system, network, and process space.</p> <p>Docker is a containerization technology that allows you to create, deploy, and manage containers. It provides a way to package and distribute software applications in a standardized and portable format, making it easy to move them from one environment to another. With Docker, you can create a Dockerfile that describes the dependencies and configuration of your application, and then use the Docker command-line interface to build, run, and manage containers based on that Dockerfile.</p> <p>Overall, Docker provides a lightweight and flexible alternative to traditional VMs, making it easier to develop, deploy, and scale applications.</p>"},{"location":"docker/docker_intro/#what-is-a-containers","title":"What is a Containers","text":"<p>Docker's use of the term \"container\" is inspired by the shipping industry. In the shipping industry, containers are standardized, self-contained units that can be easily transported between ships, trains, and trucks. These containers can hold a variety of goods and products, and they are designed to be easy to load and unload from transport vehicles.</p> <p>Similarly, in the context of software development, a container is a standardized, self-contained unit that can hold an application along with its dependencies and configurations. Like a shipping container, a software container can be easily transported between different environments, such as development, testing, and production.</p> <p>By using the term \"container\", Docker is emphasizing the portability and standardization of its technology, which is similar to the shipping industry's use of containers to transport goods and products between different locations.</p>"},{"location":"docker/docker_intro/#advantages-of-containerization","title":"Advantages of Containerization","text":"<p>Containerization provides several advantages over traditional deployment methods:</p> <ul> <li>Portability : Containers are self-contained units of software that can be easily moved between different environments.</li> <li>Scalability : Containers can be quickly and easily scaled up or down, depending on demand.</li> <li>Consistency: Containers provide a consistent environment for running applications, which makes it easier to manage and troubleshoot applications.</li> <li>Resource Efficiency : Containers use fewer resources than traditional virtual machines, which means that you can run more containers on the same hardware.</li> <li>Security : Containers provide a high degree of isolation between different applications, which helps to reduce the risk of security breaches.</li> </ul> <p>In summary, Docker provides a flexible and efficient way to package and deploy applications as containers. By using Docker, you can create consistent, portable, and scalable environments for running your applications, which can help to reduce costs and improve reliability.</p>"},{"location":"docker/docker_intro/#5-reasons-why-developers-should-consider-using-docker","title":"5 reasons why developers should consider using Docker","text":"<ul> <li>Consistent Development Environments: With Docker, developers can create a consistent environment for developing and testing applications. Docker allows developers to package an application along with all its dependencies, libraries, and configurations into a container. This ensures that the application will run the same way on any machine, regardless of the underlying operating system or environment.</li> <li>Easy Collaboration: Docker containers can be easily shared between developers, which makes it easier to collaborate on projects. Containers can be used to create a development environment that is identical across all team members, which helps to reduce the risk of compatibility issues and errors.</li> <li>Faster Application Development and Deployment: Docker makes it easier to develop and deploy applications by automating the process of packaging and deploying applications. Developers can quickly create and test new versions of an application in a container, and then deploy it to production with minimal effort.</li> <li>Improved Testing: Docker makes it easier to test applications by allowing developers to create multiple containers with different configurations and environments. This makes it easier to test applications in different scenarios, such as different operating systems, libraries, or dependencies.</li> <li>Resource Efficiency: Docker containers are lightweight and use fewer resources than traditional virtual machines, which means that developers can run more containers on the same machine. This can result in significant cost savings for cloud-based applications.</li> </ul>"},{"location":"docker/docker_network/","title":"What is Docker Networking?","text":"<p>Docker Networking allows you to connect Docker containers together so that they can communicate with each other. This is useful for building complex applications that are made up of multiple containers, each with its own functionality.</p> <p>Docker Networking also allows you to isolate containers from each other, providing an added layer of security. Additionally, Docker Networking makes it easy to connect containers to external networks, such as the internet, and to other Docker hosts.</p>"},{"location":"docker/docker_network/#docker-network-types","title":"Docker Network Types","text":"<p>Docker supports several types of network drivers that provide different ways to connect containers together. Here are some of the most common Docker network types:</p> <ul> <li>Bridge Network: The default network type in Docker, a bridge network is a private network that allows containers to communicate with each other using IP addresses. Containers on a bridge network can communicate with each other but are isolated from the host machine and external networks.</li> <li>Host Network: A host network allows containers to use the host machine's network stack, essentially giving them direct access to the host's network interfaces. This can provide better performance but may not be as secure as other network types.</li> <li>Overlay Network: An overlay network allows you to connect containers that are running on different Docker hosts. This is useful for building distributed applications that are made up of multiple Docker hosts.</li> <li>Macvlan Network: A macvlan network allows you to assign a MAC address to a container, essentially making it appear as though it is a physical machine on the network. This can be useful for running containers that require direct access to the physical network.</li> </ul>"},{"location":"docker/docker_network/#creating-a-docker-network","title":"Creating a Docker Network","text":"<p>Creating a Docker network is easy. You can use the docker network create command to create a new network: <pre><code>docker network create mynetwork\n</code></pre> This command creates a new Docker network with the name mynetwork.</p>"},{"location":"docker/docker_network/#attaching-containers-to-a-network","title":"Attaching Containers to a Network","text":"<p>To attach a container to a network, you can use the --network option when you start the container: <pre><code>docker run --name mycontainer --network mynetwork alpine sleep 3000\n</code></pre></p> <p>This command creates a new container with the name mycontainer and attaches it to the mynetwork network.</p>"},{"location":"docker/docker_network/#connecting-to-external-networks","title":"Connecting to External Networks","text":"<p>To connect a container to an external network, such as the internet, you can use the --network option to specify the host network: <pre><code>docker run --name mycontainer --network host alpine ping google.com\n</code></pre> This command creates a new container with the name mycontainer and attaches it to the host network. The container then uses the host machine's network stack to ping google.com.</p>"},{"location":"docker/docker_network/#create-containers-and-attach-them-to-a-network","title":"Create containers and attach them to a network","text":""},{"location":"docker/docker_network/#step-1-create-a-docker-network","title":"Step 1: Create a Docker Network","text":"<p>The first step is to create a Docker network that both containers will be attached to. This can be done using the docker network create command: <pre><code>docker network create mynetwork\n</code></pre></p>"},{"location":"docker/docker_network/#step-2-create-the-first-container","title":"Step 2: Create the First Container","text":"<p>Next, we'll create the first container and attach it to the mynetwork network. We'll use the docker run command to create the container: <pre><code>docker run --name container1 --network mynetwork alpine sleep 3000\n</code></pre></p> <p>This command creates a new container with the name container1, attaches it to the mynetwork network, and starts the sleep command to keep the container running for 3000 seconds.</p>"},{"location":"docker/docker_network/#step-3-create-the-second-container","title":"Step 3: Create the Second Container","text":"<p>Next, we'll create the second container and attach it to the mynetwork network. We'll use the docker run command again: <pre><code>docker run --name container2 --network mynetwork alpine sleep 3000\n</code></pre> Same thing, this command creates a new container with the name <code>container2</code>, attaches it to the mynetwork network, and starts the sleep command to keep the container running for 3000 seconds.</p>"},{"location":"docker/docker_network/#step-4-create-the-third-container","title":"Step 4: Create the Third Container","text":"<p>Now, let's create a third container that is not attached to the mynetwork network. We'll use the docker run command to create the container: <pre><code>docker run --name container3 alpine sleep 3000\n</code></pre> This command creates a new container with the name <code>container3</code> and starts the sleep command to keep the container running for 3000 seconds. Since we did not specify a network for this container, it will be attached to the default bridge network.</p>"},{"location":"docker/docker_network/#step-5-ping-one-container-from-the-other","title":"Step 5: Ping One Container from the Other","text":""},{"location":"docker/docker_network/#what-is-ping","title":"What is <code>ping</code>","text":"<p>The <code>ping</code> command is commonly used to test the availability and responsiveness of network devices, such as servers or routers. It can help diagnose network connectivity issues, such as packet loss or latency.</p> <p>When you run the <code>ping</code> command, it will send packets of data to the specified destination, and display the results in the terminal. The output will typically include statistics about the packet transmission, such as the number of packets sent and received, the round-trip time (RTT) for each packet, and any errors or packet loss that occurred during the transmission.</p> <p>Here's an example of running the ping command: <pre><code>ping google.com\n</code></pre></p> <p>This command sends packets of data to the Google.com domain name, and displays the results in the terminal. The output will show the RTT for each packet, as well as other statistics about the packet transmission.</p>"},{"location":"docker/docker_network/#ping-container1-from-container2","title":"Ping  <code>container1</code> from <code>container2</code>","text":"<p>Now that both containers are running and attached to the same network, we can confirm that they can communicate with each other. We'll do this by pinging <code>container1</code> from <code>container2</code>: <pre><code>docker exec container2 ping container1\n</code></pre> This command uses the docker exec command to run the ping container1 command inside container2. If the two containers are able to communicate with each other, you should see output similar to the following: <pre><code>PING container1 (172.19.0.2): 56 data bytes\n64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.091 ms\n64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.111 ms\n</code></pre> If you see this output, it means that the two containers are able to communicate with each other over the <code>mynetwork</code> network.</p> <p>Now, let's try to ping <code>container1</code> from <code>container3</code>, which is not attached to the <code>mynetwork</code> network: <pre><code>docker exec container3 ping container1\n</code></pre> This command uses the docker exec command to run the ping container1 command inside <code>container3</code>. Since <code>container3</code> is not attached to the mynetwork network, it should not be able to communicate with container1. You should see output similar to the following: <pre><code>ping: bad address 'container1'\n</code></pre> This output confirms that <code>container3</code> is not able to communicate with <code>container1</code>.</p>"},{"location":"docker/docker_network/#wrap-up","title":"Wrap-up","text":"<p>Docker Networking is a powerful feature that allows you to connect Docker containers together so that they can communicate with each other. By mastering Docker Networking, you can build complex applications that are made up of multiple containers, each with its own functionality. You can also isolate containers from each other, connect them to external networks, and build distributed applications that are made up of multiple Docker hosts.</p>"},{"location":"docker/docker_python_app/","title":"Building a Docker Image for your Python App","text":"<p>Docker provides a convenient way to package your Python applications and dependencies into a self-contained image that can be run on any machine. In this tutorial, we will walk you through the process of building a Docker image for a standard Python app.</p>"},{"location":"docker/docker_python_app/#common-problems-if-you-choose-to-not-use-docker","title":"Common problems if you choose to NOT use Docker","text":"<p>Here are three common problems you might encounter if you choose not to use Docker for your Python script deployment:</p> <ul> <li>Dependency Conflicts: One of the biggest challenges with Python application deployment is managing dependencies. Without Docker, it can be difficult to ensure that your Python application and its dependencies will work correctly on different machines and environments. This can result in dependency conflicts, broken code, and lost productivity.</li> <li>Inconsistency: Another issue with deploying Python applications without Docker is inconsistency. Different machines and environments can have different versions of Python, different system libraries, and different configurations. This can make it difficult to reproduce and debug issues, and can result in code that works on some machines but not on others.</li> <li>Limited Portability: Without Docker, it can be difficult to move your Python application between different machines and environments. This can limit your ability to scale and deploy your application effectively, and can result in lost opportunities and increased costs.</li> </ul> <p>Overall, while it is possible to deploy Python applications without Docker, doing so can lead to dependency conflicts, inconsistency, and limited portability. By using Docker to package your Python application and its dependencies into a self-contained container, you can ensure that your application runs consistently and reliably across different machines and environments.</p>"},{"location":"docker/docker_python_app/#why-we-use-docker-to-run-python-scripts-in-containers","title":"Why we use Docker to run Python scripts in containers:","text":"<ul> <li>Isolation: Running a Python script in a Docker container provides a degree of isolation between the script and the host machine, which helps to minimize conflicts and dependencies with other applications or processes.</li> <li>Consistency: By running a Python script in a Docker container, you can ensure that the environment in which the script runs is consistent across different machines and environments. This helps to avoid the \"it works on my machine\" problem and makes it easier to reproduce and debug issues.</li> <li>Portability: Docker containers are self-contained units that can be easily moved between different machines and environments. This makes it easy to deploy and scale Python scripts in a variety of settings, from local development to production servers.</li> <li>Efficiency: Docker containers are lightweight and efficient, which means that they can be deployed quickly and consume minimal resources. This makes them an ideal choice for running Python scripts that need to be deployed quickly or scaled up or down rapidly.</li> </ul>"},{"location":"docker/docker_python_app/#creating-a-dockerfile-for-our-python-app","title":"Creating a Dockerfile for our python app","text":"<p>The first step in building a Docker image for your Python app is to create a Dockerfile. The Dockerfile is a text file that contains a set of instructions for building the Docker image. Here's an example Dockerfile for a Python app: <pre><code># Use an official Python runtime as a parent image\nFROM python:3.9\n# Set the working directory to /app\nWORKDIR /app\n# Copy the current directory contents into the container at /app\nCOPY . /app\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Make port 80 available to the world outside this container\nEXPOSE 80\n# Define environment variable\nENV NAME World\n\n# Run app.py when the container launches\nCMD [\"python\", \"app.py\"]\n</code></pre></p>"},{"location":"docker/docker_python_app/#lets-see-how-this-file-works-line-by-line","title":"Let's see how this file works line by line","text":""},{"location":"docker/docker_python_app/#defining-the-base-image-and-environment","title":"Defining the base image and environment","text":"<p>The first line in the Dockerfile specifies the base image to use for the container. In this case, we are using the official <code>Python 3.9</code> image. <pre><code>FROM python:3.9\n</code></pre></p> <p>Next, we set the working directory to \"/app\" inside the container. <pre><code>WORKDIR /app\n</code></pre> This is the directory where we will copy our application code and dependencies.</p>"},{"location":"docker/docker_python_app/#installing-dependencies-and-copying-source-code","title":"Installing dependencies and copying source code","text":"<p>Next, we copy our application code and dependencies into the container. This is done using the <code>COPY</code> command. <pre><code>COPY . /app\n</code></pre> This command copies the contents of the current directory into the \"/app\" directory inside the container.</p> <p>We then install any dependencies that are needed for our application. This is done using the \"RUN\" command. <pre><code>RUN pip install --no-cache-dir -r requirements.txt\n</code></pre> This command reads the requirements.txt file and installs any dependencies listed in the file.</p>"},{"location":"docker/docker_python_app/#configuring-the-app-and-exposing-ports","title":"Configuring the app and exposing ports","text":"<p>Next, we configure our application by setting any environment variables and exposing any necessary ports. <pre><code>EXPOSE 80\nENV NAME World\n</code></pre> In this example, we are exposing port 80 and setting an environment variable named \"NAME\" to \"World\".</p> <p>Finally, we specify the command to run when the container is launched. <pre><code>CMD [\"python\", \"app.py\"]\n</code></pre></p> <p>This command specifies that the \"app.py\" file should be executed when the container is launched.</p>"},{"location":"docker/docker_python_app/#building-the-docker-image","title":"Building the Docker image","text":"<p>Now that we have created our Dockerfile, we can build our Docker image.  To do this, we use the <code>docker build</code> command like this :  <pre><code>docker build -t my-python-app .\n</code></pre></p> <p>This command tells Docker to build an image with the name <code>my-python-app</code> using the Dockerfile in the current directory (.) </p>"},{"location":"docker/docker_python_app/#running-the-docker-container","title":"Running the Docker container","text":"<p>Once we have built our Docker image, we can run it using the <code>docker run</code> command :  <pre><code>docker run -p 4000:80 my-python-app\n</code></pre> This command tells Docker to run the <code>my-python-app</code> image and map port <code>4000</code> on the host machine to port <code>80</code> inside the container.</p>"},{"location":"docker/docker_python_app/#summary-of-the-most-common-dockerfile-commands","title":"Summary of the most common Dockerfile commands","text":"<p>These commands can be combined in various ways to create a Dockerfile for your specific application. By using Dockerfile commands, you can define the steps needed to build a Docker image and run a Docker container for your application.</p> <p>Most common Dockerfile commands: </p> <ul> <li><code>FROM</code>: Specifies the base image for the Docker image.</li> <li><code>RUN</code>: Executes a command during the build process, such as installing dependencies or running tests.</li> <li><code>COPY</code> or <code>ADD</code>: Copies files or directories from the host machine into the Docker image.</li> <li><code>WORKDIR</code>: Sets the working directory inside the Docker image.</li> <li><code>EXPOSE</code>: Exposes a port for the Docker container.</li> <li><code>ENV</code>: Sets an environment variable inside the Docker image.</li> <li><code>CMD</code> or <code>ENTRYPOINT</code>: Specifies the command to run when the Docker container starts.</li> </ul> <p> </p> <p>These commands can be combined in various ways to create a Dockerfile for your specific application. By using Dockerfile commands, you can define the steps needed to build a Docker image and run a Docker container for your application.</p>"},{"location":"docker/docker_python_app/#run-a-fastapi-hello-world-python-app-into-a-container","title":"Run a FastAPI \"Hello World\" Python app into a container","text":"<p>Create a new Python file named <code>main.py</code> with the following code :  main.py<pre><code>from fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/\")\nasync def root():\nreturn {\"message\": \"Hello World!\"}\n</code></pre></p> <p>Create a new file named <code>Dockerfile</code> in the same directory with the following contents: <pre><code>FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8-slim\nCOPY ./app /app\n\nEXPOSE 80\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n</code></pre></p> <p>This Dockerfile uses the <code>tiangolo/uvicorn-gunicorn-fastapi</code> base image, copies the app directory (which contains main.py) into the container, exposes port <code>80</code>, and sets the <code>CMD</code> to run the uvicorn server with the <code>main:app</code> parameter.</p> <p>Build the Docker image using the following command: <pre><code>docker build -t fastapi-demo .\n</code></pre> This command builds the Docker image and tags it with the name fastapi-demo.</p> <p>Run the Docker container using the following command: <pre><code>docker run -p 80:80 fastapi-demo\n</code></pre> This command starts the Docker container and maps port 80 on the host machine to port 80 inside the container.</p> <p>Make sure the container is up and the API is running with the command :  <pre><code>docker ps </code></pre></p> <p>If you see the container UP and running, then you can open your web browser and navigate to http://localhost:80/. You should see the message \"Hello World!\" displayed in your browser \ud83e\udd73</p>"},{"location":"docker/docker_python_app/#why-0000-and-not-localhost","title":"Why <code>0.0.0.0</code> and not <code>localhost</code>","text":"<p>When setting up a Docker container, it's common to bind the container's internal port to a port on the host machine so that the container's services can be accessed from the outside. When specifying the IP address for the --host parameter in the uvicorn command, you have a choice between using <code>localhost</code> and <code>0.0.0.0</code></p> <p>Using localhost as the IP address for the --host parameter means that the server will only accept requests coming from within the container itself. This can be useful if you want to restrict access to the server to only the container itself.</p> <p>However, if you want to allow external access to the server (i.e., from the host machine or other machines on the same network), you should use <code>0.0.0.0</code> as the IP address for the --host parameter. This tells the server to accept requests from any IP address.</p> <p>So, in a FastAPI application context for a Docker container, using <code>0.0.0.0</code> as the IP address for the --host parameter allows the container's services to be accessed from the host machine or other machines on the same network, while using localhost would restrict access to only the container itself.</p>"},{"location":"docker/docker_python_app/#wrap-up","title":"Wrap-up","text":"<p>In summary, building a Docker image for your Python app involves creating a Dockerfile, defining the base image and environment, installing dependencies and copying source code, configuring the app and exposing ports, and finally building and running the Docker image. </p>"},{"location":"docker/docker_volume/","title":"Docker Volumes","text":""},{"location":"docker/docker_volume/#what-are-docker-volumes","title":"What are Docker Volumes?","text":"<p>Docker volumes are a way to persist data outside of a container's file system. When you create a Docker volume, you create a new volume object that can be attached to one or more containers. Data can be written to or read from the volume, and the data will persist even if the container is removed or recreated.</p>"},{"location":"docker/docker_volume/#using-a-docker-volume-for-a-hello-world-fastapi-app","title":"Using a Docker Volume for a Hello World FastAPI App","text":"<p>Let's say you have a simple Hello World FastAPI app that you want to run in a Docker container. Here's an example of what the Dockerfile might look like:</p> <pre><code>FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8\nWORKDIR /app\nCOPY ./app /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n</code></pre> <p>This Dockerfile uses the <code>tiangolo/uvicorn-gunicorn-fastapi</code> base image and copies the app directory into the <code>/app</code> directory in the container.</p> <p>Next, it runs the pip command to install the packages listed in the requirements.txt file. The <code>--no-cache-dir</code> flag is used to ensure that the packages are installed from scratch, rather than using any cached packages.</p> <p>Finally, it sets the command to start the app using the Uvicorn server on port <code>80</code>.</p> <p>Here's the code for the <code>app.py</code> file: <pre><code>from fastapi import FastAPI\napp = FastAPI()\n@app.get(\"/\")\ndef read_root():\nreturn {\"Hello\": \"World\"}\n</code></pre> and the <code>requirements.txt</code> file :  <pre><code>fastapi==0.68.1\nuvicorn==0.15.0\n</code></pre></p>"},{"location":"docker/docker_volume/#why-using-volume","title":"Why using volume","text":"<p>When you create a Docker volume and attach it to a container, it's like putting a bookmark from the container to a local folder on your host machine.</p> <p></p> <p>Just like a bookmark in a web browser, a volume allows you to quickly access a specific location in the container's file system, without having to navigate through all of the directories manually.</p> <p>With a volume, you can also persist data outside of the container's file system. This can be useful if you need to share data between multiple containers, or if you need to keep data separate from the container image itself.</p> <p>Overall, volumes are a powerful tool in Docker that allow you to manage and persist data in a flexible and efficient way.</p>"},{"location":"docker/docker_volume/#add-volume-to-docker-run","title":"Add volume to <code>docker run</code>","text":"<p>With this Dockerfile, you can build and run the container using the following commands:</p> <pre><code>docker build -t myimage .\n\ndocker run -d --name mycontainer -p 8000:80 -v $(pwd):/app myimage\n</code></pre> <p>When you run this app in a Docker container, you can use a Docker volume to mount the <code>app.py</code> file into the container at runtime, rather than copying it into the container at build time. This has a few advantages:</p> <ul> <li>You can make changes to the app.py file without having to rebuild the entire Docker image.</li> <li>You can keep the app code and the container image separate, which can make it easier to manage and update the app over time.</li> </ul>"},{"location":"sql/01_sql_intro/","title":"Introduction","text":"<p>Welcome to the SQL and Python for Data Analysis and Database Development course! In this course, you will learn how to use SQL and Python to work with databases and analyze data. Databases are an essential part of modern computing, and they are used in everything from social media applications to e-commerce websites to scientific research.</p>"},{"location":"sql/01_sql_intro/#why-database","title":"Why database ?","text":"<p>Imagine you work for a large online retailer, and your company needs to manage thousands of products, customers, and orders every day. You could store this data in an Excel spreadsheet, but as your company grows, this becomes increasingly difficult and time-consuming. You might have dozens or even hundreds of spreadsheets, each containing different pieces of data, making it difficult to find the information you need quickly. In addition, spreadsheets are not ideal for handling large amounts of data, and they can become slow and unwieldy as the size of the dataset grows.</p> <p>This is where databases come in. A database is an organized collection of data that is designed to be easy to access, manage, and update. With a database, you can store all your company's data in one place, making it easy to find the information you need quickly. Databases are also designed to handle large amounts of data efficiently, so you can work with massive datasets without running into performance issues.</p>"},{"location":"sql/01_sql_intro/#course-goals","title":"Course goals :","text":"<p>In this course, we will be using the Structured Query Language (SQL) to work with databases and python. SQL is a powerful language that allows you to manipulate and analyze data stored in databases. We will also be using Python, specifically the SQLAlchemy library, to connect to databases, query data, and create tables. By the end of this course, you will have a solid understanding of SQL concepts and practical experience using SQL and Python to manipulate and analyze data.</p>"},{"location":"sql/01_sql_intro/#technical-goals","title":"Technical goals","text":"<p>Here are some main goals as a developer for mastering databases:</p> <ul> <li>Understanding data modeling: The ability to design and implement effective data models is crucial for building scalable and efficient databases. This includes knowledge of different types of databases, data structures, and normalization techniques.</li> <li>Proficiency in SQL: SQL (Structured Query Language) is the standard language used for querying, manipulating, and managing data in databases. As a developer, it is important to have a strong understanding of SQL and its various functions.</li> <li>Database administration skills: Database administration involves tasks such as installing, configuring, and maintaining databases. A developer who is proficient in database administration can optimize performance, troubleshoot issues, and ensure the security of their databases.</li> <li>Knowledge of database architecture: Understanding the architecture of databases and how they interact with other systems is essential for building and integrating applications with databases.</li> <li>Familiarity with database tools and frameworks: There are many tools and frameworks available to developers for working with databases, including ORMs (Object-Relational Mappers), and database management systems. Familiarity with these tools and frameworks can help developers work more efficiently and effectively with databases.</li> </ul>"},{"location":"sql/01_sql_intro/#table-of-content","title":"Table of content","text":"<ol> <li>Introduction<ul> <li>Explanation of course objectives and overview of SQL</li> <li>Overview of the main topics that will be covered in the course and goals</li> </ul> </li> <li>What is a Database?<ul> <li>Explanation of what a database is and why they are important</li> <li>Overview of different types of databases and their uses</li> </ul> </li> <li>Tables &amp; Keys<ul> <li>Explanation of tables and keys in databases</li> <li>Introduction to primary and foreign keys</li> <li>Explanation of how to create tables</li> </ul> </li> <li>SQL Basics<ul> <li>Explanation of SQL language and its uses</li> <li>Overview of different SQL commands</li> </ul> </li> <li>MySQL Windows Installation<ul> <li>Explanation of how to install MySQL on Windows</li> <li>Overview of installation steps and potential issues to be aware of</li> </ul> </li> <li>MySQL Mac Installation<ul> <li>Explanation of how to install MySQL on a Mac</li> <li>Overview of installation steps and potential issues to be aware of</li> </ul> </li> <li>Creating Tables<ul> <li>In-depth look at how to create tables</li> <li>Overview of different data types and how to use them</li> <li>Explanation of primary and foreign keys</li> </ul> </li> <li>Inserting Data<ul> <li>Explanation of how to insert data into tables</li> <li>Overview of different insert commands and syntax</li> </ul> </li> <li>Constraints<ul> <li>Explanation of constraints and their importance in databases</li> <li>Overview of different types of constraints and how to use them</li> </ul> </li> <li>Update &amp; Delete<ul> <li>Explanation of how to update and delete data in tables</li> <li>Overview of different update and delete commands and syntax</li> </ul> </li> <li>Basic Queries<ul> <li>Introduction to basic queries in SQL</li> <li>Overview of different select commands and syntax</li> </ul> </li> <li>Company Database Intro<ul> <li>Explanation of a company database</li> <li>Overview of how it can be used and why it's important</li> </ul> </li> <li>Creating Company Database<ul> <li>In-depth look at how to create a company database</li> <li>Explanation of different tables and their relationships</li> </ul> </li> <li>More Basic Queries<ul> <li>In-depth look at more basic queries in SQL</li> <li>Explanation of how to use different clauses and functions</li> </ul> </li> <li>Functions<ul> <li>Introduction to functions in SQL</li> <li>Overview of different types of functions and how to use them</li> </ul> </li> <li>Wildcards<ul> <li>Explanation of wildcards in SQL</li> <li>Overview of different wildcard characters and their uses</li> </ul> </li> <li>Union<ul> <li>Explanation of union in SQL</li> <li>Overview of how to use union to combine data</li> </ul> </li> <li>Joins<ul> <li>Explanation of joins in SQL</li> <li>Overview of different types of joins and how to use them</li> </ul> </li> <li>Nested Queries<ul> <li>Explanation of nested queries in SQL</li> <li>Overview of how to use subqueries</li> </ul> </li> <li>On Delete<ul> <li>Explanation of on delete in SQL</li> <li>Overview of how to use on delete to maintain data integrity</li> </ul> </li> <li>Triggers<ul> <li>Introduction to triggers in SQL</li> <li>Overview of how to use triggers to automate tasks</li> </ul> </li> <li>ER Diagrams Intro<ul> <li>Explanation of ER diagrams and their importance</li> <li>Overview of how to use ER diagrams to visualize data</li> </ul> </li> <li>Designing an ER Diagram<ul> <li>In-depth look at how to design an ER diagram</li> <li>Explanation of different entities, attributes, and relationships</li> </ul> </li> <li>Converting ER Diagrams to Schemas<ul> <li>Explanation of how to convert ER diagrams to database schemas</li> <li>Overview of how to create tables and relationships based on the ER diagram</li> </ul> </li> <li>Quick review Python<ul> <li>Explanation of what Python is and why it's useful for data analysis</li> <li>Overview of Python data structures and functions</li> </ul> </li> <li>Introduction to SQLAlchemy<ul> <li>Explanation of what SQLAlchemy is and its benefits for working with databases</li> <li>Overview of SQLAlchemy concepts and how they relate to SQL</li> </ul> </li> <li>Connecting to Databases with Python<ul> <li>Explanation of how to connect to a database using Python and SQLAlchemy</li> <li>Overview of different types of database connections and their uses</li> </ul> </li> <li>Creating Tables with Python<ul> <li>Explanation of how to create tables in a database using Python and SQLAlchemy</li> <li>Overview of different data types and how to use them</li> </ul> </li> <li>Inserting Data with Python<ul> <li>Explanation of how to insert data into tables using Python and SQLAlchemy</li> <li>Overview of different insert commands and syntax</li> </ul> </li> <li>Querying Data with Python<ul> <li>Explanation of how to query data from tables using Python and SQLAlchemy</li> <li>Overview of different types of queries and their uses</li> </ul> </li> <li>Updating and Deleting Data with Python<ul> <li>Explanation of how to update and delete data in tables using Python and SQLAlchemy</li> <li>Overview of different update and delete commands and syntax</li> </ul> </li> <li>Advanced Queries with Python<ul> <li>In-depth look at advanced querying techniques using Python and SQLAlchemy</li> <li>Explanation of how to use joins, subqueries, and other advanced SQL features</li> </ul> </li> <li>Working with Large Datasets in Python<ul> <li>Explanation of how to work with large datasets in Python and SQLAlchemy</li> <li>Overview of different techniques for managing and processing large amounts of data</li> </ul> </li> <li>ORM (Object-Relational Mapping) with SQLAlchemy<ul> <li>Introduction to ORM and how it can be used to map Python objects to database tables</li> <li>Overview of how to use SQLAlchemy to implement ORM</li> </ul> </li> <li>SQLAlchemy and Flask/FastAPI<ul> <li>Explanation of how to use SQLAlchemy with Flask/FastAPI, a popular web framework</li> <li>Overview of how to integrate SQLAlchemy and Flask/FastAPI for web development</li> </ul> </li> <li>Conclusion<ul> <li>Summary of the main topics covered in the course</li> <li>Next steps for further learning in SQL and Python for data analysis and database development.</li> </ul> </li> </ol> <p>Databases are a critical component of almost every modern website or application, as they provide the necessary infrastructure for storing and organizing large volumes of data. From social media platforms to e-commerce websites, databases help manage user information, product catalogs, transaction records, and more.</p> <p>As a developer, understanding databases is therefore an essential skill that can open many doors in your career. Being proficient in databases will enable you to build and maintain robust, scalable, and secure systems that can handle vast amounts of data efficiently. Moreover, with the increasing demand for data-driven decision-making, businesses are relying more and more on skilled database developers to help them extract insights from their data.</p> <p>So, whether you're building a simple web application or a large-scale enterprise system, having a solid understanding of databases will undoubtedly be an asset in your career.</p> <p>Let's get started \ud83e\udd73 </p>"},{"location":"sql/02_db_kesako/","title":"What is a Database ?","text":"<p>A database is an organized collection of data that is designed to be easy to access, manage, and update. Databases are used in a wide range of applications, from social media platforms to scientific research to financial systems. They are essential for storing and managing large amounts of data in a way that makes it easy to find, update, and retrieve the information you need quickly.</p>"},{"location":"sql/02_db_kesako/#some-examples","title":"Some examples","text":"<p>One of the simplest examples of a database is an address book. Think about the contacts list on your phone. You have a list of people you know, along with their phone numbers, email addresses, and other details. This list is essentially a simple database, with each contact representing a record in the database. You can easily search for a contact by name, update their information, or delete a contact when you no longer need it.</p> <p>Another example of a database is an online store. When you shop online, you browse through a catalog of products, add items to your cart, and then complete your purchase. Behind the scenes, the online store is using a database to store information about the products, customers, and orders. When you search for a product, the database is used to find all the relevant information about that product, including the price, description, and availability. When you complete your purchase, the database is updated with information about the order, including the items you bought, the shipping address, and the payment method.</p>"},{"location":"sql/02_db_kesako/#types-of-databases","title":"Types of Databases","text":"<p>There are many different types of databases, each with its own strengths and weaknesses. Some of the most common types of databases include:</p> <ul> <li>Relational databases: These databases organize data into tables with columns and rows, similar to a spreadsheet. They are the most common type of database and are used in many different applications.</li> <li>NoSQL databases: These databases are designed to handle large amounts of unstructured or semi-structured data. They are commonly used in big data applications, such as social media analytics and scientific research.</li> <li>Object-oriented databases: These databases store data as objects, which can be manipulated using object-oriented programming techniques. They are commonly used in software development and data modeling.</li> </ul> <p>In this course, we will be focusing on relational databases, specifically MySQL, which is a popular open-source database management system. We will also introduce the concept of Object Relational Mapping (ORM) using Python and the SQLAlchemy library. </p> <p>By the end of the course, you will have a solid understanding of the different types of databases and when to use them, as well as practical experience working with relational databases and SQL.</p>"},{"location":"sql/02_db_kesako/#examples-of-day-to-day-use-cases-for-each-type-of-database","title":"Examples of day-to-day use cases for each type of database","text":""},{"location":"sql/02_db_kesako/#relational-databases","title":"Relational databases","text":"<ul> <li>Customer database example : A business might use a relational database to keep track of customer information, such as their name, contact details, and purchase history. They could then use this information to target customers with personalized marketing campaigns based on their previous purchases.</li> <li>Inventory management example : A store might use a relational database to manage their inventory, with one table for products and another table for suppliers. They could then use SQL queries to quickly retrieve information on which products are in stock, which products are selling quickly, and which suppliers they need to contact to restock their inventory.</li> <li>Employee scheduling example : A company might use a relational database to manage employee schedules, with one table for employees and another table for shifts. They could then use SQL queries to quickly retrieve information on which employees are available to work on a particular day or time, and which shifts still need to be filled.</li> </ul>"},{"location":"sql/02_db_kesako/#nosql-databases","title":"NoSQL databases","text":"<ul> <li>Social media analytics: Social media platforms like Facebook and Twitter use NoSQL databases to store and analyze massive amounts of user data, such as likes, comments, and shares. This allows them to quickly retrieve and analyze user data to provide better ad targeting and personalized content.</li> <li>Internet of Things (IoT) devices: IoT devices like smart thermostats and security cameras generate a huge amount of data, which can be stored and analyzed in NoSQL databases. This allows manufacturers to track device usage patterns, identify and fix bugs, and improve device performance over time.</li> <li>Gaming: Many video games use NoSQL databases to store player data, such as character stats and in-game achievements. This allows players to continue their game progress across different devices, and enables game developers to quickly retrieve and analyze player data to identify areas for improvement.</li> </ul>"},{"location":"sql/02_db_kesako/#object-oriented-databases","title":"Object-oriented databases","text":"<ul> <li>Geolocation data: Companies that rely on geolocation data, such as mapping and navigation services, often use object-oriented databases to store and retrieve this data. This allows them to quickly retrieve and analyze large amounts of geolocation data in real-time.</li> <li>E-commerce: An e-commerce website might use an object-oriented database to store and manage product information, such as product images and descriptions. This allows them to easily update and manage product information across multiple platforms, such as their website, mobile app, and social media.</li> <li>Medical records: Hospitals and healthcare providers often use object-oriented databases to manage patient medical records, which can include a wide range of data types, such as images, test results, and diagnoses. This allows healthcare providers to easily access and update patient information, and can help improve patient care and outcomes.</li> </ul> <p>In this part we will focus only on relational databases. </p>"},{"location":"sql/02_db_kesako/#how-to-interact-with-databases-mysql-client-and-cli","title":"How to interact with databases : MySQL client and CLI","text":"<p>Think of a database like a big organized warehouse full of information. In order to get information from the warehouse or add information to it, we need a way to talk to it. </p> <p>That's where the MySQL client comes in. It's like the messenger that we use to talk to the warehouse, and it allows us to read or update information stored in the database.</p> <p>We use a command line interface (CLI) to interact with the MySQL client, which allows us to send specific commands to the database. A command-line interface (CLI) is a text-based interface used to interact with a computer's operating system or software by typing commands in a terminal window. It allows you to perform various tasks such as managing files and directories, executing programs, and interacting with databases, by entering commands and receiving text-based output.</p> <p>In the context of MySQL, the CLI is a tool that enables you to interact with a MySQL database from a terminal window or a graphic interface by typing SQL commands. This means you can create, modify, and query your databases without using a graphical user interface. The CLI is a powerful tool that gives you fine-grained control over your database, but it requires some knowledge of SQL commands and syntax to use effectively.</p>"},{"location":"sql/02_db_kesako/#vocabulary","title":"Vocabulary","text":"<p>Here's an additional point on the differences between MySQL client, server, and SQL:</p> <ul> <li>MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases.</li> <li>MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases.</li> <li>SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases.</li> </ul>"},{"location":"sql/03_table/","title":"Tables &amp; Keys","text":"<p>In a database, a table is a collection of related data that is organized into rows and columns. Tables are the primary way to store data in a relational database management system (RDBMS). In order to organize data effectively, tables are structured with columns that define the data that can be stored in each row.</p>"},{"location":"sql/03_table/#keys","title":"Keys","text":"<p>Keys are an important concept in database design. They are used to ensure data integrity and to establish relationships between tables. There are several types of keys in a database:</p> <ul> <li>Primary Key: A primary key is a column or set of columns that uniquely identifies each row in a table. The primary key is used to enforce data integrity and to ensure that there are no duplicate rows in the table.</li> <li>Foreign Key: A foreign key is a column or set of columns that refers to the primary key of another table. It is used to establish a relationship between two tables.</li> <li>Composite Key: A composite key is a combination of two or more columns that together uniquely identify each row in a table.</li> </ul>"},{"location":"sql/03_table/#examples-of-social-security-number","title":"Examples of social security number","text":"<ul> <li>Primary Key: A primary key is a unique identifier for a record in a table. It is used to ensure that each record in the table is unique and can be easily identified. For example, a person's social security number (SSN) can be used as a primary key in a table of customer data to ensure that each customer is unique and can be easily searched for.</li> <li>Foreign Key: A foreign key is used to link two tables together in a relational database. It is a field in one table that refers to the primary key in another table. For example, a customer's order history can be linked to their customer record using a foreign key. The foreign key in the order history table would refer to the primary key in the customer table, allowing for easy retrieval of all orders associated with a particular customer.</li> <li>Composite Key: A composite key is a key that consists of more than one field. It is used to ensure that a combination of fields in a record is unique. For example, in a table of product inventory, a combination of the product name and the manufacturer's part number could be used as a composite key to ensure that each product is unique and can be easily searched for.</li> </ul>"},{"location":"sql/03_table/#examples-of-social-media-database","title":"Examples of social media database","text":"<ul> <li>Primary Key: In a social media website's database, each user's unique username or email address can be used as a primary key to identify and manage their account. This ensures that each user has a unique identifier, making it easy for the website to maintain user data, track user activity, and provide personalized content.</li> <li>Foreign Key: In a hospital's database, a patient's medical record can be linked to their lab results using a foreign key. The foreign key would refer to the primary key in a table of lab test results, allowing doctors to easily access each patient's test results and track their medical history.</li> <li>Composite Key: In a hotel's database, a room reservation can be linked to a specific guest's booking using a composite key consisting of the guest's name and reservation number. This ensures that each guest has a unique reservation and allows the hotel to easily track each guest's room preference and check-in/check-out dates.</li> </ul>"},{"location":"sql/03_table/#creating-tables","title":"Creating Tables","text":"<p>Creating a table is the first step in building a database. The syntax for creating a table varies depending on the specific database management system being used. Here's an example of how to create a simple table with a primary key:</p> <pre><code>CREATE TABLE employees (\nid INT PRIMARY KEY,\nfirst_name VARCHAR(50),\nlast_name VARCHAR(50),\nage INT\n);\n</code></pre> <p>In this example, we have created a table called employees with four columns: <code>id</code>, <code>first_name</code>, <code>last_name</code>, and <code>age</code>. The id column is designated as the primary key for the table.</p> <p>To create a table with a foreign key, we first need to create the primary key in the table it will reference, and then add the foreign key to the table we're creating. Here's an example:</p> <pre><code>CREATE TABLE departments (\nid INT PRIMARY KEY,\nname VARCHAR(50)\n);\nCREATE TABLE employees (\nid INT PRIMARY KEY,\nfirst_name VARCHAR(50),\nlast_name VARCHAR(50),\nage INT,\ndepartment_id INT,\nFOREIGN KEY (department_id) REFERENCES departments(id)\n);\n</code></pre> <p>In this example, we have created two tables - <code>employees</code> and <code>departments</code>. The <code>departments</code> table has two columns - <code>id</code> and <code>name</code>, with <code>id</code> designated as the primary key. The <code>employees</code> table has five columns - <code>id</code>, <code>first_name</code>, <code>last_name</code>, <code>age</code>, and <code>department_id</code>. The <code>id</code> column is the primary key, and the <code>department_id</code> column is a foreign key that references the <code>id</code> column in the <code>departments</code> table.</p> <p>By using tables and keys, we can organize data effectively and establish relationships between tables. This allows us to build powerful and flexible databases that can store and manipulate large amounts of data.</p> <p>Don't worry about understunding the syntaxe at this point we will explain more later \ud83e\udd13</p>"},{"location":"sql/04_basics/","title":"SQL Basics understunding","text":""},{"location":"sql/04_basics/#formal-introduction","title":"Formal introduction","text":"<p>Structured Query Language (SQL) is a programming language used to manage and manipulate relational databases. It is a standard language used by most databases to store, retrieve, and manipulate data. SQL is an essential skill for any developer working with databases.</p>"},{"location":"sql/04_basics/#sql-commands","title":"SQL commands","text":"<p>SQL commands are used to interact with a database, such as inserting, updating, deleting, and selecting data.</p> <p>The basic SQL commands include SELECT, INSERT, UPDATE, DELETE, and CREATE. The SELECT command is used to retrieve data from a database, while the INSERT, UPDATE, and DELETE commands are used to modify data in a database. The CREATE command is used to create tables and other database objects.</p> <p>SQL commands are typically entered into a command line interface or a graphical user interface, such as MySQL Workbench or pgAdmin. These interfaces allow developers to visually design and manipulate databases, as well as enter SQL commands to manage data.</p> <p>SQL is widely used in web development, data analysis, and many other fields. It allows developers to easily store and retrieve data, as well as perform complex data manipulations and analysis. Understanding SQL and its commands is essential for developers working with relational databases, and is a valuable skill in today's tech industry.</p> <p>In the following sections, we will delve deeper into the world of SQL and explore each of the major SQL commands in more detail. By the end of this course, you will have a solid understanding of SQL, its uses, and how to use it to manage and manipulate data. With this knowledge, you will be equipped to tackle a variety of database-related challenges and create powerful data-driven applications. </p> <p>So let's continue with SQL installations \ud83d\ude80</p>"},{"location":"sql/05_MacOS_install/","title":"Install MySQL on Mac OS","text":""},{"location":"sql/05_MacOS_install/#spec","title":"Spec","text":"<p>Version OS : Catalina 10.15.7 or higher Version MAMP : 5.5 </p>"},{"location":"sql/05_MacOS_install/#what-is-mamp","title":"What is MAMP?","text":"<p>MAMP is a free, open-source software that allows you to easily install and run Apache, PHP, and MySQL on your local machine. MAMP is a popular solution for web developers who want to develop and test websites locally before uploading them to a live server. In this section, we'll focus on how to use MAMP to set up and use MySQL on MacOS. </p>"},{"location":"sql/05_MacOS_install/#step-1-download-and-install-mamp","title":"Step 1: Download and Install MAMP","text":"<p>The first step is to download and install MAMP on your MacOS machine. You can download the latest version of MAMP from the official website : https://www.mamp.info/en/downloads/</p> <p>Once the download is complete, double-click on the downloaded file to begin the installation process. Follow the on-screen instructions to install MAMP on your machine.</p>"},{"location":"sql/05_MacOS_install/#step-2-start-mamp-server","title":"Step 2: Start MAMP Server","text":"<p>After installing MAMP, you can start the server by double-clicking on the MAMP icon in the Applications folder. This will launch the MAMP control panel.</p> <p>Click on the Start Servers button to start the Apache and MySQL servers. You can check the status of the servers by looking at the indicators in the MAMP control panel. The Apache server is running if the status indicator is green, and the MySQL server is running if the status indicator is also green.</p> <p></p>"},{"location":"sql/05_MacOS_install/#step-3-create-a-test-database-with-graphic-interface-in-mamp","title":"Step 3: Create a test Database with graphic interface in MAMP","text":"<p>Once the servers are running, you can create a database. To do this, click on the Open WebStart page button in the MAMP control panel. This will launch the MAMP homepage in your default browser.</p> <p></p> <p>Click on the phpMyAdmin link on the left-hand side of the MAMP homepage to launch the phpMyAdmin interface. phpMyAdmin is a web-based interface that allows you to manage your MySQL databases.</p> <p></p> <p>In the phpMyAdmin interface, click on the Databases tab </p> <p>and then enter a name for your new database in the Create Database field for our case <code>test</code>. </p> <p>Click on the Create button to create the database and add a table name <code>departments</code> who look like this in SQL command line : </p> <pre><code>CREATE TABLE departments (\n  id INT PRIMARY KEY,\n  name VARCHAR(50)\n);\n</code></pre> <p></p> <p>after validating the table creation we have to specify two field like above :</p> <p></p> <p>and then you can see your new database :</p> <p></p>"},{"location":"sql/05_MacOS_install/#why-mysql-workbench","title":"Why MySQL Workbench","text":"<p>MySQL Workbench and MAMP are two different software tools that can be used to work with MySQL databases, but they have different features and use cases.</p> <p>MySQL Workbench is a graphical user interface (or GUI) tool that is designed for database administrators and developers who need to manage and develop MySQL databases. It provides a wide range of features for working with databases, including:</p> <ul> <li>Creating and managing database schemas</li> <li>Designing and executing SQL queries</li> <li>Visualizing database structures with ER diagrams</li> <li>Managing user accounts and permissions</li> <li>Managing database backups and restores</li> </ul> <p>MySQL Workbench is a powerful tool for working with MySQL databases, but it can be complex and may have a steep learning curve for beginners and we thinks it's more easy to handle and query database.</p> <p>MAMP, on the other hand, is a lightweight web development environment that is designed to make it easy to set up a local web server on your computer. It includes a range of tools that are useful for web developers, including:</p> <ul> <li>Apache web server</li> <li>MySQL database server</li> <li>PHP scripting language</li> </ul> <p>MAMP is designed to be easy to use and configure, and is a good choice for beginners who want to set up a local web development environment quickly and easily.</p>"},{"location":"sql/05_MacOS_install/#difference-between-mysql-and-mamp","title":"Difference between MySQL and MAMP","text":"<p>In summary, MySQL Workbench is a powerful tool for working with MySQL databases, while MAMP is a lightweight web development environment that includes a MySQL database server as one of its components. Which one you choose to use depends on your specific needs and level of expertise.</p>"},{"location":"sql/05_MacOS_install/#install-mysql-workbench","title":"Install MySQL Workbench","text":"<p>Go to the official download link : https://dev.mysql.com/downloads/workbench/ </p> <p>Download the appropriate version of the software for your OS and lunch MAMP SQL server then open the software and click on the button <code>MySQL Connection</code> &gt; <code>Local Instance</code> like the screen below : </p> <p></p> <p>If you don't have change anything you have the following ids : </p> <ul> <li>user : root </li> <li>password : root </li> </ul> <p>Good you are now connected to MAMP SQL Server \ud83e\udd73</p>"},{"location":"sql/05_MacOS_install/#wrap-up","title":"Wrap up","text":"<p>In this tutorial, we have seen how to install MAMP on MacOS and use it to create and manage MySQL databases. Here some important notions about what you have learned through the MAMP installation and MySQL server and client:</p> <ul> <li>MAMP is a software package that allows you to easily install a local web server on your computer, which includes Apache, MySQL, and PHP.</li> <li>With MAMP, you can easily set up a MySQL server and manage databases and data with the MySQL client.</li> <li>To install MAMP on Windows, you can download the MAMP software package and follow the installation instructions. Once installed, you can access the MySQL server and client through the MAMP control panel.</li> <li>MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases.</li> <li>MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases.</li> <li>SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases.</li> <li>With the MySQL client, you can create and manage databases, create tables, and insert, update, and delete data with SQL queries.</li> <li>By practicing with MAMP and the MySQL Workbench, you have learned the basics of how to install and set up a MySQL server and interact with it.</li> </ul> <p>In short, SQL is the language used to communicate with databases, while the MySQL server is the software that manages the databases and listens for connections from clients like the MySQL client. The MySQL client is the tool used to connect to the MySQL server and execute SQL queries. </p>"},{"location":"sql/06_Windows_install/","title":"Install and use MAMP on Windows","text":""},{"location":"sql/06_b_docker_install/","title":"Install MySQL server with docker","text":"<p>Before we get started, it's important to note that Docker is a containerization platform that allows you to run software applications in isolated environments called containers. This means that you can interact with MySQL server without installing it from scrach and run multiple instances of the same application without any interference between them.</p> <p>Now let's dive into the tutorial:</p>"},{"location":"sql/06_b_docker_install/#step-1-install-docker","title":"Step 1: Install Docker","text":"<p>If you don't have Docker installed on your system, you'll need to download and install it first. You can download Docker from the official website: https://www.docker.com/products/docker-desktop</p>"},{"location":"sql/06_b_docker_install/#step-2-pull-the-mysql-docker-image","title":"Step 2: Pull the MySQL Docker image","text":"<p>In Docker, images are used to create containers, which are isolated environments that run applications. Images can be thought of as a template for containers, as they contain all the necessary files, libraries, and dependencies required for an application to run.</p> <p>The <code>docker pull</code> command is used to download an image from a remote registry, such as Docker Hub. When you run this command, Docker will search for the specified image in the remote registry and download it to your local machine.</p> <p>Once Docker is installed, open a terminal and run the following command to pull the MySQL Docker image: <pre><code>docker pull mysql\n</code></pre> This command will download the MySQL image to your local machine, which you can then use to create a container.</p> <p>It's important to note that you must have Docker installed on your local machine to use the <code>docker pull</code> command, as it is a Docker CLI command. Additionally, the image you're trying to pull must be available in the remote registry you're trying to access.</p>"},{"location":"sql/06_b_docker_install/#step-3-start-a-mysql-container","title":"Step 3: Start a MySQL container","text":"<p>After you have pulled the MySQL Docker image, you can start a container using the following command: <pre><code>docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql\n</code></pre> This is the command used to start a new MySQL container with the following options : </p> <ul> <li>--name mysql-container: This option is used to give a name to the new container. In this case, the container is named \"mysql-container\".</li> <li>-e MYSQL_ROOT_PASSWORD=my-secret-pw: This option sets an environment variable for the container, in this case, the MySQL - root password. This means that the password \"my-secret-pw\" will be used as the MySQL root password.</li> <li>-d: This option runs the container in detached mode, which means that it will run in the background and not attach to the terminal session. This is useful for long-running containers, such as database servers.</li> <li>mysql: This is the name of the Docker image that the container is based on. In this case, it is the official MySQL Docker image.</li> </ul> <p>So when you run this command, Docker will start a new container based on the MySQL image with the name \"mysql-container\", set the MySQL root password to \"my-secret-pw\", and run the container in the background it just send you the id of the container like <code>8c4f5828f04b</code> it means it started fine. </p> <p>It's important to note that the MySQL root password should be changed to a more secure password before using the container in a production environment. Also, the name of the container and the password used can be changed to suit your specific needs.</p> <p>This command will start a new container named \"mysql-container\" with the root password <code>my-secret-pw</code></p> <p>You can verify if the container is running with the command in your terminal :  <pre><code>docker ps\n</code></pre> You should see this in your terminal :  </p>"},{"location":"sql/06_b_docker_install/#step-4-access-the-mysql-container-with-the-command-line","title":"Step 4: Access the MySQL container with the command line","text":"<p>To access the MySQL container, you can use the following command: <pre><code>docker exec -it mysql-container mysql -p\n</code></pre> This command will start a MySQL shell session inside the container and prompt you to enter the password you set in the previous step.</p>"},{"location":"sql/06_b_docker_install/#step-5-create-a-test-database-and-a-table","title":"Step 5: Create a test database and a table","text":"<p>Now that you have access to the MySQL container, you can create a database and a table using the following commands: <pre><code>CREATE DATABASE testdb;\nUSE testdb;\nCREATE TABLE users (\nid INT NOT NULL AUTO_INCREMENT,\nname VARCHAR(50) NOT NULL,\nemail VARCHAR(50) NOT NULL,\nPRIMARY KEY (id)\n);\n</code></pre></p> <p>These commands will create a new database named \"testdb\" and a new table named \"users\" with three columns: \"id\", \"name\", and \"email\".</p>"},{"location":"sql/06_b_docker_install/#step-6-insert-values-into-the-table","title":"Step 6: Insert values into the table","text":"<p>You can insert values into the table using the following command: <pre><code>INSERT INTO users (name, email) VALUES ('John Doe', 'johndoe@example.com');\n</code></pre> This command will insert a new row into the \"users\" table with the name \"John Doe\" and the email \"johndoe@example.com\".</p>"},{"location":"sql/06_b_docker_install/#step-7-test-a-query","title":"Step 7: Test a query","text":"<p>Finally, you can test a query to retrieve the data you just inserted using the following command: <pre><code>SELECT * FROM users;\n</code></pre></p> <p>This command will retrieve all the data from the \"users\" table.</p> <p>And that's it! You've successfully installed MySQL with Docker and created a table, inserted values, and executed a test query \ud83e\udd73</p>"},{"location":"sql/07_creating_tables/","title":"Creating Tables","text":"<p>We said before, in SQL a table is a collection of data stored in rows and columns. To create a table, you need to define the table schema which includes the table name, column names, data types, and any constraints on the data. The CREATE TABLE statement is used to create a new table in a database.</p>"},{"location":"sql/07_creating_tables/#in-depth-look-at-how-to-create-tables","title":"In-depth look at how to create tables","text":"<p>To create a new table in SQL, you use the <code>CREATE TABLE</code> command followed by the table name and a list of column definitions. Each column definition specifies the column name, data type, and any constraints on the data.</p> <p>Here is an example of creating a simple table with two columns:</p> <pre><code>CREATE TABLE users (\nid INT PRIMARY KEY,\nname VARCHAR(50) NOT NULL\n);\n</code></pre> <p>This creates a table named <code>users</code> with two columns: <code>id</code> and <code>name</code>. The <code>id</code> column is defined as an integer and is marked as the primary key for the table. The <code>name</code> column is defined as a variable-length string with a maximum length of 50 characters and is marked as required <code>(NOT NULL)</code>.</p>"},{"location":"sql/07_creating_tables/#overview-of-different-data-types-and-how-to-use-them","title":"Overview of different data types and how to use them","text":"<p>SQL provides a wide range of data types that can be used to define columns in a table. These data types include integers, floating-point numbers, strings, dates, and more. Here are some common data types: * INT: used for integer values * VARCHAR(n): used for variable-length character strings with a maximum length of n * DATE: used for date values * FLOAT: used for floating-point numbers * BOOLEAN: used for boolean values</p> <p>Here is an example of creating a table with columns of different data types:</p> <pre><code>CREATE TABLE products (\nid INT PRIMARY KEY,\nname VARCHAR(50) NOT NULL,\nprice FLOAT,\nin_stock BOOLEAN,\ncreated_at DATE\n);\n</code></pre>"},{"location":"sql/07_creating_tables/#add-primary-and-foreign-keys-and-link-an-other-table","title":"Add primary and foreign keys and link an other table","text":"<p>In a relational database, a primary key is a unique identifier for each row in a table. It is used to ensure that each row can be uniquely identified and is commonly used to link to other tables in the database.</p> <p>A foreign key is a column in one table that refers to the primary key of another table. This is used to create relationships between tables and enforce referential integrity.</p> <p>Here is an example of creating a table with a primary key and a foreign key:</p> <pre><code>CREATE TABLE orders (\nid INT PRIMARY KEY,\nproduct_id INT,\nquantity INT,\nFOREIGN KEY (product_id) REFERENCES products(id)\n);\n</code></pre> <p>This creates a table named orders with three columns: <code>id</code>, <code>product_id</code>, and <code>quantity</code>. The <code>id</code> column is defined as the primary key for the table. The <code>product_id</code> column is defined as a foreign key that references the id column in the <code>products</code> table, which creates a relationship between the two tables. Here, the <code>quantity</code> column is defined as an integer.</p>"},{"location":"sql/08_insert/","title":"Inserting Data","text":"<p>Once you have created a table, you can start inserting data into it. The process of inserting data involves specifying the table name, the columns to insert data into, and the values to be inserted.</p>"},{"location":"sql/08_insert/#overview-of-different-insert-commands-and-syntax","title":"Overview of Different Insert Commands and Syntax","text":"<p>There are a few different ways to insert data into a table in SQL, depending on how much information you have about the data you are inserting. Here are some common insert commands and their syntax:</p>"},{"location":"sql/08_insert/#inserting-values-into-specific-columns","title":"Inserting Values into Specific Columns","text":"<p>You can use the <code>INSERT INTO</code> command to insert values into specific columns in a table. Here is the syntax for inserting a single row of data into a table:</p> <pre><code>INSERT INTO table_name (column1, column2, column3, ...)\nVALUES (value1, value2, value3, ...);\n</code></pre> <p>For example, to insert a new row into a <code>users</code> table with the values \"John Doe\" for the <code>name</code> column, \"johndoe@example.com\" for the <code>email</code> column, and 25 for the <code>age</code> column, you would use the following command:</p> <pre><code>INSERT INTO users (name, email, age)\nVALUES ('John Doe', 'johndoe@example.com', 25);\n</code></pre>"},{"location":"sql/08_insert/#inserting-values-into-all-columns","title":"Inserting Values into All Columns","text":"<p>If you have data to insert for every column in a table, you can omit the column names from the INSERT INTO command. Here is the syntax for inserting a single row of data into a table without specifying column names:</p> <pre><code>INSERT INTO table_name\nVALUES (value1, value2, value3, ...);\n</code></pre> <p>For example, to insert a new row into the <code>users</code> table with the values \"Jane Smith\" for the <code>name</code> column, \"janesmith@example.com\" for the <code>email</code> column, 30 for the <code>age</code> column, and \"female\" for the <code>gender</code> column, you would use the following command:</p> <pre><code>INSERT INTO users\nVALUES ('Jane Smith', 'janesmith@example.com', 30, 'female');\n</code></pre>"},{"location":"sql/08_insert/#inserting-multiple-rows-at-once","title":"Inserting Multiple Rows at Once","text":"<p>You can also use the <code>INSERT INTO</code> command to insert multiple rows of data at once. Here is the syntax for inserting multiple rows of data into a table:</p> <pre><code>INSERT INTO table_name (column1, column2, column3, ...)\nVALUES\n(value1, value2, value3, ...),\n(value1, value2, value3, ...),\n(value1, value2, value3, ...),\n...;\n</code></pre> <p>For example, to insert three new rows into the <code>users</code> table, you would use the following command:</p> <pre><code>INSERT INTO users (name, email, age)\nVALUES\n('Alice Johnson', 'alicejohnson@example.com', 35),\n('Bob Williams', 'bobwilliams@example.com', 40),\n('Charlie Brown', 'charliebrown@example.com', 45);\n</code></pre> <p>By using these different insert commands and syntax, you can efficiently add data to your SQL database tables.</p> <p>In the following chapters, we will dive into more examples and exercises to practice the different SQL commands we've covered, including creating tables and inserting data. By practicing these commands, you will gain a deeper understanding of how to manipulate and retrieve data from a database using SQL.</p>"},{"location":"sql/09_constraints/","title":"Constraints","text":"<p>Constraints are rules that you can apply to a table in a database to enforce data integrity. They play a vital role in ensuring that the data within the database remains consistent and accurate. There are various types of constraints that can be applied to a table, each serving a specific purpose.</p>"},{"location":"sql/09_constraints/#types-of-constraints","title":"Types of constraints","text":"<p>One type of constraint is the primary key constraint, which enforces the uniqueness of a column or a group of columns within a table. Another type of constraint is the foreign key constraint, which establishes a relationship between two tables based on the values of their respective columns.</p> <p>Other types of constraints include the NOT NULL constraint, which ensures that a column cannot have a NULL value, and the UNIQUE constraint, which ensures that the values in a column are unique.</p>"},{"location":"sql/09_constraints/#examples-of-customers-table-one-without-constraints-and-the-other-with-constraints","title":"Examples of customers table one without constraints and the other with constraints","text":""},{"location":"sql/09_constraints/#without-constraints","title":"Without Constraints","text":"<pre><code>CREATE TABLE customers (\nid INT,\nfirst_name VARCHAR(50),\nlast_name VARCHAR(50),\nemail VARCHAR(100)\n);\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n(1, 'John', 'Doe', 'john.doe@example.com'),\n(2, 'Jane', 'Doe', 'jane.doe@example.com'),\n(3, 'Bob', 'Smith', 'bob.smith@example.com'),\n(4, 'Alice', 'Johnson', 'alice.johnson@example.com');\n</code></pre> <p>In this example, we create a table named <code>customers</code> with four columns - <code>id</code>, <code>first_name</code>, <code>last_name</code>, and <code>email</code>. We then insert some sample data into the table. However, there are no constraints set on the table to enforce any rules about the data being inserted. For example, we can insert multiple rows with the same <code>id</code> value, which can lead to inconsistencies in the data.</p>"},{"location":"sql/09_constraints/#with-constraints","title":"With Constraints","text":"<pre><code>CREATE TABLE customers (\nid INT PRIMARY KEY,\nfirst_name VARCHAR(50) NOT NULL,\nlast_name VARCHAR(50) NOT NULL,\nemail VARCHAR(100) UNIQUE\n);\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n(1, 'John', 'Doe', 'john.doe@example.com'),\n(2, 'Jane', 'Doe', 'jane.doe@example.com'),\n(3, 'Bob', 'Smith', 'bob.smith@example.com'),\n(4, 'Alice', 'Johnson', 'alice.johnson@example.com');\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n(1, 'Mark', 'Smith', 'mark.smith@example.com'); -- This will fail due to duplicate primary key constraint\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n(5, 'Sam', 'Jones', 'bob.smith@example.com'); -- This will fail due to unique constraint on email column\n</code></pre> <p>In this example, we create the same customers table, but with additional constraints. We set the id column as the primary key, which means that it must be unique for each row. We also set the first_name and last_name columns as NOT NULL, which means that they cannot be empty. Finally, we set the email column as UNIQUE, which means that each email must be unique in the table.</p> <p>When we try to insert data into the table, the constraints are enforced. The first INSERT statement will work fine because it does not violate any constraints. However, the second INSERT statement will fail because it tries to insert a row with a duplicate id value, which violates the primary key constraint. Similarly, the third INSERT statement will fail because it tries to insert a row with a duplicate email value, which violates the unique constraint on the email column.</p>"},{"location":"sql/10_update_delete/","title":"Update &amp; Delete","text":"<p>In addition to inserting data into tables, you may also need to modify or delete existing data. The SQL language provides several commands for updating and deleting data within tables.</p>"},{"location":"sql/10_update_delete/#updating-data","title":"Updating Data","text":"<p>To update data within a table, you can use the <code>UPDATE</code> command followed by the name of the table and the <code>SET</code> keyword. The <code>SET</code> keyword is followed by the column name you want to update, an equals sign, and the new value you want to set.</p> <p>Here's the basic syntax for updating data in a table:</p> <pre><code>UPDATE table_name\nSET column_name = new_value\nWHERE condition;\n</code></pre> <p>In this syntax, the <code>WHERE</code> clause specifies which rows to update. Without a <code>WHERE</code> clause, all rows in the table would be updated.</p> <p>Here's an example that updates the price of a product in a table called <code>products</code>:</p> <pre><code>UPDATE products\nSET price = 19.99\nWHERE product_id = 1234;\n</code></pre> <p>This statement updates the price column for the row where the product_id is equal to 1234.</p>"},{"location":"sql/10_update_delete/#deleting-data","title":"Deleting Data","text":"<p>To delete data from a table, you can use the <code>DELETE</code> command followed by the name of the table. If you want to delete only certain rows, you can use a <code>WHERE</code> clause to specify which rows to delete.</p> <p>Here's the basic syntax for deleting data from a table:</p> <pre><code>DELETE FROM table_name\nWHERE condition;\n</code></pre> <p>Here's an example that deletes a row from a table called <code>orders</code>:</p> <pre><code>DELETE FROM orders\nWHERE order_id = 5678;\n</code></pre> <p>This statement deletes only the row where the <code>order_id</code> is equal to 5678.</p>"},{"location":"sql/10_update_delete/#summarize-creating-inserting-updating-and-deleting","title":"Summarize : creating, inserting, updating and deleting","text":"<p>Let's summarize the previous notions with an SQL example code to create a table, insert values into it, and update a field : </p> <pre><code>-- Creating a table for products\nCREATE TABLE products (\nid INT PRIMARY KEY,\nname VARCHAR(50),\ncategory VARCHAR(50),\nprice DECIMAL(8, 2)\n);\n-- Inserting data into the table\nINSERT INTO products (id, name, category, price)\nVALUES (1, 'Product A', 'Category 1', 10.99),\n(2, 'Product B', 'Category 2', 19.99),\n(3, 'Product C', 'Category 1', 5.99);\n-- Updating the price of Product A\nUPDATE products\nSET price = 12.99\nWHERE id = 1;\n-- Deleting a record from the 'products' table\nDELETE FROM products\nWHERE product_id = 2;\n</code></pre> <p>In this example, we first create a table named <code>products</code> with four columns: <code>id</code>, <code>name</code>, <code>category</code>, and <code>price</code>. We define the <code>id</code> column as the primary key, meaning it uniquely identifies each row in the table.</p> <p>Next, we insert three rows of data into the table using the <code>INSERT INTO</code> command. Each row represents a different product, with values for the <code>id</code>, <code>name</code>, <code>category</code>, and <code>price</code> columns.</p> <p>Finally, we update the price of <code>Product A</code> using the <code>UPDATE</code> command. We specify the table we want to update (<code>products</code>), the field we want to update (<code>price</code>), and the new value we want to set <code>(12.99)</code>. We use the <code>WHERE</code> clause to specify which row(s) we want to update; in this case, we only want to update the row with an <code>id</code> of <code>1</code>, which corresponds to <code>Product A</code>.</p> <p>Then, the <code>DELETE</code> command is used to remove the record from the <code>products</code> table where the value of the <code>product_id</code> field is equal to <code>2</code>. This will delete the second product from the table, which in this case is <code>Product B</code>.</p>"},{"location":"sql/10_update_delete/#deleting-a-single-field-in-a-row","title":"Deleting a single field in a row","text":"<p>Here's an example of deleting a single field in a row of the products table:</p> <pre><code>-- Delete the description of the product with id 3\nUPDATE products\nSET description = NULL\nWHERE id = 3;\n</code></pre> <p>In this example, we use the <code>UPDATE</code> command to modify the description field of the row with <code>id</code> equal to <code>3</code>. The <code>SET</code> keyword is used to specify the new value of the description field, which we set to <code>NULL</code> to delete the existing value. </p> <p>The <code>WHERE</code> clause is used to specify which row(s) to update. In this case, we're only updating the row with <code>id</code> equal to <code>3</code>. By setting the description field to <code>NULL</code>, we effectively delete the value of that field for that particular row.</p>"},{"location":"sql/11_queries/","title":"Basic Queries","text":"<p>In the world of database management, tables and queries go hand in hand. Queries are a fundamental component of any database, as they allow you to retrieve and manipulate data in meaningful ways. </p> <p>In this chapter, we will explore the basics of SQL queries and how they are used to extract data from tables. To demonstrate this, we will use two example tables, the <code>orders</code> and <code>customers</code> tables. </p> <p>These tables will be linked together using a foreign key to show how queries can retrieve data from multiple tables at once. Understanding queries and the relationship between tables is essential for effective database management, as it enables developers to extract valuable insights and make informed decisions based on data.</p> <p>This is the example table called <code>customers</code>:</p> <pre><code>CREATE TABLE customers (\nid INT PRIMARY KEY,\nfirst_name VARCHAR(50),\nlast_name VARCHAR(50),\nemail VARCHAR(100),\naddress VARCHAR(100),\ncity VARCHAR(50),\nstate VARCHAR(50),\nzip_code VARCHAR(20)\n);\n</code></pre> <p>This table has columns for a customer's ID, first name, last name, email address, street address, city, state, and zip code. The <code>id</code> column is the primary key for the table, which means that each row in the table is uniquely identified by its value in the <code>id</code> column.</p> <p>This is the example of an <code>orders</code> table:</p> <pre><code>CREATE TABLE orders (\norder_id INT PRIMARY KEY,\ncustomer_id INT,\norder_date DATE,\ntotal_price DECIMAL(10,2)\n);\n</code></pre> <p>This table has four columns: <code>order_id</code>, <code>customer_id</code>, <code>order_date</code>, and <code>total_price</code>. The <code>order_id</code> column is the primary key of the table, which means that each row has a unique value in that column.</p> <p>The <code>customer_id</code> column is a foreign key that references the <code>customer_id</code> column in the <code>customers</code> table. </p> <p>This establishes a relationship between the two tables. The orders table contains information about each order placed by a customer. The <code>customer_id</code> column is used to link each order to a specific customer in the <code>customers</code> table. </p> <p>The <code>order_date</code> column contains the date that the order was placed, and the <code>total_price</code> column contains the total price of the order. By joining the <code>orders</code> table with the <code>customers</code> table on the <code>customer_id</code> column, we can retrieve information about both the customer and their order in a single query.</p>"},{"location":"sql/11_queries/#overview-of-different-select-commands-and-syntax","title":"Overview of Different SELECT Commands and Syntax","text":"<p>The <code>SELECT</code> statement has a variety of options for retrieving and manipulating data. Here are some examples:</p> <ul> <li> <p>The <code>WHERE</code> clause is used to filter data based on a specified condition: <pre><code>SELECT * FROM customers WHERE city = 'London';\n</code></pre> This statement retrieves all columns and rows from the <code>customers</code> table where the city is <code>London</code>.</p> </li> <li> <p>The <code>ORDER BY</code> clause is used to sort data by one or more columns: <pre><code>SELECT * FROM customers ORDER BY last_name;\n</code></pre> This statement retrieves all columns and rows from the <code>customers</code> table, sorted by the <code>last_name</code> column.</p> </li> <li> <p>The <code>GROUP BY</code> clause is used to group data by one or more columns: <pre><code>SELECT city, COUNT(*) FROM customers GROUP BY city;\n</code></pre> This statement retrieves the <code>city</code> column and a count of how many times each <code>city</code> appears in the <code>customers</code> table.</p> </li> <li> <p>The <code>JOIN</code> command is used to combine data from two or more tables: <pre><code>SELECT * FROM customers JOIN orders ON customers.customer_id = orders.customer_id;\n</code></pre> This statement retrieves all columns and rows from both the <code>customers</code> and <code>orders</code> tables where the <code>customer_id</code> column matches in both tables.</p> </li> </ul> <p>These are just a few examples of the many options available in the <code>SELECT</code> statement. We will explore more advanced queries in later chapters.</p>"},{"location":"sql/12_company_db_1/","title":"Company Database Introduction","text":"<p>In the modern era of technology, most businesses depend on software to manage and track various aspects of their operations. One of the most important types of software that businesses rely on is the database management system (DBMS). A DBMS allows companies to store, manage, and retrieve information in a structured and organized way. A company database is a type of DBMS that is specifically designed to help organizations store and manage information about their employees, customers, products, and services.</p> <p>A company database can be used for a wide range of purposes, such as tracking inventory, processing transactions, generating reports, and analyzing data. By keeping all the relevant information in a centralized location, a company database provides a more efficient and accurate way to manage and analyze data. This, in turn, enables businesses to make informed decisions based on reliable and up-to-date information.</p> <p>Having a well-designed and properly maintained company database is vital to the success of any business. A good company database can help to improve operational efficiency, streamline processes, and enhance customer satisfaction. It can also help organizations to identify trends, analyze performance, and make strategic decisions based on real data.</p> <p>In this chapter, we will explore the various components of a company database, including tables, fields, and relationships. We will also learn how to design and build a company database from scratch, as well as how to use SQL to retrieve, analyze, and manipulate data. By the end of this tutorial, you should have a good understanding how to build a database from scratch for your own business or project.</p>"},{"location":"sql/12_company_db_1/#summary-of-the-project","title":"Summary of the project","text":"<p>This project will focus on building a company database that includes seven tables: * employees * departments * projects * department_projects * employee_projects * jobs * location</p> <p>These tables will be linked together using foreign keys and relationships, allowing organizations to easily access and manage information. The project will also include the creation of primary keys, indexes, and constraints to ensure the integrity and consistency of the data. This database will provide a robust platform for companies to store, organize, and access data in a way that enhances their ability to make data-driven decisions.</p>"},{"location":"sql/12_company_db_1/#set-up-the-project","title":"Set up the project","text":"<p>Start by opening your MySQL client and connecting to your server. In our case just start MAMP like in the installation section. </p>"},{"location":"sql/12_company_db_1/#database-creation","title":"Database creation","text":"<p>Create a new database call <code>company</code> with the graphic interface like in the installation section or with the SQL command line :  <pre><code>CREATE DATABASE company;\n</code></pre> if you used the command line option run also this command : <pre><code>USE company;\n</code></pre> like you've guess it just tell to MySQL to use our database for the futur queries.</p>"},{"location":"sql/12_company_db_1/#tables-creation","title":"Tables creation","text":"<p>This is the SQL script that creates the necessary tables : </p> <pre><code>-- Create Employees table\nCREATE TABLE Employees (\nEmployeeID INT AUTO_INCREMENT PRIMARY KEY,\nFirstName VARCHAR(50),\nLastName VARCHAR(50),\nEmail VARCHAR(50),\nPhone VARCHAR(20),\nHireDate DATE,\nSalary DECIMAL(10,2),\nCommissionPct DECIMAL(4,2),\nManagerID INT,\nDepartmentID INT,\nJobID INT,\nLocationID INT,\nCONSTRAINT fk_manager FOREIGN KEY (ManagerID) REFERENCES Employees(EmployeeID),\nCONSTRAINT fk_department FOREIGN KEY (DepartmentID) REFERENCES Departments(DepartmentID),\nCONSTRAINT fk_job FOREIGN KEY (JobID) REFERENCES Jobs(JobID),\nCONSTRAINT fk_location FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)\n);\n-- Create Departments table\nCREATE TABLE Departments (\nDepartmentID INT AUTO_INCREMENT PRIMARY KEY,\nDepartmentName VARCHAR(50),\nManagerID INT,\nLocationID INT,\nCONSTRAINT fk_department_manager FOREIGN KEY (ManagerID) REFERENCES Employees(EmployeeID),\nCONSTRAINT fk_department_location FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)\n);\n-- Create Projects table\nCREATE TABLE Projects (\nProjectID INT AUTO_INCREMENT PRIMARY KEY,\nProjectName VARCHAR(50),\nStartDate DATE,\nEndDate DATE,\nBudget DECIMAL(15,2)\n);\n-- Create Department_Projects table\nCREATE TABLE Department_Projects (\nDepartmentID INT,\nProjectID INT,\nCONSTRAINT fk_department_project_department FOREIGN KEY (DepartmentID) REFERENCES Departments(DepartmentID),\nCONSTRAINT fk_department_project_project FOREIGN KEY (ProjectID) REFERENCES Projects(ProjectID)\n);\n-- Create Employee_Projects table\nCREATE TABLE Employee_Projects (\nEmployeeID INT,\nProjectID INT,\nHoursWorked DECIMAL(8,2),\nCONSTRAINT fk_employee_project_employee FOREIGN KEY (EmployeeID) REFERENCES Employees(EmployeeID),\nCONSTRAINT fk_employee_project_project FOREIGN KEY (ProjectID) REFERENCES Projects(ProjectID)\n);\n-- Create Jobs table\nCREATE TABLE Jobs (\nJobID INT AUTO_INCREMENT PRIMARY KEY,\nJobTitle VARCHAR(50),\nMinSalary DECIMAL(10,2),\nMaxSalary DECIMAL(10,2)\n);\n-- Create Locations table\nCREATE TABLE Locations (\nLocationID INT AUTO_INCREMENT PRIMARY KEY,\nAddress VARCHAR(50),\nCity VARCHAR(50),\nStateProvince VARCHAR(50),\nCountry VARCHAR(50),\nPostalCode VARCHAR(50)\n);\n</code></pre> <p>Note that the foreign keys are created using the <code>CONSTRAINT</code> keyword and the <code>REFERENCES</code> keyword to specify the table and column to which the key refers. The <code>AUTO_INCREMENT</code> keyword is used to specify that the primary key column should automatically increment for each new row.</p>"},{"location":"sql/12_company_db_1/#insert-data","title":"Insert data","text":"<p>Then populate the tables with this script : </p> <pre><code>-- Insert 10 employees\nINSERT INTO employees (first_name, last_name, email, phone, hire_date, job_id, salary, manager_id, department_id)\nVALUES\n('John', 'Doe', 'johndoe@example.com', '555-555-1234', '2022-01-01', 1, 50000, NULL, 1),\n('Jane', 'Doe', 'janedoe@example.com', '555-555-5678', '2022-01-01', 2, 60000, 1, 1),\n('Bob', 'Smith', 'bobsmith@example.com', '555-555-9012', '2022-02-01', 3, 75000, 2, 2),\n('Alice', 'Johnson', 'alicejohnson@example.com', '555-555-3456', '2022-02-01', 4, 85000, 2, 2),\n('Mark', 'Lee', 'marklee@example.com', '555-555-7890', '2022-03-01', 5, 95000, 2, 3),\n('Emily', 'Chen', 'emilychen@example.com', '555-555-2345', '2022-03-01', 5, 80000, 2, 3),\n('Sara', 'Kim', 'sarakim@example.com', '555-555-6789', '2022-04-01', 6, 70000, 3, 4),\n('Michael', 'Wu', 'michaelwu@example.com', '555-555-0123', '2022-04-01', 7, 65000, 3, 4),\n('David', 'Nguyen', 'davidnguyen@example.com', '555-555-4567', '2022-05-01', 8, 55000, 4, 5),\n('Jennifer', 'Garcia', 'jennifergarcia@example.com', '555-555-8901', '2022-05-01', 9, 60000, 4, 5);\n-- Insert 3 departments\nINSERT INTO departments (name, manager_id, location_id)\nVALUES\n('Engineering', 1, 1),\n('Marketing', 2, 2),\n('Sales', 3, 3);\n-- Insert 4 projects\nINSERT INTO projects (name, start_date, end_date)\nVALUES\n('Project A', '2022-01-01', '2022-03-01'),\n('Project B', '2022-02-01', '2022-05-01'),\n('Project C', '2022-03-01', '2022-06-01'),\n('Project D', '2022-04-01', '2022-07-01');\n-- Insert 4 department_projects relationships\nINSERT INTO department_projects (department_id, project_id)\nVALUES\n(1, 1),\n(1, 2),\n(2, 3),\n(3, 4);\n-- insert 10 rows into department_projects table\nINSERT INTO department_projects (department_id, project_id) VALUES\n(1, 1),\n(1, 2),\n(2, 1),\n(2, 3),\n(3, 2),\n(3, 3),\n(4, 1),\n(4, 2),\n(5, 1),\n(5, 3);\n-- insert 10 rows into jobs table\nINSERT INTO jobs (title, min_salary, max_salary) VALUES\n('Manager', 70000, 120000),\n('Salesperson', 20000, 40000),\n('Developer', 50000, 100000),\n('Accountant', 35000, 60000),\n('HR Manager', 45000, 80000),\n('Marketing Specialist', 40000, 75000),\n('Administrative Assistant', 25000, 35000),\n('Designer', 45000, 80000),\n('Writer', 30000, 50000),\n('Engineer', 55000, 90000);\n-- insert 10 rows into location table\nINSERT INTO location (city, state, country) VALUES\n('New York', 'NY', 'USA'),\n('Los Angeles', 'CA', 'USA'),\n('San Francisco', 'CA', 'USA'),\n('Chicago', 'IL', 'USA'),\n('Houston', 'TX', 'USA'),\n('London', NULL, 'England'),\n('Paris', NULL, 'France'),\n('Berlin', NULL, 'Germany'),\n('Sydney', NULL, 'Australia'),\n('Tokyo', NULL, 'Japan');\n-- Insert 10 rows into the employee_projects table\nINSERT INTO employee_projects (employee_id, project_id, start_date, end_date)\nVALUES (1, 1, '2021-01-01', '2021-06-30'),\n(1, 2, '2021-07-01', '2021-12-31'),\n(2, 1, '2021-01-01', '2021-06-30'),\n(2, 3, '2021-07-01', '2021-12-31'),\n(3, 2, '2021-01-01', '2021-06-30'),\n(3, 3, '2021-07-01', '2021-12-31'),\n(4, 2, '2021-01-01', '2021-06-30'),\n(4, 1, '2021-07-01', '2021-12-31'),\n(5, 3, '2021-01-01', '2021-06-30'),\n(5, 1, '2021-07-01', '2021-12-31');\n</code></pre>"},{"location":"sql/12_company_db_1/#more-informations-about-constraint-and-references","title":"More informations about <code>CONSTRAINT</code> and <code>REFERENCES</code>","text":"<p>The CONSTRAINT and REFERENCES keywords are used to create foreign key constraints in SQL. A foreign key constraint is a rule that ensures the values in a column or set of columns in one table are matched by values in another table.</p> <p>In the example code I provided earlier, we used the CONSTRAINT keyword to create foreign key constraints between the employee_projects and employees tables, as well as between the department_projects and departments tables.</p> <p>Here is an example of the foreign key constraint between the employee_projects and employees tables:</p> <pre><code>CREATE TABLE employee_projects (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    employee_id INT,\n    project_id INT,\n    hours_worked DECIMAL(5,2),\n    CONSTRAINT fk_employee_project_employee\n        FOREIGN KEY (employee_id)\n        REFERENCES employees (id)\n);\n</code></pre> <p>In this example, we first create the employee_projects table with the id, employee_id, project_id, and hours_worked columns. Then we use the CONSTRAINT keyword to create a foreign key constraint named fk_employee_project_employee. The FOREIGN KEY clause specifies the employee_id column as the foreign key column, and the REFERENCES clause specifies the employees table and the id column as the referenced column.</p> <p>This foreign key constraint ensures that every value in the employee_id column in the employee_projects table must exist in the id column of the employees table.</p> <p>The CONSTRAINT and REFERENCES keywords are powerful tools that allow you to establish relationships between tables in a database. They can help ensure data integrity and improve the accuracy and reliability of your queries.</p>"},{"location":"sql/12_company_db_1/#tests-some-queries-for-verification-to-test","title":"Tests some queries for verification --&gt; TO TEST","text":"<p>Let's take a look to ten example queries to verify the data in the seven tables:</p> <ul> <li>Retrieve all employees who work in the \"Sales\" department: <pre><code>SELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nJOIN departments d ON e.department_id = d.department_id\nWHERE d.department_name = 'Sales';\n</code></pre></li> <li>Retrieve all projects that are assigned to the \"Marketing\" department: <pre><code>SELECT p.project_name, d.department_name\nFROM projects p\nJOIN department_projects dp ON p.project_id = dp.project_id\nJOIN departments d ON dp.department_id = d.department_id\nWHERE d.department_name = 'Marketing';\n</code></pre></li> <li>Retrieve all projects that have an estimated cost greater than $100,000: <pre><code>SELECT project_name, estimated_cost\nFROM projects\nWHERE estimated_cost &gt; 100000;\n</code></pre></li> <li>Retrieve all employees who are working on the \"Big Project\": <pre><code>SELECT e.first_name, e.last_name, p.project_name\nFROM employees e\nJOIN employee_projects ep ON e.employee_id = ep.employee_id\nJOIN projects p ON ep.project_id = p.project_id\nWHERE p.project_name = 'Big Project';\n</code></pre></li> <li>Retrieve all job titles and the number of employees who hold each job title: <pre><code>SELECT j.job_title, COUNT(*) AS num_employees\nFROM employees e\nJOIN jobs j ON e.job_id = j.job_id\nGROUP BY j.job_title;\n</code></pre></li> <li>List all employees and their department: <pre><code>SELECT e.employee_id, e.first_name, e.last_name, d.department_name \nFROM employees e \nINNER JOIN departments d ON e.department_id = d.department_id;\n</code></pre></li> <li>List all departments and their location: <pre><code>SELECT d.department_name, l.city, l.state \nFROM departments d \nINNER JOIN location l ON d.location_id = l.location_id;\n</code></pre></li> <li>List all projects and their department: <pre><code>SELECT p.project_id, p.project_name, d.department_name \nFROM projects p \nINNER JOIN department_projects dp ON p.project_id = dp.project_id \nINNER JOIN departments d ON dp.department_id = d.department_id;\n</code></pre></li> <li>List all employees and the projects they are working on: <pre><code>SELECT e.first_name, e.last_name, p.project_name \nFROM employees e \nINNER JOIN employee_projects ep ON e.employee_id = ep.employee_id \nINNER JOIN projects p ON ep.project_id = p.project_id;\n</code></pre></li> <li>List all employees, their job title, and salary: <pre><code>SELECT e.first_name, e.last_name, j.job_title, j.salary \nFROM employees e \nINNER JOIN jobs j ON e.job_id = j.job_id;\n</code></pre></li> </ul>"},{"location":"sql/12_company_db_1/#the-importance-of-schema-and-organization","title":"The importance of schema and organization","text":"<p>Creating a schema and diagrams for a database is critical, especially when dealing with large databases with many tables and relationships. Without proper organization and documentation, it can be challenging to understand the structure and relationships between different tables. This is particularly true when many people are working on the database or when there is a lot of data being added and updated regularly. Having a clear schema and diagrams can help developers and users understand the structure and relationships of the data, leading to more efficient and effective use of the database. Additionally, it can help to identify and prevent errors in the data or in the database design itself. Overall, investing time in creating a clear schema and diagrams can save time and resources in the long run and make the database easier to manage and use.</p>"},{"location":"sql/12_company_db_1/#wrap-up","title":"Wrap-up","text":"<ul> <li>In this project, we learned how to create a company database using MySQL.</li> <li>We created 7 tables: employees, departments, projects, department_projects, employee_projects, jobs, and location.</li> <li>We added primary keys to all tables with auto-increment options for unique identification and added foreign keys to establish relationships between tables.</li> <li>We inserted data into each table and test some queries.</li> <li>We also learned about the importance of schema and diagrams for databases, especially as the number of tables and relationships grows, and the significance of foreign keys in ensuring data integrity and consistency.</li> </ul>"},{"location":"sql/13_queries_db/","title":"More queries","text":"<p>In this chapter we will be working on the MySQL Sample Database.  The MySQL Sample Database provides a sample database called \"employees\" that you can use to practice SQL queries. You can download the database and load it into your MySQL server. Here is the link to the database: https://dev.mysql.com/doc/employee/en/</p>"},{"location":"sql/13_queries_db/#download-the-database-and-load-it-into-mysqlworkbench","title":"Download the database and load it into MySQLWorkbench","text":"<p>\ud83d\udea7 You need to run MySQL server (with MAMP for example) before lunching MySQLWorkbench \ud83d\udea7</p>"},{"location":"sql/13_queries_db/#dowload-the-mysql-sample-database","title":"Dowload the MySQL Sample Database","text":"<p>You can follow the documentation above or just go to : https://github.com/datacharmer/test_db and download the repo as zip. </p>"},{"location":"sql/13_queries_db/#load-mysql-sample-database-into-mysqlworkbench","title":"Load MySQL Sample Database into MySQLWorkbench","text":"<p>When you have downloaded the git repo as zip go to your Download files and unzip the folder and  open MySQLWorkbench then go to &gt; <code>File</code> &gt; <code>Run SQL Scripts</code> and load the file <code>employees.sql</code></p>"},{"location":"sql/13_queries_db/#run-a-test-query","title":"Run a test query","text":"<p>We will running a test query for testing our database, we must open a new file for writing our query for that you can click on the file icon button like in the screen below or go to <code>File</code> &gt; <code>New Query Tab</code></p> <p><pre><code>use employees;\nSELECT d.dept_name, AVG(s.salary) AS avg_salary\nFROM departments d\nINNER JOIN dept_emp de ON d.dept_no = de.dept_no\nINNER JOIN salaries s ON de.emp_no = s.emp_no\nGROUP BY d.dept_name;\n</code></pre> Notice that, the first line <code>use employees;</code> is here to tell to our software to use the employees database then you can see the result of our test query in the window bellow :  </p> <p>We will study in detail this query later don't worry. </p>"},{"location":"sql/13_queries_db/#in-depth-look-at-more-basic-queries-in-sql","title":"In-depth look at more basic queries in SQL","text":"<p>We encourage you to pratice the queries into MySQLWorkbench, let's review some basics !</p>"},{"location":"sql/13_queries_db/#select-statement","title":"SELECT statement:","text":"<p>The <code>SELECT</code> statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas.  The <code>*</code> character can be used as a shorthand to select all columns in a table. We often use the <code>AS</code> keyword is used to assign a name to a column in the output.</p> <pre><code>SELECT first_name, last_name, salary AS \"Annual Salary\"\nFROM employees;\n</code></pre> <p>In this example, the AS keyword is used to assign a new name to the \"salary\" column in the output. The new name is \"Annual Salary\".</p> <p>This query selects the first name, last name, and salary of all the employees in the \"employees\" table, but it renames the \"salary\" column as \"Annual Salary\" in the output.</p> <p>Note that the AS keyword is optional, and you can also use a space or equals sign to assign a name to a column. For example, the following query is equivalent to the one above:</p> <pre><code>SELECT first_name, last_name, salary \"Annual Salary\"\nFROM employees;\n</code></pre> <p>In both cases, the output column is named \"Annual Salary\".</p>"},{"location":"sql/13_queries_db/#where-clause","title":"WHERE clause:","text":"<p>The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table.</p> <pre><code>SELECT *\nFROM orders\nWHERE order_date &gt;= '2022-01-01';\n</code></pre> <p>This query selects all the columns from the \"orders\" table where the order date is on or after January 1, 2022.</p> <p>This is an other example : </p> <p><pre><code>SELECT first_name, last_name, salary * 12 AS \"Annual Salary\"\nFROM employees\nWHERE hire_date &gt;= '2005-01-01';\n</code></pre> In this example, the WHERE clause is used to filter the results to include only employees hired on or after January 1, 2005. The AS keyword is used to assign a new name to the \"salary * 12\" expression in the output. The new name is \"Annual Salary\".</p> <p>This query selects the first name, last name, and annual salary of all the employees in the \"employees\" table who were hired on or after January 1, 2005. The annual salary is calculated by multiplying the monthly salary by 12.</p> <p>Note that the order of the SQL clauses matters. The WHERE clause is used to filter the results before the AS keyword is used to assign a new name to the output column.</p>"},{"location":"sql/13_queries_db/#join-clause","title":"JOIN clause","text":"<p>The <code>JOIN</code> clause is used to combine rows from two or more tables based on a related column between them. Here's an example:</p> <p><pre><code>SELECT customers.first_name, customers.last_name, orders.order_date\nFROM customers\nINNER JOIN orders\nON customers.customer_id = orders.customer_id;\n</code></pre> This query selects the first name, last name, and order date of all customers who have placed an order. The results are obtained by joining the \"customers\" and \"orders\" tables on the customer_id column.</p> <p>We will discuss nore about <code>JOIN</code> later don't worry. </p>"},{"location":"sql/13_queries_db/#order-by-clause","title":"ORDER BY clause","text":"<p>The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. Here's an example: <pre><code>SELECT product_name, unit_price\nFROM products\nORDER BY unit_price DESC;\n</code></pre> This query selects the product name and unit price of all the products in the \"products\" table and sorts the results in descending order based on the unit price.</p>"},{"location":"sql/13_queries_db/#group-by-clause","title":"GROUP BY clause","text":"<p>The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data.</p> <pre><code>SELECT category_id, COUNT(*) AS num_products\nFROM products\nGROUP BY category_id;\n</code></pre> <p>This query groups the products in the \"products\" table by their category and counts the number of products in each category. The COUNT(*) function is used to count the number of rows in each group, and the AS keyword is used to assign the name \"num_products\" to the output column.</p> <p>Here an other example : </p> <pre><code>SELECT department, AVG(salary) AS \"Average Salary\"\nFROM employees\nGROUP BY department\nORDER BY \"Average Salary\" DESC;\n</code></pre> <p>In this example, the GROUP BY clause is used to group the employees by department, and the AVG() function is used to calculate the average salary for each department. The AS keyword is used to assign a new name to the \"AVG(salary)\" expression in the output. The new name is \"Average Salary\".</p> <p>The ORDER BY keyword is used to sort the results in descending order based on the \"Average Salary\" column. Note that we need to enclose the output column name in double quotes because it contains a space.</p> <p>This query selects the department and average salary of all the employees in the \"employees\" table, grouped by department, and sorted in descending order by average salary.</p> <p>Note that when using the GROUP BY clause, the SELECT statement can only include the columns that are specified in the GROUP BY clause or have an aggregate function applied to them. Any other columns will result in an error, unless they are included in an aggregate function. In this example, we only select the department and average salary columns because the department column is included in the GROUP BY clause.</p>"},{"location":"sql/13_queries_db/#wrap-up","title":"Wrap up","text":"<p>These are just a few examples of basic SQL queries, but they provide a good foundation for building more complex queries. By combining these statements with other SQL clauses, you can perform powerful data analysis and extract valuable insights from your data.</p> <p>Let's summarize what we've learn in this section : </p> <ul> <li>The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table. The AS keyword is used to assign a name to a column in the output.</li> <li>The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table.</li> <li>The JOIN clause is used to combine rows from two or more tables based on a related column between them. It can be used to join tables on a primary key/foreign key relationship or on a common column.</li> <li>The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them.</li> <li>Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data.</li> <li>The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. It can be used to sort in ascending (ASC) or descending (DESC) order.</li> <li>The AS keyword is used to assign a new name to a column or an expression in the output.</li> <li>SQL keywords are not case-sensitive, but it is a best practice to use them in uppercase to make the code more readable.</li> <li>The order of the SQL clauses matters, and it can affect the output of the query.</li> </ul>"},{"location":"sql/14_functions/","title":"SQL Functions","text":""},{"location":"sql/14_functions/#introduction-to-functions-in-sql","title":"Introduction to Functions in SQL","text":"<p>SQL functions are built-in functions that are used to perform operations on data in a database. They take one or more arguments as input, perform a specific operation, and return a result. Functions can be used in SELECT, WHERE, HAVING, and ORDER BY clauses of a SQL query.</p> <p>There are many different types of functions in SQL, including aggregate functions, scalar functions, date and time functions, and string functions. Each type of function performs a specific operation on data and returns a result.</p> <p>Overall, SQL functions are essential for data analysis because they allow you to perform complex calculations, filter data based on specific criteria, clean up messy data, aggregate data to provide insights into trends and patterns, and transform data from one format to another. By mastering SQL functions, you can become a more effective data analyst and make more informed decisions based on your data.</p>"},{"location":"sql/14_functions/#overview-of-different-types-of-functions-and-examples","title":"Overview of Different Types of Functions and Examples","text":""},{"location":"sql/14_functions/#aggregate-functions","title":"Aggregate Functions","text":"<p>Aggregate functions are used to perform calculations on groups of rows and return a single value. Some common aggregate functions are:</p> <ul> <li><code>COUNT()</code>: returns the number of rows in a table or the number of non-null values in a column. <pre><code>SELECT COUNT(*) as num_employees\nFROM employees;\n</code></pre> This query counts the number of rows in the \"employees\" table and assigns the name \"num_employees\" to the output column.</li> <li><code>SUM()</code>: returns the sum of values in a column. <pre><code>SELECT SUM(salary) as total_salary\nFROM salaries;\n</code></pre> This query calculates the total salary of all employees in the \"salaries\" table and assigns the name \"total_salary\" to the output column. -<code>AVG()</code>: returns the average value of a column. <pre><code>SELECT AVG(salary) as avg_salary\nFROM salaries;\n</code></pre> This query calculates the average salary of all employees in the \"salaries\" table and assigns the name \"avg_salary\" to the output column.</li> <li><code>MAX()</code>: returns the maximum value in a column. <pre><code>SELECT MAX(salary) as max_salary\nFROM salaries;\n</code></pre> This query finds the highest salary in the \"salaries\" table and assigns the name \"max_salary\" to the output column.</li> <li><code>MIN()</code>: returns the minimum value in a column. <pre><code>SELECT MIN(salary) as min_salary\nFROM salaries;\n</code></pre> This query finds the lowest salary in the \"salaries\" table and assigns the name \"min_salary\" to the output column.</li> </ul>"},{"location":"sql/14_functions/#scalar-functions","title":"Scalar Functions","text":"<p>Scalar functions are used to perform operations on individual values and return a single value. Some common scalar functions are:</p> <ul> <li><code>UPPER()</code>: converts a string to uppercase. <pre><code>SELECT UPPER(first_name) as upper_first_name\nFROM employees;\n</code></pre> This query converts the first name of all employees in the \"employees\" table to uppercase and assigns the name \"upper_first_name\" to the output column.</li> <li><code>LOWER()</code>: converts a string to lowercase. <pre><code>SELECT LOWER(last_name) as lower_last_name\nFROM employees;\n</code></pre> This query converts the last name of all employees in the \"employees\" table to lowercase and assigns the name \"lower_last_name\" to the output column. -<code>LENGTH()</code>: returns the length of a string. <pre><code>SELECT first_name, LENGTH(first_name) as name_length\nFROM employees;\n</code></pre> This query returns the first name of all employees in the \"employees\" table, and calculates the length of each name and assigns the name \"name_length\" to the output column.</li> </ul>"},{"location":"sql/14_functions/#date-and-time-functions","title":"Date and Time Functions","text":"<p>Date and time functions are used to perform operations on date and time values. Some common date and time functions are:</p> <ul> <li><code>DATE()</code>: extracts the date part from a datetime value. <pre><code>SELECT hire_date, DATE(hire_date) as hire_date_only\nFROM employees;\n</code></pre> This query extracts the date part from the \"hire_date\" column of the \"employees\" table and assigns the name \"hire_date_only\" to the output column.</li> <li><code>YEAR()</code>: returns the year from a date value. <pre><code>SELECT hire_date, YEAR(hire_date) as hire_year\nFROM employees;\n</code></pre> This query returns the \"hire_date\" column of the \"employees\" table and calculates the year each employee was hired. The name \"hire_year\" is assigned to the output column.</li> </ul> <p>Same <code>MONTH()</code> function :  <pre><code>SELECT hire_date, MONTH(hire_date) as hire_month\nFROM employees;\n</code></pre> This query returns the \"hire_date\" column of the \"employees\" table and calculates the month each employee was hired. The name \"hire_month\" is assigned to the output column.</p>"},{"location":"sql/14_functions/#string-functions","title":"String Functions","text":"<p>String functions are used to perform operations on string values. Some common string functions are:</p> <ul> <li>CONCAT(): concatenates two or more strings together. <pre><code>SELECT CONCAT(first_name, ' ', last_name) as full_name\nFROM employees;\n</code></pre> This query combines the first name and last name columns of the \"employees\" table and assigns the name \"full_name\" to the output column.</li> <li>LEFT(): returns the leftmost characters of a string. <pre><code>SELECT first_name, LEFT(first_name, 3) as initial\nFROM employees;\n</code></pre> This query returns the first name of all employees in the \"employees\" table and extracts the first three characters of each name. The name \"initial\" is assigned to the output column.</li> <li>REPLACE(): replaces a substring in a string with another substring. <pre><code>SELECT REPLACE(email, 'gmail', 'yahoo') as new_email\nFROM employees;\n</code></pre> This query returns the email column of the \"employees\" table and replaces the substring 'gmail' with 'yahoo' in each email address. The name \"new_email\" is assigned to the output column.</li> </ul>"},{"location":"sql/14_functions/#mix-up","title":"Mix up","text":"<p>Let's take a look at three examples of SQL queries that use a mix of functions on the \"employees\" database again. </p>"},{"location":"sql/14_functions/#find-the-average-salary-of-employees-by-department-and-round-the-results-to-two-decimal-places","title":"Find the average salary of employees by department, and round the results to two decimal places:","text":"<p><pre><code>SELECT department, ROUND(AVG(salary), 2) as avg_salary\nFROM employees\nJOIN dept_emp ON employees.emp_no = dept_emp.emp_no\nJOIN departments ON dept_emp.dept_no = departments.dept_no\nGROUP BY department;\n</code></pre> This query joins the \"employees\", \"dept_emp\", and \"departments\" tables, and uses the AVG() function to calculate the average salary of employees in each department. The ROUND() function is used to round the results to two decimal places. The output includes the department name and the average salary for each department.</p> <p>Don't worry about the <code>JOIN</code> clause we will get to it in detail later. </p>"},{"location":"sql/14_functions/#find-the-top-10-most-common-first-names-among-employees-and-show-the-number-of-employees-with-each-name","title":"Find the top 10 most common first names among employees, and show the number of employees with each name:","text":"<p><pre><code>SELECT first_name, COUNT(*) as num_employees\nFROM employees\nGROUP BY first_name\nORDER BY num_employees DESC\nLIMIT 10;\n</code></pre> This query uses the COUNT() function to count the number of employees with each first name, and the GROUP BY clause to group the results by first name. The ORDER BY clause is used to sort the results in descending order by the number of employees, and the LIMIT clause is used to show only the top 10 results.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-hired-in-each-year-and-show-the-results-as-a-percentage-of-the-total-number-of-employees","title":"Find the number of employees hired in each year, and show the results as a percentage of the total number of employees:","text":"<pre><code>SELECT YEAR(hire_date) as hire_year, COUNT(*) / (SELECT COUNT(*) FROM employees) * 100 as percentage\nFROM employees\nGROUP BY hire_year;\n</code></pre> <p>This query uses the YEAR() function to extract the year from the hire date of each employee, and the COUNT() function to count the number of employees hired in each year. The subquery (SELECT COUNT(*) FROM employees) is used to calculate the total number of employees in the \"employees\" table. The percentage of employees hired in each year is calculated by dividing the count by the total number of employees and multiplying by 100. The output includes the hire year and the percentage of employees hired in that year.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-born-in-each-month-and-sort-the-results-by-month","title":"Find the number of employees born in each month, and sort the results by month:","text":"<pre><code>SELECT MONTH(birth_date) as birth_month, COUNT(*) as num_employees\nFROM employees\nGROUP BY birth_month\nORDER BY birth_month;\n</code></pre> <p>This query uses the MONTH() function to extract the month from the birth date of each employee, and the COUNT() function to count the number of employees born in each month. The GROUP BY clause is used to group the results by birth month, and the ORDER BY clause is used to sort the results by month.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-who-were-hired-in-each-year-and-show-the-results-as-a-bar-chart","title":"Find the number of employees who were hired in each year, and show the results as a bar chart:","text":"<pre><code>SELECT YEAR(hire_date) as hire_year, COUNT(*) as num_employees\nFROM employees\nGROUP BY hire_year;\n</code></pre> <p>This query uses the YEAR() function to extract the year from the hire date of each employee, and the COUNT() function to count the number of employees hired in each year. The GROUP BY clause is used to group the results by hire year. You can visualize the results as a bar chart in a data visualization tool, such as Tableau or Power BI, to see the distribution of hires over time.</p>"},{"location":"sql/14_functions/#conclusion","title":"Conclusion","text":"<p>SQL functions are powerful tools that allow you to perform operations on data and return meaningful results. They can be used to calculate aggregate values, manipulate strings, and work with date and time values. By understanding the different types of functions available in SQL and how to use them in queries, you can perform complex data analysis and retrieve valuable insights from your data.</p>"},{"location":"sql/15_Wildcards/","title":"Wildcards &amp; Unions","text":""},{"location":"sql/15_Wildcards/#wildcaards","title":"Wildcaards","text":"<p>Wildcards are special characters that are used in SQL to represent one or more characters in a string. They are used in conjunction with the LIKE operator to perform pattern matching on text values. Wildcards allow you to search for strings that match a specific pattern, even if you don't know the exact value of the string.</p> <p>Wildcards are particularly useful when searching for records that have similar but not identical values in a column. For example, you can use a wildcard to find all employees with a first name that starts with the letter \"J\", or all employees with a last name that ends in \"son\".</p>"},{"location":"sql/15_Wildcards/#overview-of-different-wildcard-characters-and-their-uses","title":"Overview of Different Wildcard Characters and Their Uses","text":"<p>There are three main wildcard characters in SQL: the percent sign (%), the underscore (_), and the square brackets ([]). Each wildcard character serves a different purpose and can be used in different ways.</p>"},{"location":"sql/15_Wildcards/#the-percent-sign","title":"The Percent Sign (%)","text":"<p>The percent sign is used to represent zero or more characters in a string. It can be used at the beginning, end, or in the middle of a search pattern.</p> <p>For example, to find all employees with a first name that starts with the letter \"J\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE 'J%';\n</code></pre> <p>This query returns all employees whose first name starts with the letter \"J\". The % wildcard character is used to match any number of characters that come after the letter \"J\".</p> <p>Similarly, to find all employees with a last name that ends in \"son\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE last_name LIKE '%son';\n</code></pre> <p>This query returns all employees whose last name ends in the letters \"son\". The % wildcard character is used to match any number of characters that come before the letters \"son\".</p>"},{"location":"sql/15_Wildcards/#the-underscore-_","title":"The Underscore (_)","text":"<p>The underscore is used to represent a single character in a string. It can be used at the beginning, end, or in the middle of a search pattern.</p> <p>For example, to find all employees with a first name that starts with the letter \"J\" and has a second letter that is an \"o\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE 'J_o%';\n</code></pre> <p>This query returns all employees whose first name starts with the letter \"J\", has a second letter that is an \"o\", and has any number of characters that come after the second letter.</p>"},{"location":"sql/15_Wildcards/#the-square-brackets","title":"The Square Brackets ([])","text":"<p>The square brackets are used to represent a single character that can be any one of the characters specified within the brackets. For example, to find all employees with a first name that starts with the letters \"J\" or \"P\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE '[JP]%';\n</code></pre> <p>This query returns all employees whose first name starts with the letters \"J\" or \"P\". The square brackets are used to specify that the first letter can be either \"J\" or \"P\".</p> <p>You can also use the square brackets to search for ranges of characters. For example, to find all employees with a last name that starts with the letters \"M\" to \"Z\", you can use the following SQL query:</p> <p><pre><code>SELECT * FROM employees\nWHERE last_name LIKE '[M-Z]%';\n</code></pre> This query returns all employees whose last name starts with any letter from \"M\" to \"Z\". The square brackets and the \"-\" symbol are used to specify the range of letters.</p>"},{"location":"sql/15_Wildcards/#wildcards-wrap-up","title":"Wildcards Wrap-up","text":"<p>Wildcards are an essential tool for performing pattern matching on text values in SQL. They allow you to search for records that match a specific pattern, even if you don't know the exact value of the string. There are three main wildcard characters in SQL: the percent sign (%), the underscore (_), and the square brackets ([]). The percent sign is used to represent zero or more characters, the underscore is used to represent a single character, and the square brackets are used to represent a single character that can be any one of the characters specified within the brackets.</p> <p>By using wildcards in conjunction with the LIKE operator, you can perform powerful pattern matching on text values in SQL. This is particularly useful when searching for records that have similar but not identical values in a column. With a basic understanding of wildcard characters, you can improve your SQL queries and retrieve more accurate and meaningful results from your data.</p>"},{"location":"sql/15_Wildcards/#union","title":"Union","text":"<p>Union is a set operation in SQL that is used to combine the results of two or more <code>SELECT</code> statements into a single result set. Union returns a distinct set of rows that are present in either of the two or more <code>SELECT</code> statements. Union can be used to combine data from multiple tables, or to combine data from a single table that is split across multiple columns.</p> <p>Union can be useful when you need to combine data from multiple sources or when you want to merge two or more tables with similar structure. Union can help simplify data analysis by providing a consolidated view of data that is spread across multiple sources.</p>"},{"location":"sql/15_Wildcards/#overview-of-how-to-use-union-to-combine-data","title":"Overview of How to Use Union to Combine Data","text":"<p>The syntax for using Union in SQL is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nUNION\nSELECT column1, column2, ... FROM table2;\n</code></pre> <p>In this syntax, the first <code>SELECT</code> statement selects data from table1 and the second <code>SELECT</code> statement selects data from <code>table2</code>. The column names and data types of the columns in each <code>SELECT</code> statement must match.</p> <p>Union combines the results of the two <code>SELECT</code> statements and removes any duplicate rows. The columns in the result set are determined by the columns in the first <code>SELECT</code> statement.</p> <p>Here are a few examples of how to use Union to combine data:</p>"},{"location":"sql/15_Wildcards/#example-1-combine-data-from-two-tables","title":"Example 1: Combine Data from Two Tables","text":"<p>Suppose you have two tables in the \"employees\" database: \"sales\" and \"marketing\". Both tables have the same structure and contain sales data for different regions. You can use Union to combine the sales data from both tables into a single result set:</p> <pre><code>SELECT region, sales_amount, year FROM sales\nUNION\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> <p>This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes the region, sales amount, and year for each sale. Union removes any duplicate rows from the result set.</p>"},{"location":"sql/15_Wildcards/#example-2-combine-data-from-multiple-columns","title":"Example 2: Combine Data from Multiple Columns","text":"<p>Suppose you have a table in the \"employees\" database that stores the names of employees in two columns: \"first_name\" and \"last_name\". You can use Union to combine the data from both columns into a single column:</p> <p><pre><code>SELECT first_name as name FROM employees\nUNION\nSELECT last_name as name FROM employees;\n</code></pre> This query combines the data from the \"first_name\" and \"last_name\" columns into a single column called \"name\". Union removes any duplicate names from the result set.</p>"},{"location":"sql/15_Wildcards/#example-3-use-union-all-to-include-duplicate-rows","title":"Example 3: Use Union All to Include Duplicate Rows","text":"<p>By default, Union removes duplicate rows from the result set. If you want to include all rows from both <code>SELECT</code> statements, including duplicates, you can use Union All instead:</p> <p><pre><code>SELECT region, sales_amount, year FROM sales\nUNION ALL\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes all rows, including duplicates.</p>"},{"location":"sql/15_Wildcards/#union-wrap-up","title":"Union Wrap-up","text":"<p>Union is a powerful set operation in SQL that is used to combine the results of two or more <code>SELECT</code> statements into a single result set. Union can be used to combine data from multiple tables or to combine data from a single table that is split across multiple columns. By understanding how to use Union in SQL, you can simplify data analysis and retrieve a consolidated view of data that is spread across multiple sources.</p>"},{"location":"sql/16_unions/","title":"Union","text":""},{"location":"sql/16_unions/#explanation-of-union-in-sql","title":"Explanation of Union in SQL","text":"<p>Union is a set operation in SQL that is used to combine the results of two or more <code>SELECT</code> statements into a single result set. Union returns a distinct set of rows that are present in either of the two or more <code>SELECT</code> statements. Union can be used to combine data from multiple tables, or to combine data from a single table that is split across multiple columns.</p> <p>Union can be useful when you need to combine data from multiple sources or when you want to merge two or more tables with similar structure. Union can help simplify data analysis by providing a consolidated view of data that is spread across multiple sources.</p>"},{"location":"sql/16_unions/#overview-of-how-to-use-union-to-combine-data","title":"Overview of How to Use Union to Combine Data","text":"<p>The syntax for using Union in SQL is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nUNION\nSELECT column1, column2, ... FROM table2;\n</code></pre> <p>In this syntax, the first <code>SELECT</code> statement selects data from table1 and the second <code>SELECT</code> statement selects data from <code>table2</code>. The column names and data types of the columns in each <code>SELECT</code> statement must match.</p> <p>Union combines the results of the two <code>SELECT</code> statements and removes any duplicate rows. The columns in the result set are determined by the columns in the first <code>SELECT</code> statement.</p> <p>Here are a few examples of how to use Union to combine data:</p>"},{"location":"sql/16_unions/#example-1-combine-data-from-two-tables","title":"Example 1: Combine Data from Two Tables","text":"<p>Suppose you have two tables in the \"employees\" database: \"sales\" and \"marketing\". Both tables have the same structure and contain sales data for different regions. You can use Union to combine the sales data from both tables into a single result set:</p> <pre><code>SELECT region, sales_amount, year FROM sales\nUNION\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> <p>This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes the region, sales amount, and year for each sale. Union removes any duplicate rows from the result set.</p>"},{"location":"sql/16_unions/#example-2-combine-data-from-multiple-columns","title":"Example 2: Combine Data from Multiple Columns","text":"<p>Suppose you have a table in the \"employees\" database that stores the names of employees in two columns: \"first_name\" and \"last_name\". You can use Union to combine the data from both columns into a single column:</p> <p><pre><code>SELECT first_name as name FROM employees\nUNION\nSELECT last_name as name FROM employees;\n</code></pre> This query combines the data from the \"first_name\" and \"last_name\" columns into a single column called \"name\". Union removes any duplicate names from the result set.</p>"},{"location":"sql/16_unions/#example-3-use-union-all-to-include-duplicate-rows","title":"Example 3: Use Union All to Include Duplicate Rows","text":"<p>By default, Union removes duplicate rows from the result set. If you want to include all rows from both <code>SELECT</code> statements, including duplicates, you can use Union All instead:</p> <p><pre><code>SELECT region, sales_amount, year FROM sales\nUNION ALL\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes all rows, including duplicates.</p>"},{"location":"sql/16_unions/#conclusion","title":"Conclusion","text":"<p>Union is a powerful set operation in SQL that is used to combine the results of two or more <code>SELECT</code> statements into a single result set. Union can be used to combine data from multiple tables or to combine data from a single table that is split across multiple columns. By understanding how to use Union in SQL, you can simplify data analysis and retrieve a consolidated view of data that is spread across multiple sources.</p>"},{"location":"sql/17_joins/","title":"Joins","text":""},{"location":"sql/17_joins/#explanation-of-joins-in-sql","title":"Explanation of Joins in SQL","text":"<p>Joins in SQL are used to combine data from two or more tables in a relational database. Joins allow you to retrieve data that is spread across multiple tables by linking related data together.</p> <p>A join creates a new virtual table that contains data from the tables being joined. The data in the virtual table is a combination of data from the original tables that match a specific condition. The condition for joining tables is typically based on the values of a common column or set of columns in each table.</p> <p>Joins are an essential tool for retrieving complex data from a database. By linking related data together, joins allow you to retrieve data that is spread across multiple tables in a single query.</p>"},{"location":"sql/17_joins/#overview-of-different-types-of-joins-and-how-to-use-them","title":"Overview of Different Types of Joins and How to Use Them","text":"<p>There are several types of joins in SQL, including <code>inner join</code>, <code>left join</code>, <code>right join</code>, and <code>full outer join</code>. Each type of join is used to combine data from two or more tables in a different way.</p> <p>Here a summary schema for each type of join : </p> <p></p> <ul> <li>Inner Join: This join returns only the rows that have matching values in both tables. In the image, the result of an inner join between tables A and B is shown. Only the rows that have matching values in both tables are included in the result set.</li> <li>Left Join: This join returns all the rows from the left table and the matching rows from the right table. If there is no match in the right table, the result will contain NULL values for those columns. In the image, the result of a left join between tables A and B is shown. All the rows from table A are included in the result set, and the matching rows from table B are included. Rows in table A that have no matching rows in table B are included, with NULL values for the columns in table B.</li> <li>Right Join: This join returns all the rows from the right table and the matching rows from the left table. If there is no match in the left table, the result will contain NULL values for those columns. In the image, the result of a right join between tables A and B is shown. All the rows from table B are included in the result set, and the matching rows from table A are included. Rows in table B that have no matching rows in table A are included, with NULL values for the columns in table A.</li> <li>Full Outer Join: This join returns all the rows from both tables, with NULL values in the columns where there is no match. In the image, the result of a full outer join between tables A and B is shown. All the rows from both tables are included in the result set, with NULL values in the columns where there is no match.</li> <li>Left Outer Join or Left Excluding Join: This join returns all the rows from the left table that do not have a matching row in the right table. In the image, the result of a left outer join (or left excluding join) between tables A and B is shown. Only the rows from table A that do not have a matching row in table B are included in the result set.</li> <li>Right Outer Join or Right Excluding Join: This join returns all the rows from the right table that do not have a matching row in the left table. In the image, the result of a right outer join (or right excluding join) between tables A and B is shown. Only the rows from table B that do not have a matching row in table A are included in the result set.</li> </ul>"},{"location":"sql/17_joins/#some-examples-on-mysql-employees-database","title":"Some examples on MySQL Employees Database","text":""},{"location":"sql/17_joins/#inner-join","title":"Inner Join","text":"<p>An inner join returns only the rows that have matching values in both tables being joined. The syntax for an inner join is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nINNER JOIN table2\nON table1.column = table2.column;\n</code></pre> <p>In this syntax, the <code>INNER JOIN</code> keyword specifies that an inner join is being performed. The <code>ON</code> keyword specifies the condition for joining the tables. The columns being joined must have the same data type and contain similar data.</p> <p>Here's an example of an inner join that combines data from the \"employees\" and \"departments\" tables:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nINNER JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The INNER JOIN operator links the \"employees\" and \"departments\" tables on the \"dept_no\" column, and returns only the rows where there is a match between the two tables.</p>"},{"location":"sql/17_joins/#left-join","title":"Left Join","text":"<p>A left join returns all the rows from the left table and the matching rows from the right table. If there are no matching rows in the right table, the result set will contain NULL values for the columns in the right table. The syntax for a left join is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nLEFT JOIN table2\nON table1.column = table2.column;\n</code></pre> <p>In this syntax, the <code>LEFT JOIN</code> keyword specifies that a left join is being performed. The ON keyword specifies the condition for joining the tables.</p> <p>Here's an example of a left join that combines data from the <code>employees</code> and <code>departments</code> tables:</p> <p><pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nLEFT JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The <code>LEFT JOIN</code> operator links the <code>employees</code> and <code>departments</code> tables on the <code>dept_no</code> column, and returns all the rows from the <code>employees</code> table, and the matching rows from the <code>departments</code> table.</p>"},{"location":"sql/17_joins/#right-join","title":"Right Join","text":"<p>A right join returns all the rows from the right table and the matching rows from the left table. If there are no matching rows in the left table, the result set will contain <code>NULL</code> values for the columns in the left table. </p> <p>Here's an example of a right join that combines data from the <code>employees</code> and <code>departments</code> tables:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nRIGHT JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The <code>RIGHT JOIN</code> operator links the <code>employees</code> and <code>departments</code> tables on the <code>dept_no</code> column, and returns all the rows from the <code>departments</code> table, and the matching rows from the <code>employees</code> table.</p>"},{"location":"sql/17_joins/#full-outer-join","title":"Full Outer Join","text":"<p>A full outer join returns all the rows from both tables being joined, and <code>NULL</code> values for the columns that do not have matching values in the other table. The syntax for a full outer join varies depending on the database management system being used. In MySQL, a full outer join can be simulated using a combination of left join and union operators:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nLEFT JOIN departments\nON employees.dept_no = departments.dept_no\nUNION\nSELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nRIGHT JOIN departments\nON employees.dept_no = departments.dept_no\nWHERE employees.dept_no IS NULL;\n</code></pre> <p>This query combines the results of a <code>left join</code> and a <code>right join</code> to simulate a full outer join. The first <code>SELECT</code> statement performs a <code>left join</code> and returns all the rows from the <code>employees</code> table and the matching rows from the <code>departments</code> table. The second <code>SELECT</code> statement performs a right join and returns all the rows from the <code>departments</code> table and the matching rows from the <code>employees</code> table where there is no match in the <code>employees</code> table. The <code>UNION</code> operator combines the results of the two <code>SELECT</code> statements.</p> <p>This is the same version with the <code>full outer join</code> keyword : </p> <p><pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nFULL OUTER JOIN departments\nON employees.dept_no = departments.dept_no\nWHERE employees.dept_no IS NULL OR departments.dept_no IS NULL;\n</code></pre> In this query, the <code>FULL OUTER JOIN</code> returns all the rows from both tables, including those that do not have a match in the other table. The <code>WHERE</code> clause filters the result set to include only the rows where either the <code>employees.dept_no</code> or <code>departments.dept_no</code> is <code>NULL</code>, which indicates that there is no match in the other table.</p>"},{"location":"sql/17_joins/#more-examples-of-left-join-inner-join-and-right-join","title":"More examples of <code>left join</code>, <code>inner join</code> and <code>right join</code>","text":""},{"location":"sql/17_joins/#inner-join-example-1","title":"Inner Join Example 1","text":"<p>Suppose you want to retrieve data that shows the salary of each employee along with the department name for the department they work in. You can use an inner join to link the <code>employees</code> and <code>dept_emp</code> tables on the <code>emp_no</code> column and the <code>departments</code> and <code>dept_emp</code> tables on the <code>dept_no</code> column:</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, d.dept_name, s.salary\nFROM employees e\nINNER JOIN dept_emp de ON e.emp_no = de.emp_no\nINNER JOIN departments d ON de.dept_no = d.dept_no\nINNER JOIN salaries s ON e.emp_no = s.emp_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, department name, and salary for each employee. The <code>INNER JOIN</code> operator links the <code>employees</code> and <code>dept_emp</code> tables on the <code>emp_no</code> column, and links the <code>departments</code> and <code>dept_emp</code> tables on the <code>dept_no</code> column, and links the <code>salaries</code> table on the <code>emp_no</code> column.</p>"},{"location":"sql/17_joins/#inner-join-example-2","title":"Inner Join Example 2","text":"<p>Suppose you want to retrieve data that shows the department name and manager's name for each department in the company. You can use an inner join to link the <code>departments</code> and <code>dept_manager</code> tables on the <code>dept_no</code> column, and link the <code>employees</code> table on the <code>emp_no</code> column to get the name of the manager:</p> <pre><code>SELECT d.dept_name, e.first_name, e.last_name\nFROM departments d\nINNER JOIN dept_manager dm ON d.dept_no = dm.dept_no\nINNER JOIN employees e ON dm.emp_no = e.emp_no;\n</code></pre> <p>This query returns a result set that includes the department name and the first and last name of the manager for each department. The INNER JOIN operator links the \"departments\" and \"dept_manager\" tables on the \"dept_no\" column, and links the \"employees\" table on the \"emp_no\" column to get the name of the manager.</p>"},{"location":"sql/17_joins/#left-join-example-1","title":"Left Join Example 1","text":"<p>Suppose you want to retrieve data that shows the name and department of each employee, even if they are not currently assigned to a department. You can use a left join to link the \"employees\" and \"dept_emp\" tables on the \"emp_no\" column, and link the \"departments\" table on the \"dept_no\" column:</p> <pre><code>SELECT e.first_name, e.last_name, d.dept_name\nFROM employees e\nLEFT JOIN dept_emp de ON e.emp_no = de.emp_no\nLEFT JOIN departments d ON de.dept_no = d.dept_no;\n</code></pre> <p>This query returns a result set that includes the first name, last name, and department name for each employee. The LEFT JOIN operator links the \"employees\" and \"dept_emp\" tables on the \"emp_no\" column, and links the \"departments\" table on the \"dept_no\" column. Even if an employee is not currently assigned to a department, their name will still appear in the result set with a NULL value for the \"dept_name\" column.</p>"},{"location":"sql/17_joins/#left-join-example-2","title":"Left Join Example 2","text":"<p>Suppose you want to retrieve data that shows the total number of sales made by each employee, even if they have not made any sales. You can use a left join to link the \"employees\" and \"sales\" tables on the \"emp_no\" column:</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, COUNT(s.sales_amount) as total_sales\nFROM employees e\nLEFT JOIN sales s ON e.emp_no = s.emp_no\nGROUP BY e.emp_no;\n</code></pre>"},{"location":"sql/17_joins/#right-join-example-1","title":"Right Join Example 1","text":"<p>Retrieving data that shows the name and department of each employee, even if the department has no employees assigned to it.</p> <pre><code>SELECT e.first_name, e.last_name, d.dept_name\nFROM dept_emp de\nRIGHT JOIN employees e ON de.emp_no = e.emp_no\nRIGHT JOIN departments d ON de.dept_no = d.dept_no;\n</code></pre>"},{"location":"sql/17_joins/#right-join-example-2","title":"Right Join Example 2","text":"<p>Retrieving data that shows the total number of sales made by each employee, even if they have not made any sales.</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, COUNT(s.sales_amount) as total_sales\nFROM sales s\nRIGHT JOIN employees e ON s.emp_no = e.emp_no\nGROUP BY e.emp_no;\n</code></pre>"},{"location":"sql/17_joins/#conclusion","title":"Conclusion","text":"<p>Joins are an essential tool in SQL for retrieving data that is spread across multiple tables in a relational database. There are several types of joins available, including <code>inner join</code>, <code>left join</code>, <code>right join</code>, and <code>full outer join</code>. By understanding how to use joins in SQL, you can retrieve complex data from a database and link related data together.</p>"},{"location":"sql/18_Nested_Queries/","title":"Nested Queries","text":""},{"location":"sql/18_Nested_Queries/#introduction-to-nested-queries","title":"Introduction to Nested Queries","text":"<p>A nested query, also known as a subquery, is a query that is nested inside another query. A subquery can be used to retrieve data that will be used in the main query, allowing for complex queries that would be difficult to write using a single query. Subqueries can be used with various clauses in SQL, such as <code>SELECT</code>, <code>WHERE</code>, and <code>HAVING</code>.</p>"},{"location":"sql/18_Nested_Queries/#overview-of-how-to-use-subqueries","title":"Overview of How to Use Subqueries","text":"<p>A subquery is typically enclosed in parentheses and used in conjunction with an operator such as <code>IN</code>, <code>EXISTS</code>, or <code>=.</code> The subquery can be used in various parts of a query, depending on the desired result.</p> <p>Here's an example of a subquery used in a <code>SELECT</code> statement: <pre><code>SELECT first_name, last_name, birth_date\nFROM employees\nWHERE birth_date &gt; (SELECT birth_date FROM employees WHERE emp_no = 10001);\n</code></pre> This query returns a result set that includes the first name, last name, and birth date for each employee whose birth date is later than that of the employee with <code>emp_no = 10001</code>. The subquery is used in the <code>WHERE</code> clause to retrieve the birth date of the employee with <code>emp_no = 10001</code>.</p> <p>Here's an example of a subquery used in a <code>HAVING</code> clause: <pre><code>SELECT departments.dept_name, AVG(salaries.salary) AS avg_salary\nFROM employees\nINNER JOIN dept_emp ON employees.emp_no = dept_emp.emp_no\nINNER JOIN departments ON dept_emp.dept_no = departments.dept_no\nINNER JOIN salaries ON employees.emp_no = salaries.emp_no\nGROUP BY departments.dept_name\nHAVING AVG(salaries.salary) &gt; (SELECT AVG(salary) FROM salaries);\n</code></pre></p> <p>This query joins the employees, salaries, dept_emp, and departments tables together based on the employee number, department number, and salary information. It then groups the results by department name using the <code>GROUP BY</code> clause and calculates the average salary for each department using the <code>AVG</code> function.</p> <p>The <code>HAVING</code> clause is used to filter the results based on the condition that the average salary for a department is greater than the overall average salary of all employees, which is calculated using a subquery that selects the average salary from the salaries table.</p>"},{"location":"sql/18_Nested_Queries/#some-examples-with-mysql-employees-database","title":"Some examples with MySQL Employees database","text":""},{"location":"sql/18_Nested_Queries/#example-1-retrieving-data-for-employees-who-are-currently-managers","title":"Example 1: Retrieving data for employees who are currently managers","text":"<p><pre><code>SELECT first_name, last_name, hire_date\nFROM employees\nWHERE emp_no IN (\nSELECT emp_no\nFROM dept_manager\n);\n</code></pre> This query returns a result set that includes the first name, last name, and hire date for each employee who is currently a manager. The subquery is used in the WHERE clause to retrieve the employee numbers of all employees who are currently department managers.</p>"},{"location":"sql/18_Nested_Queries/#example-2-retrieving-data-for-employees-who-were-hired-in-the-same-year-as-a-specific-employee","title":"Example 2: Retrieving data for employees who were hired in the same year as a specific employee","text":"<p><pre><code>SELECT first_name, last_name, hire_date\nFROM employees\nWHERE YEAR(hire_date) = (\nSELECT YEAR(hire_date)\nFROM employees\nWHERE emp_no = 10001\n);\n</code></pre> This query returns a result set that includes the first name, last name, and hire date for each employee who was hired in the same year as the employee with emp_no = 10001. The subquery is used in the WHERE clause to retrieve the year in which the employee with emp_no = 10001 was hired.</p>"},{"location":"sql/18_Nested_Queries/#example-3-find-the-10th-employee-with-the-highest-salary-along-with-their-job-title","title":"Example 3: Find the 10th employee with the highest salary, along with their job title","text":"<pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, MAX(salaries.salary) AS max_salary, MAX(titles.title) AS title\nFROM employees\nJOIN salaries ON employees.emp_no = salaries.emp_no\nJOIN titles ON employees.emp_no = titles.emp_no\nGROUP BY employees.emp_no\nORDER BY max_salary DESC\nLIMIT 10; </code></pre> <p>The query starts by selecting specific columns from the employees table, including the employee number, first name, and last name. It then joins the salaries and titles tables to the employees table based on the employee number, using the <code>JOIN</code> clause. The <code>MAX</code> function is used to find the maximum salary and job title for each employee.</p> <p>The <code>GROUP BY</code> clause is used to group the results by employee number. This ensures that the maximum salary and job title returned for each employee correspond to the same person. The <code>ORDER BY</code> clause is used to sort the results in descending order based on the maximum salary, so that the employee with the highest salary is at the top.</p> <p>Finally, the <code>LIMIT</code> clause is used to limit the results to only the top row, which corresponds to the employee with the highest salary.</p>"},{"location":"sql/18_Nested_Queries/#wrap-up","title":"Wrap-up","text":"<p>Nested queries, or subqueries, are a powerful tool in SQL that allows for complex queries to be written by breaking them down into smaller, more manageable queries. Subqueries can be used in various parts of a query, including <code>SELECT</code>, <code>WHERE</code>, and <code>HAVING</code> clauses. By understanding how to use subqueries in SQL, you can write more complex queries and retrieve more specific data from a database.</p> <p>Here's a summary of what we've learned about nested queries in SQL:</p> <ul> <li>A nested query, also known as a subquery, is a query that is nested inside another query.</li> <li>Subqueries can be used in various parts of a query, such as SELECT, WHERE, and HAVING clauses.</li> <li>Subqueries are typically enclosed in parentheses and used in conjunction with an operator such as IN, EXISTS, or =.</li> <li>Subqueries can be used to retrieve data that will be used in the main query, allowing for complex queries that would be difficult to write using a single query.</li> <li>Examples of subqueries include retrieving data for employees who are currently managers, retrieving data for employees who were hired in the same year as a specific employee, and retrieving data for departments with the highest average salary.</li> <li>Understanding how to use subqueries in SQL can help you write more complex queries and retrieve more specific data from a database.</li> </ul>"},{"location":"sql/19_delete/","title":"On delete","text":""},{"location":"sql/19_delete/#introduction-to-on-delete","title":"Introduction to ON DELETE","text":"<p><code>ON DELETE</code> is a referential action that can be applied to foreign key constraints in SQL. It specifies what should happen to data in the child table when a row is deleted from the parent table. The different options available for <code>ON DELETE</code> include <code>CASCADE</code>, <code>SET NULL</code>, <code>RESTRICT</code>, and <code>NO ACTION</code>. Using <code>ON DELETE</code> is important for maintaining data integrity in a database.</p>"},{"location":"sql/19_delete/#overview-of-how-to-use-on-delete","title":"Overview of How to Use ON DELETE","text":"<p>Here's an example of creating a foreign key with <code>ON DELETE CASCADE</code> in SQL: <pre><code>ALTER TABLE employees\nADD CONSTRAINT emp_dept_fk\nFOREIGN KEY (dept_no)\nREFERENCES departments (dept_no)\nON DELETE CASCADE;\n</code></pre></p> <p>In this example, a foreign key constraint named \"emp_dept_fk\" is added to the \"employees\" table. The foreign key references the \"dept_no\" column in the \"departments\" table, and specifies \"ON DELETE CASCADE.\" This means that when a row is deleted from the \"departments\" table, any corresponding rows in the \"employees\" table will also be deleted.</p> <p>Here's an example of creating a foreign key with \"ON DELETE SET NULL\" in SQL:</p> <pre><code>ALTER TABLE employees\nADD CONSTRAINT emp_manager_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE SET NULL;\n</code></pre> <p>In this example, a foreign key constraint named \"emp_manager_fk\" is added to the \"employees\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE SET NULL.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in other tables will have the foreign key column value set to NULL.</p> <p>Here's an example of creating a foreign key with \"ON DELETE RESTRICT\" in SQL: <pre><code>ALTER TABLE departments\nADD CONSTRAINT dept_manager_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE RESTRICT;\n</code></pre></p> <p>In this example, a foreign key constraint named \"dept_manager_fk\" is added to the \"departments\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE RESTRICT.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in the \"departments\" table cannot be deleted.</p> <p>Here's an example of creating a foreign key with \"ON DELETE NO ACTION\" in SQL: <pre><code>ALTER TABLE dept_emp\nADD CONSTRAINT dept_emp_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE NO ACTION;\n</code></pre></p> <p>In this example, a foreign key constraint named \"dept_emp_fk\" is added to the \"dept_emp\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE NO ACTION.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in the \"dept_emp\" table will cause an error and the delete operation will be rejected.</p>"},{"location":"sql/19_delete/#conclusion","title":"Conclusion","text":"<p>Using \"ON DELETE\" in SQL is important for maintaining data integrity in a database. The different options available for \"ON DELETE\" include \"CASCADE,\" \"SET NULL,\" \"RESTRICT,\" and \"NO ACTION.\" By understanding how to use \"ON DELETE\" in SQL, you can ensure that your database remains consistent and accurate over time.</p>"},{"location":"sql/20_triggers/","title":"Triggers","text":""},{"location":"sql/20_triggers/#introduction-to-triggers-in-sql","title":"Introduction to Triggers in SQL","text":"<p>In SQL, a trigger is a special kind of stored program that is automatically executed in response to specific events or actions that occur within a database. Triggers can be used to automate tasks, maintain data integrity, and enforce business rules. They are often used in conjunction with other SQL features, such as constraints and indexes, to ensure that a database remains consistent and accurate over time.</p>"},{"location":"sql/20_triggers/#overview-of-how-to-use-triggers-to-automate-tasks","title":"Overview of How to Use Triggers to Automate Tasks","text":"<p>Here's an example of creating a trigger in SQL that automatically sets the \"to_date\" field of a row in the \"dept_emp\" table to the current date whenever a new row is inserted:</p> <pre><code>CREATE TRIGGER update_dept_emp_to_date\nBEFORE INSERT ON dept_emp\nFOR EACH ROW\nSET NEW.to_date = NOW();\n</code></pre> <p>In this example, a trigger named \"update_dept_emp_to_date\" is created using the CREATE TRIGGER statement. The trigger is defined to execute \"BEFORE INSERT\" on the \"dept_emp\" table, and is set to execute \"FOR EACH ROW\" that is inserted. The body of the trigger consists of a single statement that sets the value of the \"to_date\" field for the newly inserted row to the current date and time, using the NOW() function.</p> <p>Here's an example of creating a trigger in SQL that prevents the deletion of a row in the \"employees\" table if that row is currently assigned to a department: <pre><code>CREATE TRIGGER prevent_emp_delete\nBEFORE DELETE ON employees\nFOR EACH ROW\nBEGIN\nDECLARE dept_count INT;\nSELECT COUNT(*) INTO dept_count\nFROM dept_emp\nWHERE emp_no = OLD.emp_no;\nIF dept_count &gt; 0 THEN\nSIGNAL SQLSTATE '45000'\nSET MESSAGE_TEXT = 'Cannot delete employee who is currently assigned to a department.';\nEND IF;\nEND;\n</code></pre></p> <p>In this example, a trigger named \"prevent_emp_delete\" is created using the CREATE TRIGGER statement. The trigger is defined to execute \"BEFORE DELETE\" on the \"employees\" table, and is set to execute \"FOR EACH ROW\" that is deleted. The body of the trigger consists of a block of code that checks whether the employee being deleted is currently assigned to a department, and if so, raises an error using the SIGNAL statement to prevent the delete operation.</p>"},{"location":"sql/20_triggers/#examples-of-using-triggers-on-the-employees-database","title":"Examples of using triggers on the employees database","text":""},{"location":"sql/20_triggers/#example-1-audit-trail-for-changes-to-the-employees-table","title":"Example 1: Audit trail for changes to the employees table","text":"<pre><code>CREATE TABLE employees_audit (\naction VARCHAR(50) NOT NULL,\nemp_no INT NOT NULL,\nlast_name VARCHAR(50) NOT NULL,\nfirst_name VARCHAR(50) NOT NULL,\ntimestamp DATETIME DEFAULT NOW()\n);\nDELIMITER //\nCREATE TRIGGER employees_audit_insert\nAFTER INSERT ON employees\nFOR EACH ROW\nBEGIN\nINSERT INTO employees_audit (action, emp_no, last_name, first_name)\nVALUES ('insert', NEW.emp_no, NEW.last_name, NEW.first_name);\nEND//\nCREATE TRIGGER employees_audit_update\nAFTER UPDATE ON employees\nFOR EACH ROW\nBEGIN\nINSERT INTO employees_audit (action, emp_no, last_name, first_name)\nVALUES ('update', NEW.emp_no, NEW.last_name, NEW.first_name);\nEND//\nCREATE TRIGGER employees_audit_delete\nAFTER DELETE ON employees\nFOR EACH ROW\nBEGIN\nINSERT INTO employees_audit (action, emp_no, last_name, first_name)\nVALUES ('delete', OLD.emp_no, OLD.last_name, OLD.first_name);\nEND//\nDELIMITER ;\n</code></pre> <p>In this example, a new table \"employees_audit\" is created to store an audit trail of changes to the \"employees\" table. Three triggers are then defined using the CREATE TRIGGER statement to execute after each insert, update, and delete operation on the \"employees\" table. These triggers use the INSERT statement to add a new row to the \"employees_audit\" table that records the action, employee number, last name, first name, and timestamp of the change.</p>"},{"location":"sql/20_triggers/#example-2-preventing-changes-to-the-departments-table","title":"Example 2: Preventing changes to the departments table","text":"<pre><code>CREATE TRIGGER prevent_dept_change\nBEFORE UPDATE ON departments\nFOR EACH ROW\nBEGIN\nSIGNAL SQLSTATE '45000'\nSET MESSAGE_TEXT = 'Changes to departments table are not allowed.';\nEND;\n</code></pre> <p>In this example, a trigger named \"prevent_dept_change\" is defined using the CREATE TRIGGER statement to execute before any update operation on the \"departments\" table. The body of the trigger consists of a single statement that raises an error using the SIGNAL statement to prevent the update operation.</p>"},{"location":"sql/20_triggers/#example-3-automatic-promotion-to-manager-for-department-heads","title":"Example 3: Automatic promotion to manager for department heads","text":"<pre><code>CREATE TRIGGER promote_to_manager\nAFTER UPDATE ON dept_manager\nFOR EACH ROW\nBEGIN\nIF NEW.to_date = '9999-01-01' THEN\nUPDATE employees SET emp_title = 'Manager' WHERE emp_no = NEW.emp_no;\nEND IF;\nEND;\n</code></pre> <p>In this example, a trigger named \"promote_to_manager\" is defined using the CREATE TRIGGER statement to execute after any update operation on the \"dept_manager\" table. The body of the trigger consists of an IF statement that checks whether the \"to_date\" field for the updated row is set to the special value of '9999-01-01', which indicates that the employee is currently a department head. If so, the trigger uses the UPDATE statement to change the employee's title to \"Manager\" in the \"employees\" table.</p>"},{"location":"sql/20_triggers/#why-triggers-are-important-for-data-analysis-job","title":"Why triggers are important for data analysis job","text":"<p>Triggers are important in data analysis because they allow you to automate tasks and enforce data integrity rules within a database. By using triggers, you can ensure that data is consistent and accurate over time, and that business rules are enforced consistently across different operations and users.</p> <p>For example, if you are analyzing sales data in a database, you might use triggers to automatically update certain fields or tables whenever new sales data is added or existing data is updated. You could also use triggers to prevent certain types of changes to the database, or to notify you when certain events occur.</p> <p>By automating tasks and enforcing rules using triggers, you can save time and reduce the risk of errors or inconsistencies in your data. This can help you to make more informed decisions and gain deeper insights into the patterns and trends in your data.</p> <p>Overall, triggers are an important tool for data analysts and other database professionals who need to ensure the accuracy and integrity of their data. By mastering the use of triggers in SQL, you can become more effective at managing and analyzing data in a wide range of contexts.</p>"},{"location":"sql/20_triggers/#conclusion","title":"Conclusion","text":"<p>Using triggers in SQL is a powerful way to automate tasks, maintain data integrity, and enforce business rules. Triggers can be used to respond to specific events or actions that occur within a database, and can be defined to execute before or after specific operations such as inserts, updates, and deletes. By understanding how to use triggers in SQL, you can ensure that your database remains consistent and accurate over time.</p>"},{"location":"sql/21_er_diagrams/","title":"ER Diagrams","text":""},{"location":"sql/21_er_diagrams/#explanation-of-er-diagrams-and-their-importance","title":"Explanation of ER Diagrams and their Importance","text":"<p>ER (Entity-Relationship) diagrams are a visual representation of the relationships between entities (tables) in a database. They are an important tool for designing and managing databases, as they provide a clear and concise way to understand how different tables are related to each other.</p> <p>ER diagrams are used to model and plan database structures, to optimize data retrieval and to make queries more efficient. They are also used to help non-technical stakeholders understand the relationships between data tables, as they provide a simple and visual way to communicate complex data structures.</p>"},{"location":"sql/21_er_diagrams/#overview-of-how-to-use-er-diagrams-to-visualize-data","title":"Overview of How to Use ER Diagrams to Visualize Data","text":"<p>ER diagrams consist of entities (tables) and relationships (connections between tables), and are created using a set of symbols and rules. Entities are represented as rectangles, and relationships are represented as lines connecting the entities.</p> <p>Here's an example of an ER diagram for our employees database: </p> <p>You can see the full documentation of the database on the official page here</p> <p>In this diagram, the rectangles represent entities (tables), and the lines connecting the entities represent relationships between them. The relationships are labeled with the type of relationship (e.g. \"belongs to\", \"manages\", etc.), and with cardinality symbols that indicate the minimum and maximum number of instances of one entity that can be related to instances of the other entity.</p> <p>ER diagrams can be used to model complex relationships between tables, including one-to-one, one-to-many, and many-to-many relationships. They can also be used to represent subtypes and supertypes, and to define constraints and business rules that govern the relationships between entities.</p> <p>By using ER diagrams to visualize data, you can better understand the structure of your database and optimize your queries for maximum efficiency. ER diagrams can also be used to communicate complex data structures to non-technical stakeholders, helping to ensure that everyone involved in your data analysis projects has a common understanding of the data structures and relationships at play.</p>"},{"location":"sql/21_er_diagrams/#in-depth-look-at-how-to-design-an-er-diagram","title":"In-depth Look at How to Design an ER Diagram","text":"<p>The process of designing an ER (Entity-Relationship) diagram involves identifying the entities (tables) that will be included in the database, and determining the relationships between them. This process is crucial for building a database that is efficient, accurate, and easy to work with.</p> <p>Here are the steps involved in designing an ER diagram:</p> <ul> <li>Identify the entities: Start by identifying the different entities (tables) that will be included in the database. These might include things like customers, products, orders, and so on.</li> <li>Determine the attributes: For each entity, determine the attributes (columns) that will be included in the table. These might include things like names, addresses, dates, and so on.</li> <li>Determine the relationships: Once you have identified the entities and their attributes, determine the relationships between them. For example, a customer might place many orders, or an order might contain many products.</li> <li>Choose the cardinality: For each relationship, determine the cardinality, or how many instances of one entity can be related to instances of another entity. This might be one-to-one, one-to-many, or many-to-many.</li> <li>Choose the modality: For each relationship, determine the modality, or whether the relationship is mandatory or optional. This might be represented using symbols such as \"1\" for mandatory or \"0\" for optional.</li> <li>Create the ER diagram: Finally, create the ER diagram using symbols and conventions that represent the entities, attributes, and relationships. These might include rectangles for entities, diamonds for relationships, and lines connecting them.</li> </ul>"},{"location":"sql/21_er_diagrams/#explanation-of-different-entities-attributes-and-relationships","title":"Explanation of Different Entities, Attributes, and Relationships","text":"<p>In ER diagrams, entities are represented as rectangles, attributes are represented as ovals, and relationships are represented as diamonds. Here's a brief explanation of each:</p> <ul> <li>Entities: Entities represent tables in the database. Each entity has a name and a set of attributes that define the data it contains.</li> <li>Attributes: Attributes represent the columns within an entity. They define the specific data that the entity contains, such as names, addresses, and dates.</li> <li>Relationships: Relationships represent the connections between entities. They define how different entities are related to each other, and the cardinality and modality of the relationship.</li> </ul>"},{"location":"sql/21_er_diagrams/#some-common-types-of-relationships-that-you-might-encounter-in-er-diagrams-include","title":"Some common types of relationships that you might encounter in ER diagrams include:","text":"<ul> <li>One-to-one: One instance of an entity is related to only one instance of another entity.</li> <li>One-to-many: One instance of an entity is related to multiple instances of another entity.</li> <li>Many-to-many: Multiple instances of an entity are related to multiple instances of another entity.</li> </ul> <p>By understanding the different entities, attributes, and relationships involved in an ER diagram, you can design a database that is efficient, accurate, and easy to work with. This can help you to analyze and manage your data more effectively, and to gain deeper insights into the patterns and trends in your data.</p>"},{"location":"sql/21_er_diagrams/#explanation-of-how-to-convert-er-diagrams-to-database-schemas","title":"Explanation of How to Convert ER Diagrams to Database Schemas","text":"<p>Once you have designed an ER (Entity-Relationship) diagram for your database, the next step is to convert it into a database schema. This involves creating tables and relationships that reflect the structure and relationships defined in the ER diagram.</p> <p>Here are the steps involved in converting an ER diagram to a database schema:</p> <ul> <li>Identify the tables: Start by identifying the tables that will be created based on the entities in the ER diagram. For example, if the ER diagram has an entity called \"Employees\", create a table called \"Employees\" in the database.</li> <li>Create the columns: For each table, create the columns that reflect the attributes of the entity in the ER diagram. For example, if the \"Employees\" entity has attributes such as \"Employee Number\", \"First Name\", and \"Last Name\", create columns in the \"Employees\" table with these same names and data types.</li> <li>Define the relationships: Once the tables and columns are created, define the relationships between the tables based on the relationships in the ER diagram. For example, if the \"Employees\" entity is related to the \"Departments\" entity in the ER diagram, create a foreign key column in the \"Employees\" table that references the primary key column in the \"Departments\" table.</li> <li>Specify the constraints: Finally, specify any constraints or rules that are defined in the ER diagram, such as unique constraints or not-null constraints.</li> <li>Overview of How to Create Tables and Relationships Based on the ER Diagram</li> </ul>"},{"location":"sql/21_er_diagrams/#example-of-how-to-convert-the-er-diagram-for-the-employees-database-into-a-database-schema","title":"Example of how to convert the ER diagram for the Employees database into a database schema:","text":"<ul> <li>Identify the tables: Based on the ER diagram, we need to create tables for employees, departments, titles, salaries, and more.</li> <li>Create the columns: For the \"Employees\" table, we need to create columns such as \"emp_no\", \"birth_date\", \"first_name\", \"last_name\", \"gender\", and \"hire_date\". For the \"Departments\" table, we need to create columns such as \"dept_no\" and \"dept_name\". For the other tables, we would create columns based on the attributes defined in the ER diagram.</li> <li>Define the relationships: Based on the ER diagram, we know that employees are related to departments, titles, and salaries. To define these relationships, we would create foreign key columns in the \"Employees\" table that reference the primary key columns in the other tables. For example, the \"Employees\" table would have a foreign key column called \"dept_no\" that references the \"dept_no\" column in the \"Departments\" table.</li> <li>Specify the constraints: We would specify any constraints or rules that are defined in the ER diagram, such as unique constraints or not-null constraints. For example, we might specify that the \"emp_no\" column in the \"Employees\" table must be unique and not-null.</li> </ul> <p>By converting the ER diagram to a database schema in this way, we can create a database that accurately reflects the structure and relationships defined in the ER diagram. This can help us to manage and analyze data more effectively, and to gain deeper insights into the patterns and trends in our data.</p>"},{"location":"sql/21_er_diagrams/#wrap-up","title":"Wrap-up","text":"<p>Let's summarize what we've learn about ER diagrams : </p> <ul> <li>ER diagrams, or Entity-Relationship diagrams, are visual representations of data models that show the relationships between different entities, such as tables in a database.</li> <li>ER diagrams help to simplify complex data structures and make them easier to understand by providing a high-level view of the data and its relationships.</li> <li>ER diagrams can help companies to design more effective databases by providing a clear picture of how data is structured and related, and can help to identify areas for optimization or improvement.</li> <li>ER diagrams are important in the development process of software and databases, as they provide a blueprint for developers to follow when building and maintaining data systems.</li> <li>ER diagrams can be used to facilitate communication between stakeholders, such as developers, designers, project managers, and business users, by providing a common language and visual reference point for discussing the data model.</li> <li>By using ER diagrams to design and maintain their data models, companies can improve the accuracy, efficiency, and reliability of their data systems, which in turn can lead to better decision-making, cost savings, and increased competitiveness in the marketplace.</li> </ul>"},{"location":"sql/22_Python_SQLAlchemy/","title":"Python and SQLAlchemy","text":"<p>SQLAlchemy is an open-source library for Python that provides a way to work with relational databases. It allows you to interact with databases using a high-level object-oriented interface, rather than writing SQL code directly. </p>"},{"location":"sql/22_Python_SQLAlchemy/#explanation-of-what-sqlalchemy-is-and-its-benefits-for-working-with-databases","title":"Explanation of What SQLAlchemy is and Its Benefits for Working with Databases","text":"<p>SQLAlchemy provides several benefits for working with databases, including:</p> <ul> <li>Abstraction: SQLAlchemy provides a layer of abstraction between the application and the database, which makes it easier to switch between different databases without changing the application code.</li> <li>Flexibility: SQLAlchemy allows you to work with databases using an object-oriented paradigm, which can be more flexible than using SQL directly.</li> <li>Portability: SQLAlchemy is a Python library, which means it can be used on any platform that supports Python, including Windows, Mac, and Linux.</li> <li>Security: SQLAlchemy includes built-in security features, such as support for parameterized queries, which can help protect against SQL injection attacks.</li> </ul>"},{"location":"sql/22_Python_SQLAlchemy/#overview-of-sqlalchemy-concepts-and-how-they-relate-to-sql","title":"Overview of SQLAlchemy Concepts and How They Relate to SQL","text":"<p>SQLAlchemy provides several concepts that are used to work with databases, including:</p> <ul> <li>Engine: The Engine is the entry point for working with a database. It provides a way to connect to the database and execute SQL commands.</li> <li>Connection: A Connection is an instance of a connection to the database. It allows you to execute SQL commands and manage transactions.</li> <li>Transaction: A Transaction is a sequence of SQL commands that are executed as a single unit of work. Transactions provide a way to ensure that multiple SQL commands are executed atomically.</li> <li>Session: A Session is a high-level object that provides an interface for working with a database. It provides a way to manage database operations, such as creating, updating, and deleting records.</li> <li>Model: A Model is a Python class that represents a table in the database. It provides a way to interact with the data in the table using Python code.</li> </ul>"},{"location":"sql/22_Python_SQLAlchemy/#sqlalchemy-installation","title":"SQLAlchemy installation","text":"<p>The first step is to install SQLAlchemy. You can install it using pip, the Python package manager. Open a terminal or command prompt and type the following command: <pre><code>pip install sqlalchemy\n</code></pre> This will download and install the latest version of SQLAlchemy. You can verify the installation with this command on your terminal :  <pre><code>pip list | grep sqlalchemy\n</code></pre></p>"},{"location":"sql/22_Python_SQLAlchemy/#install-a-mysql-database-connector","title":"Install a MySQL database connector","text":"<p>In order to connect to a MySQL database, you'll need to install a database connector (we will see later that we can connect multiple databases not only MySQL). There are several available, but the most popular one is <code>mysql-connector-python</code>. You can install it using pip: <pre><code>pip install mysql-connector-python\n</code></pre></p>"},{"location":"sql/22_Python_SQLAlchemy/#verify-the-connection","title":"Verify the connection","text":"<p>Now that you have both SQLAlchemy and the MySQL connector installed, you can connect to your MySQL database. First, import the necessary modules: <pre><code>from sqlalchemy import create_engine\nimport mysql.connector\n</code></pre> Next, create an engine that connects to your MySQL database: <pre><code>engine = create_engine('mysql+mysqlconnector://user:password@host:port/database')\n</code></pre> Replace <code>user</code> and <code>password</code> with your MySQL <code>username</code> and <code>password</code>, host with the hostname or IP address of your MySQL server, <code>port</code> with the <code>port</code> number (usually 3306), and database with the name of the database you want to connect to.</p>"},{"location":"sql/22_Python_SQLAlchemy/#databases-supports","title":"Databases supports","text":"<p>SQLAlchemy supports a variety of different database connections, each with its own advantages and use cases. Here's an overview of some of the most common connection types with the <code>engine</code> object:</p>"},{"location":"sql/22_Python_SQLAlchemy/#sqlite","title":"SQLite","text":"<p>SQLite is a serverless, file-based database that is popular for small to medium-sized projects. SQLAlchemy provides a SQLite dialect that allows you to work with SQLite databases in Python. Since SQLite is a file-based database, it is relatively easy to set up and use, and is a good choice for applications that don't require a lot of concurrent users or high write volumes.</p> <p><pre><code>from sqlalchemy import create_engine\nengine = create_engine('sqlite:///mydatabase.db')\n</code></pre> In this example, we use the create_engine() function to create an engine object that connects to a SQLite database file named mydatabase.db.</p>"},{"location":"sql/22_Python_SQLAlchemy/#mysql","title":"MySQL","text":"<p>MySQL is a popular open-source relational database system that is commonly used for web applications. SQLAlchemy provides a MySQL dialect that allows you to work with MySQL databases in Python. MySQL is a good choice for applications that require scalability and performance, since it can handle high volumes of reads and writes.</p> <p><pre><code>from sqlalchemy import create_engine\nengine = create_engine('mysql+pymysql://username:password@host:port/database')\n</code></pre> In this example, we use the create_engine() function to create an engine object that connects to a MySQL database named database running on a <code>host</code> with the specified <code>username</code>, <code>password</code>, <code>host</code>, and <code>port</code>. In our case we will be connection our <code>localhost</code>, so we can re write this command as follow :  <pre><code>engine = create_engine('mysql+mysqlconnector://user:password@localhost/database')\n</code></pre></p>"},{"location":"sql/22_Python_SQLAlchemy/#use-mamp-sql-server-on-mac-os","title":"Use MAMP SQL Server on Mac OS","text":"<p>In case you have this error :  <pre><code>ModuleNotFoundError: No module named 'MySQLdb'\n</code></pre></p> <p>We have seen in the chapter 5 how to install a SQL server with MAMP so we will leverage this installation for connecting our python code to MAMP SQL Server !  Follow these steps : </p> <ol> <li>Install the latest version of XCode &amp; XCode developer tools.</li> <li>Install <code>brew</code> package manager, here you can find the official documentation</li> <li>Install MySQL using this command:  <pre><code>brew install mysql\n</code></pre></li> <li>Run this command into your terminal to make a async link between MySQL socket:  <pre><code>sudo ln -s /Applications/MAMP/tmp/mysql/mysql.sock /tmp/mysql.sock\n</code></pre> (your socket url could be different if you using are xampp or any other local server.)</li> <li>Start MAMP/XAMMP MySQL server</li> <li>Then install (or re-install) sqlalchemy etc.</li> </ol> <p>We will not see in detail the other types of connectors for others databases, it's very similar as you can see bellow.  </p>"},{"location":"sql/22_Python_SQLAlchemy/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL is a powerful open-source relational database system that is known for its robustness and scalability. SQLAlchemy provides a PostgreSQL dialect that allows you to work with PostgreSQL databases in Python. PostgreSQL is a good choice for applications that require high performance, scalability, and data integrity.</p> <p><pre><code>from sqlalchemy import create_engine\nengine = create_engine('postgresql+psycopg2://username:password@host:port/database')\n</code></pre> In this example, we use the create_engine() function to create an engine object that connects to a PostgreSQL database named database running on a host with the specified username, password, host, and port.</p>"},{"location":"sql/22_Python_SQLAlchemy/#oracle","title":"Oracle","text":"<p>Oracle is a commercial relational database system that is popular in enterprise settings. SQLAlchemy provides an Oracle dialect that allows you to work with Oracle databases in Python. Oracle is a good choice for applications that require high performance, scalability, and data integrity, and can handle large amounts of data and concurrent users.</p> <p><pre><code>from sqlalchemy import create_engine\nengine = create_engine('oracle+cx_oracle://username:password@host:port/SID')\n</code></pre> In this example, we use the create_engine() function to create an engine object that connects to an Oracle database identified by its SID, running on a host with the specified username, password, and port.</p>"},{"location":"sql/22_Python_SQLAlchemy/#microsoft-sql-server","title":"Microsoft SQL Server","text":"<p>Microsoft SQL Server is a popular relational database system that is commonly used in Windows environments. SQLAlchemy provides a SQL Server dialect that allows you to work with SQL Server databases in Python. SQL Server is a good choice for applications that require high performance and scalability, and can handle large amounts of data and concurrent users. <pre><code>from sqlalchemy import create_engine\nengine = create_engine('mssql+pymssql://username:password@host:port/database')\n</code></pre> In this example, we use the create_engine() function to create an engine object that connects to a Microsoft SQL Server database named database running on a host with the specified username, password, host, and port.</p> <p>As you can see, it is pretty much the same process. </p>"},{"location":"sql/22_Python_SQLAlchemy/#choosing-the-right-database","title":"Choosing the right Database","text":"<p>Choosing the right database connection is an important consideration when working with SQLAlchemy. By understanding the strengths and weaknesses of different database systems and dialects, you can choose the best option for your project. SQLAlchemy provides a consistent, high-level interface to all of these systems, allowing you to work with them in a uniform way. With SQLAlchemy, you can write Python code that works with a wide range of databases, and easily switch between them as your needs change.</p>"},{"location":"sql/22_Python_SQLAlchemy/#connect-to-our-employees-database","title":"Connect to our Employees database","text":"<p>Let's write a python script <code>connect_db.py</code> who connects to our MySQL employees database using SQLAlchemy library and retrieves some data (or metadata) about the database tables. </p> <pre><code>from sqlalchemy import create_engine, inspect\nhost = '127.0.0.1'\ndb = 'employees'\n# create an engine to connect to the database\nprint(f'--- Connecting database : mysql://user:password@{host}:3306/{db}---\\n')\nengine = create_engine(f'mysql://user:password@localhost:3306/{db}')\n# create an inspector to get metadata about the database\ninspector = inspect(engine)\nprint(f'--- \u2705 Connection database OK \u2705---')\n# get a list of all the table names in the database\ntable_names = inspector.get_table_names()\nprint('Tables : \\n\\n')\n# iterate over the table names and print the table schema\nfor table_name in table_names:\ncolumns = inspector.get_columns(table_name)\nprint(f\"Table: {table_name}\")\nfor column in columns:\nprint(f\"{column['name']}: {column['type']}\")\nprint(\"\\n\")\n# explicitly close the connection to the database\nengine.dispose()\n</code></pre> <p>Here is a step-by-step explanation of what the script does:</p> <ol> <li>The script starts by importing the required modules from the SQLAlchemy library, including the create_engine and inspect functions.</li> <li>The host and db variables are defined to store the connection details for the MySQL database. In this case, the host is set to 127.0.0.1 and the database name is employees.</li> <li>The create_engine function is used to create a connection to the MySQL database using the specified host, port, username, password, and database name. The connection details are passed as a string to the create_engine function, which returns an engine object.</li> <li>An inspector object is created using the inspect function and the engine object. The inspector is used to retrieve metadata about the database tables.</li> <li>A success message is printed to the console to indicate that the database connection was successful.</li> <li>The get_table_names function is called on the inspector object to retrieve a list of all table names in the database.</li> <li>A loop is then used to iterate over the table names and retrieve the column information for each table.</li> <li>Inside the loop, the get_columns function is called on the inspector object to retrieve the column details for the current table.</li> <li>The column details are then printed to the console, including the column name and data type.</li> <li>Once all tables have been processed, the loop ends and the script exits and the connection to the database is closed.</li> </ol> <p>In summary, this script connects to a MySQL database, retrieves metadata about the tables, and displays the column details for each table. This is a useful way to quickly check the schema of a database and verify that it is set up correctly.</p> <p>Do not forget to use you <code>username</code> and <code>password</code> in order to insure a good connection.  </p>"},{"location":"sql/22_Python_SQLAlchemy/#closing-the-connection","title":"Closing the connection","text":"<p>When a SQLAlchemy Engine is created, it creates a pool of connections to the database which are automatically checked out and returned when needed by the application. This means that once an Engine has been created, it can be used for the lifetime of the application without the need to explicitly close the connection or perform any other cleanup.</p> <p>However, it's good practice to close the connection when you're done using it, especially in long-running applications, to ensure that database resources are properly released. To close the connection in SQLAlchemy, you can use the Engine.dispose() method, which will release all resources associated with the Engine.</p>"},{"location":"sql/23_python_query/","title":"Querying Data with Python","text":"<p>In this section we will see how to use SQLAlchemy for connecting MySQL database and play with the data. </p>"},{"location":"sql/23_python_query/#querying-an-existing-database","title":"Querying an existing database","text":"<p>Let's write a python script <code>query_db.py</code> who connects to a MySQL database using SQLAlchemy library, select a table and perform a query. </p> query_db.py<pre><code>from sqlalchemy import create_engine, inspect\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create an inspector to get metadata about the database\ninspector = inspect(engine)\n# get a list of all the table names in the database\ntable_names = inspector.get_table_names()\n# iterate over the table, select employees table and perform a query\nfor table_name in table_names:\nif table_name == 'employees':\ncolumns = inspector.get_columns(table_name)\nprint(f\"Table: {table_name}\")\nfor column in columns:\nprint(f\"{column['name']}: {column['type']}\")\nprint(\"\\n\")\nemployees = engine.execute(\"SELECT * FROM employees WHERE gender = 'M' LIMIT 10\")\nfor row in employees:\nprint(row)\n</code></pre> <p>The only difference with the previous code <code>connect_db.py</code> is the highlight part when we iterate over each table name in the list and checks if the table name is <code>employees</code>. If it is, it gets the columns for the <code>employees</code> table and prints out each column name and data type.</p> <p>Next, the code executes a SQL query to select the first 10 male employees in the <code>employees</code> table and prints out each row returned by the query.</p> <p>Overall, this code demonstrates how to use SQLAlchemy to connect to a MySQL database, inspect its metadata, and execute SQL queries to retrieve data from a specific table.</p>"},{"location":"sql/23_python_query/#using-session-object","title":"Using <code>session()</code> object","text":"<p>We don't necessarily need to use a session object if we only need to execute simple queries, as we can execute queries directly using the engine object. </p> <p>However, if you need to work with transactions or make more complex database operations, using a session object would be a good practice. A session object provides a transactional scope and also allows you to perform more complex operations such as creating, updating or deleting records.</p> <p>Let's rewrite the query above with a <code>session()</code> object : </p> <p>query_db_session.py<pre><code>from sqlalchemy import create_engine, inspect\nfrom sqlalchemy.orm import sessionmaker\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\nsession = Session()\n# perform a query to select customers from London\nresult = session.execute(\"SELECT * FROM employees WHERE gender = 'M' LIMIT 10\")\nfor row in result:\nprint(row)\n# close the session\nsession.close()\n</code></pre> Note that in this example, we first create a session object using the sessionmaker function and passing the engine object as an argument. Then we can use the session object to execute the query and work with the results. Finally, we close the session to release resources.</p>"},{"location":"sql/23_python_query/#pro-and-con-using-session","title":"Pro and Con using <code>session()</code>","text":"<p>Goods:</p> <ul> <li>Sessions help manage transactions by keeping track of the state of the database and the changes made to it. This helps ensure that changes are made in a consistent and safe way.</li> <li>Sessions can help improve performance by batching together changes made to the database and reducing the number of round-trips to the database.</li> <li>Sessions can provide an additional layer of abstraction that makes it easier to work with the database in a more object-oriented way.</li> <li>Sessions can be used to automatically generate SQL statements to perform CRUD operations on the database, reducing the amount of SQL code that needs to be written.</li> </ul> <p>Bads:</p> <ul> <li>Sessions can add complexity to the code and make it more difficult to understand and maintain. Sessions can be prone to race conditions and deadlocks, especially in high-concurrency environments.</li> <li>Sessions can sometimes make it more difficult to diagnose and debug issues with the database.</li> <li>Sessions can sometimes lead to inconsistent or unexpected behavior if not used correctly or if there are bugs in the code.</li> </ul>"},{"location":"sql/23_python_query/#using-with-session","title":"Using <code>with session()</code>","text":"<p>Using the with statement to automatically close the session after the execution of the query : </p> query_db_session_with.py<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\n# perform a query to select customers from London\nwith Session() as session:\nresult = session.execute(\"SELECT * FROM employees WHERE gender = 'M' LIMIT 10\")\nfor row in result:\nprint(row)\n</code></pre>"},{"location":"sql/23_python_query/#using-query","title":"Using <code>query()</code>","text":"<p>Using the query method of the session:</p> <p>query_db_session_query.py<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n# create an engine to connect to the database\nengine = create_engine('mysql://root:root@localhost:3306/employees')\n# create a session to work with the database\nwith Session(engine) as session:\n# perform a query to select employees with a salary greater than 100000\nresult = session.query(Employees).filter(Employees.salary &gt; 100000).limit(10)\nfor row in result:\nprint(row.first_name, row.last_name, row.salary)\n</code></pre> In this example, we use the with statement to automatically close the session when we're done with it. We also use the query method to execute the SQL statement, and the filter method to filter the results based on the salary column. Finally, we use the limit method to limit the number of rows returned to 10.</p> <p>Note that in order to use this method, we first need to define the Employees class using the declarative_base function from SQLAlchemy. This allows us to represent the employees table as a Python class, making it easier to query the database using SQLAlchemy we will see that in the next chapter. </p>"},{"location":"sql/24_python_orm/","title":"Object Relational Mapping Python","text":""},{"location":"sql/24_python_orm/#what-is-orm","title":"What is ORM?","text":"<p>ORM stands for Object-Relational Mapping, which is a programming technique that allows developers to work with a relational database using an object-oriented paradigm. It maps the data stored in a database to objects in a programming language, which makes it easier for developers to work with data in their application.</p> <p></p> <p>Traditionally, when working with a relational database, developers use SQL to write queries and retrieve data. SQL is a powerful language, but it can be difficult to work with and maintain, especially for large and complex systems. ORM provides a layer of abstraction between the database and the application, allowing developers to work with objects instead of raw SQL.</p>"},{"location":"sql/24_python_orm/#orm-benefits-for-developers","title":"ORM benefits for developers","text":"<ul> <li>Simplification of code: With ORM, developers can work with objects and classes instead of complex SQL queries. This makes the code more readable and maintainable.</li> <li>Portability: ORM allows the same code to work with different databases, as it provides a common interface to access the data.</li> <li>Database abstraction: ORM shields developers from the complexities of different databases and database-specific SQL syntax, allowing them to focus on the application logic.</li> <li>Security: ORM provides built-in protection against SQL injection attacks, as it automatically sanitizes input and uses parameterized queries.</li> <li>Increased productivity: With ORM, developers can write code faster, as they don't have to write complex SQL queries manually.</li> </ul>"},{"location":"sql/24_python_orm/#why-sqlalchemy","title":"Why SQLAlchemy","text":"<p>SQLalchemy ORM (Object-Relational Mapping) is another way of working with databases using SQLalchemy. It supports a wide range of relational databases, including MySQL, PostgreSQL, SQLite, and Oracle. In ORM, database tables are represented as classes and rows in tables are represented as objects of those classes.</p> <p>SQLAlchemy provides several key features:</p> <ul> <li>Declarative base classes: SQLAlchemy allows developers to define their database schema using Python classes. This makes it easy to map tables to classes, and provides a clear separation between the database and application logic.</li> <li>Session management: SQLAlchemy provides a session management system that tracks changes made to objects and commits them to the database.</li> <li>Query API: SQLAlchemy provides a powerful and flexible query API that allows developers to construct complex queries using Python syntax. Like the <code>filter()</code> function we have seen in the previous course. </li> <li>Support for transactions: SQLAlchemy provides support for transactions, allowing developers to roll back changes if necessary.</li> <li>Built-in caching: SQLAlchemy provides built-in caching to improve performance. Support for migrations: SQLAlchemy provides support for database migrations, allowing developers to change the schema of their database over time.</li> </ul>"},{"location":"sql/24_python_orm/#how-to-use-sqlalchemy-for-orm","title":"How to use SQLAlchemy for ORM","text":"<p>Using SQLAlchemy for ORM involves several steps:</p> <ul> <li>Define the database schema using Python classes. </li> <li>Create an engine that connects to the database.</li> <li>Define a session factory that will be used to create sessions.</li> <li>Use the session factory to create a session.</li> <li>Use the session to perform CRUD (Create, Read, Update, Delete) operations on the database.</li> </ul> <p>Here is an example of how to use SQLAlchemy for ORM and perform a query with the SQLAlchemy Query API : orm_0.py<pre><code>from sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\nsession = Session()\n# import the Employee model\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy import Column, Integer, String, Date, Enum\nBase = declarative_base()\nclass Employee(Base):\n__tablename__ = 'employees'\nemp_no = Column(Integer, primary_key=True)\nbirth_date = Column(Date)\nfirst_name = Column(String(14))\nlast_name = Column(String(16))\ngender = Column(Enum('M','F'))\nhire_date = Column(Date)\n# query the database using the ORM\nemployees = session.query(Employee).filter(Employee.gender == 'M').limit(10).all()\n# print the results\nfor employee in employees:\nprint(employee.emp_no, employee.first_name, employee.last_name)\n# close the session\nsession.close()\n</code></pre> In this example, we define an ORM class Employee that represents the employees table in the database. We define the columns of the table as attributes of the class.</p> <p>To query the database, we create a session using sessionmaker and use the query method to perform a query. We filter the query to only include employees with gender 'M' and limit the results to 10 rows. We then iterate over the results and print them.</p> <p>The main advantage of ORM is that it allows developers to work with databases in a more object-oriented way. They can use the familiar syntax of Python classes and objects to interact with databases. It also allows for better organization and abstraction of database code.</p> <p>SQLalchemy provides a powerful ORM that allows developers to work with databases in a high-level, Pythonic way. The ORM provides an abstraction layer between the Python code and the database, making it easier to work with databases without needing to know SQL.</p>"},{"location":"sql/24_python_orm/#mapping-the-employees-database","title":"Mapping the employees database","text":"orm_1.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# define the departments table\ndepartments = Table('departments', metadata,\nColumn('dept_no', String(4), primary_key=True),\nColumn('dept_name', String(40))\n)\n# define the dept_emp table\ndept_emp = Table('dept_emp', metadata,\nColumn('emp_no', Integer, ForeignKey('employees.emp_no')),\nColumn('dept_no', String(4), ForeignKey('departments.dept_no')),\nColumn('from_date', String(10)),\nColumn('to_date', String(10))\n)\n# define the dept_manager table\ndept_manager = Table('dept_manager', metadata,\nColumn('emp_no', Integer, ForeignKey('employees.emp_no')),\nColumn('dept_no', String(4), ForeignKey('departments.dept_no')),\nColumn('from_date', String(10)),\nColumn('to_date', String(10))\n)\n# define the employees table\nemployees = Table('employees', metadata,\nColumn('emp_no', Integer, primary_key=True),\nColumn('birth_date', String(10)),\nColumn('first_name', String(14)),\nColumn('last_name', String(16)),\nColumn('gender', String(1)),\nColumn('hire_date', String(10))\n)\n# define the salaries table\nsalaries = Table('salaries', metadata,\nColumn('emp_no', Integer, ForeignKey('employees.emp_no')),\nColumn('salary', Integer),\nColumn('from_date', String(10)),\nColumn('to_date', String(10))\n)\n# define the titles table\ntitles = Table('titles', metadata,\nColumn('emp_no', Integer, ForeignKey('employees.emp_no')),\nColumn('title', String(50)),\nColumn('from_date', String(10)),\nColumn('to_date', String(10))\n)\n# create a session to interact with the database\nfrom sqlalchemy.orm import sessionmaker\nSession = sessionmaker(bind=engine)\nsession = Session()\n# example query to select all employees\nresult = session.query(employees).all()\nfor row in result:\nprint(row.emp_no, row.first_name, row.last_name)\n# close the session\nsession.close()\n</code></pre> <p>In this example, we first create an <code>engine</code> to connect to the database using the <code>create_engine</code> function. Then we define the tables in the database using the <code>Table</code> and <code>Column</code> objects from the sqlalchemy module, and create a metadata object to reflect the database schema.</p> <p>We then create a session to interact with the database using the <code>sessionmaker</code> function, and use the <code>query</code> method of the session object to execute a <code>SELECT</code> statement on the employees table, selecting all rows and printing : the employee number, first name, and last name.</p> <p>Finally, we close the session using the close method. We can refactor our code like this : </p> <p>orm_2.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# create a session to interact with the database\nfrom sqlalchemy.orm import sessionmaker\nSession = sessionmaker(bind=engine)\nsession = Session()\n#\n# define tables like in orm_1.py script  \n#\n# example query \ntry:\nresult = session.query(employees, salaries).filter(employees.c.emp_no == salaries.c.emp_no).limit(10)\nfor row in result:\nprint(row)\nfinally:\nsession.close()\n</code></pre> Let's dig into this code </p> <ul> <li>First, we import the necessary modules, including create_engine, Table, Column, Integer, String, MetaData, ForeignKey, and sessionmaker.</li> <li>Next, we create an engine to connect to our MySQL database, using the create_engine function.</li> <li>We then create a session to work with the database using sessionmaker.</li> <li>We define metadata using MetaData.</li> <li>We define the employees and salaries tables using Table and Column.</li> <li>We join the two tables using the filter function, specifying the emp_no columns to join on.</li> <li>We limit the results to 10 using the limit function.</li> <li>Finally, we print the results of the query.</li> </ul> <p>This code joins the <code>employees</code> and <code>salaries</code> tables on their respective <code>emp_no</code> columns and returns the first 10 results. The result is a list of tuples, with each tuple containing the corresponding rows from the two tables.</p>"},{"location":"sql/24_python_orm/#perform-queries","title":"Perform queries","text":"<p>Let's take a look at the top 5 highest paid employees : </p> orm_3.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# create a session to interact with the database\nfrom sqlalchemy.orm import sessionmaker\nSession = sessionmaker(bind=engine)\nsession = Session()\n#\n# define tables like in orm_1.py script  \n#\n# example query \ntry:\nresult = (\nsession.query(employees, salaries)\\\n    .filter(employees.c.emp_no == salaries.c.emp_no)\\\n    .order_by(desc(salaries.c.salary))\\\n    .limit(5)\n)\nfor row in result:\nprint(f'Employee {row.first_name}-{row.last_name} earn {row.salary}$/year')\n#print(f\"{employee.first_name} earns {salary.salary} dollars\")\nfinally:\nsession.close()\n</code></pre> <p>Here we've added an <code>order_by()</code> method to sort the results in descending order by the salary column. The <code>desc()</code> function is used to specify a descending sort. Finally, we use the <code>limit()</code> method to limit the results to the top 10 highest paid employees.</p> <p>Let's take a look to an other query, this time without using <code>session()</code> and ORM mapping. </p>"},{"location":"sql/24_python_orm/#using-sqlalchemy-table-object-to-join-data","title":"Using SQLAlchemy <code>Table</code> object to join data","text":"<p>Let's take a look at SQLAlchemy join and why this method has several benefits over manual SQL  joins:</p> <ul> <li>Abstraction: SQLAlchemy provides a high-level object-oriented abstraction layer over SQL, making it easier to write queries and perform joins without needing to write low-level SQL code.</li> <li>Portability: Because SQLAlchemy provides a layer of abstraction, it makes it easier to switch databases without having to re-write queries. This is especially useful for larger projects where databases may need to be switched due to scaling or other requirements.</li> <li>Security: SQLAlchemy's query system provides a safe and secure way to build complex queries, helping to prevent SQL injection attacks.</li> <li>Easier to read and maintain: SQLAlchemy queries are often easier to read and maintain than raw SQL queries. This is because they are written in Python, which is a more expressive and easier to read language than SQL.</li> <li>Object-Relational Mapping (ORM): SQLAlchemy provides an ORM that maps database tables to Python classes, making it easy to work with data in an object-oriented manner. This can simplify code and make it easier to reason about the data model.</li> </ul> <p>Overall, using SQLAlchemy to join data provides a more efficient and effective way to interact with databases, reducing the likelihood of errors and making it easier to maintain code in the long-term.</p>"},{"location":"sql/24_python_orm/#using-table","title":"Using <code>Table()</code>","text":"<p>The primary difference between using <code>Table</code> and the ORM approach in SQLAlchemy is how the data is represented and accessed.</p> <p>When using <code>Table</code>, the data is represented as tables and columns in the database. Queries are constructed using SQL-like syntax, and the results are returned as tuples or dictionaries. This approach requires a good understanding of SQL and database structure, as well as the ability to write complex queries.</p> join_query.py<pre><code>from sqlalchemy import create_engine, MetaData, Table, select\n# Define the engine\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# Define the metadata\nmetadata = MetaData()\n# Define the tables\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\ndept_emp = Table('dept_emp', metadata, autoload=True, autoload_with=engine)\ndepartments = Table('departments', metadata, autoload=True, autoload_with=engine)\n# Define the query\nquery = select([employees.c.emp_no, employees.c.first_name, employees.c.last_name, departments.c.dept_name]).\\\n    select_from(employees.join(dept_emp).join(departments, dept_emp.c.dept_no == departments.c.dept_no))\n# Execute the query\nresult = engine.execute(query)\n# Print the results\nfor row in result:\nprint(row)\n</code></pre> <p>This query selects the <code>emp_no</code>, <code>first_name</code>, <code>last_name</code>, and <code>dept_name</code> columns from the <code>employees</code>, <code>dept_emp</code>, and <code>departments</code> tables, and joins them together based on the <code>dept_no</code> column in <code>dept_emp</code> and <code>departments</code>. It then executes the query and prints the results.</p>"},{"location":"sql/24_python_orm/#orm-or-table","title":"ORM or <code>Table</code>","text":"<p>On the other hand, the ORM approach in SQLAlchemy allows developers to work with Python classes that represent database tables, and instances of those classes represent rows in the database. Queries are constructed using Python methods and attributes, which are then translated to SQL statements by SQLAlchemy. The results are returned as instances of the corresponding Python classes, making it easier to work with the data in a more object-oriented way.</p> <p>Overall, the ORM approach is more intuitive for developers who are more familiar with object-oriented programming and less familiar with SQL. It also provides better abstraction from the underlying database structure, making it easier to make changes to the schema without affecting the application code. However, the Table approach may be more appropriate in cases where more fine-grained control over the SQL queries is required.</p>"},{"location":"sql/24_python_orm/#wrap-up","title":"Wrap-up","text":"<p>Whether you prefer to work with SQL directly or use an ORM, SQLalchemy has you covered. With its intuitive API, SQLalchemy makes it easy to connect to databases, perform queries, and manipulate data. Understanding how to use SQLalchemy is an essential skill for any Python developer working with databases.</p>"},{"location":"sql/25_python_update_delete/","title":"Updating and Deleting Data with Python","text":""},{"location":"sql/25_python_update_delete/#updating-data-with-python-and-sqlalchemy","title":"Updating Data with Python and SQLAlchemy","text":""},{"location":"sql/25_python_update_delete/#using-update-method","title":"Using <code>update()</code> method","text":"<p>The update() method in SQLAlchemy can be used to update data in a table. The syntax of update() method is as follows: <pre><code>table.update().where(condition).values(column_name=new_value)\n</code></pre> Where : </p> <ul> <li><code>table</code>: The table that needs to be updated.</li> <li><code>condition</code>: The condition that specifies which rows should be updated.</li> <li><code>column_name</code>: The name of the column that needs to be updated.</li> <li><code>new_value</code>: The new value for the column.</li> </ul> <p>Here's an example of how to use the update() method in SQLAlchemy to update the salary of an employee:</p> <p>update_db.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey, desc\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# Define the table\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\n# Update the salary of employee with emp_no = 10001\nupdate_query = employees.update().where(employees.c.emp_no == 10001).values(first_name='jonh')\n# Execute the query\nwith engine.connect() as conn:\nconn.execute(update_query)\n</code></pre> Here, the line <code>employees = Table('employees', metadata, autoload=True, autoload_with=engine)</code>  loads the <code>employees</code> table from the database into a Table object named <code>employees</code> using the metadata object and the engine object. Then we define the update operation to be performed on the <code>employees</code> table. This query will update the <code>first_name</code> column of the row where <code>emp_no</code> is equal to 10001 to <code>john</code>.</p> <p>Let's verify if the database is updated with this query after the <code>update_db.py</code> script : </p> <pre><code># Verify if the field has been modified\nselect_query = select([employees]).where(employees.c.emp_no == 10001)\n# Execute the query\nwith engine.connect() as conn:\nresult = conn.execute(select_query)\nfor row in result:\nprint(row)\n</code></pre>"},{"location":"sql/25_python_update_delete/#using-execute-method","title":"Using <code>execute()</code> method","text":"<p>Another way to update data in a table is by using the <code>execute()</code> method in SQLAlchemy. Here's an example:</p> <pre><code># Define the table\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\n# Define the query\nupdate_query = \"UPDATE employees SET first_name = 'jonh' WHERE emp_no = 10001\"\n# Execute the query\nwith engine.connect() as conn:\nconn.execute(update_query)\n</code></pre>"},{"location":"sql/25_python_update_delete/#update-vs-execute","title":"\ud83d\udca1 <code>update()</code> VS <code>execute()</code>","text":"<p>The <code>execute()</code> method is more flexible and can be used to execute any SQL statement, including <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>, and more. However, it requires the statement to be provided as a string, making it more error-prone and harder to maintain in large applications.</p> <p>On the other hand, the <code>update()</code> method provides a more structured way to update data in a table. It takes a filter condition that specifies which rows to update, and a set of values to apply to the specified rows. The <code>update()</code> method also returns a <code>ResultProxy</code> object that can be used to get information about the update operation, such as the number of affected rows.</p> <p>In general, the <code>update()</code> method is preferred for modifying data in a table using SQLAlchemy, as it provides a more structured and safer approach. However, in some cases, the <code>execute()</code> method may be more appropriate for executing complex SQL statements that cannot be expressed using the <code>update()</code> method.</p>"},{"location":"sql/25_python_update_delete/#deleting-data-with-python-and-sqlalchemy","title":"Deleting Data with Python and SQLAlchemy","text":""},{"location":"sql/25_python_update_delete/#using-delete-method","title":"Using <code>delete()</code> method","text":"<p>The <code>delete()</code> method in SQLAlchemy can be used to delete data from a table. The syntax of <code>delete()</code> method is as follows: <pre><code>table.delete().where(condition)\n</code></pre> where : - table: The table that needs to be updated. - condition: The condition that specifies which rows should be deleted.</p> <p>Here's an example of how to use the delete() method in SQLAlchemy to delete an employee from the employees table:</p> delete_dd.py<pre><code>#\n#import and other stuff like all the previous scripts\n#\n# Define the table\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\n# Delete the employee with emp_no = 10001\ndelete_query = employees.delete().where(employees.c.emp_no == 10001)\n# Execute the query\nwith engine.connect() as conn:\nconn.execute(delete_query)\n</code></pre> <p>In this example, we deleted the employee with <code>emp_no</code> 10001 from the <code>employees</code> table.</p>"},{"location":"sql/25_python_update_delete/#using-execute-method_1","title":"Using <code>execute()</code> method","text":"<p>Another way to delete data from a table is by using the execute() method in SQLAlchemy. Here's an example:</p> <p><pre><code># Define the table\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\n# Define the query\ndelete_query = \"DELETE FROM employees WHERE emp_no = 10001\"\n# Execute the query\nwith engine.connect() as conn:\nconn.execute(delete_query)\n</code></pre> Same principle as before. </p>"},{"location":"sql/25_python_update_delete/#wrap-up","title":"Wrap-up","text":"<p>That's it! Now we know how to update and delete data in tables using Python and SQLAlchemy \ud83e\udd73</p>"},{"location":"sql/26_python_queries/","title":"Advanced Queries with Python","text":"<p>SQLAlchemy provides a wide range of advanced querying techniques that allow you to perform complex database queries using Python code. In this tutorial, we will cover how to use joins, subqueries, and other advanced SQL features with SQLAlchemy.</p>"},{"location":"sql/26_python_queries/#joins","title":"Joins","text":"<p>Joins are used to combine data from two or more tables in a single query like we have seen in the SQL section. SQLAlchemy provides several ways to perform joins, including the <code>join()</code>, <code>outerjoin()</code>, and <code>select_from()</code> methods.</p>"},{"location":"sql/26_python_queries/#inner-join","title":"Inner Join","text":"<p>An inner join returns only the rows that have matching values in both tables being joined. Here's an example:</p> <p>inner_join.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\n#connect database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\n#Map employees tables employees and titles\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\ntitles = Table('titles', metadata, autoload=True, autoload_with=engine)\n#perform query\nquery = employees.join(titles, employees.c.emp_no == titles.c.emp_no)\nresult = engine.execute(query.select())\n#print result\nfor row in result:\nprint(row)\n</code></pre> In the above example, we used the <code>join()</code> method to join the <code>employees</code> and <code>titles</code> tables on the <code>emp_no</code> column. The resulting query returns only the rows where there is a matching <code>emp_no</code> in both tables.</p>"},{"location":"sql/26_python_queries/#left-join","title":"Left Join","text":"<p>A left join returns all the rows from the left table and the matched rows from the right table. If there is no match in the right table, the result will contain NULL values. Here's an example:</p> <p>left_join.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nsalaries = Table('salaries', metadata, autoload=True, autoload_with=engine)\nquery = employees.join(salaries, employees.c.emp_no == salaries.c.emp_no, isouter=True)\nresult = engine.execute(query.select())\nfor row in result:\nprint(row)\n</code></pre> In the above example, we used the <code>join()</code> method to perform a <code>left join</code> between the <code>employees</code> and <code>salaries</code> tables on the <code>emp_no</code> column. The <code>isouter=True</code> argument specifies that we want to perform a <code>left join</code>. If there is no matching <code>emp_no</code> in the <code>salaries</code> table, the result will contain <code>NULL</code> values.</p>"},{"location":"sql/26_python_queries/#right-join","title":"Right Join","text":"<p>A <code>right join</code> returns all the rows from the right table and the matched rows from the left table. If there is no match in the left table, the result will contain <code>NULL</code> values. Here's an example:</p> <p>right_join.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nsalaries = Table('salaries', metadata, autoload=True, autoload_with=engine)\nquery = salaries.join(employees, salaries.c.emp_no == employees.c.emp_no, isouter=True)\nresult = engine.execute(query.select())\nfor row in result:\nprint(row)\n</code></pre> In the above example, we used the <code>join()</code> method to perform a right join between the <code>salaries</code> and <code>employees</code> tables on the <code>emp_no</code> column. The iso<code>uter=True</code> argument specifies that we want to perform a right join.</p>"},{"location":"sql/26_python_queries/#using-multiple-join-conditions-with-select_from","title":"Using multiple join conditions with <code>select_from()</code>","text":"<p>Let's try to print the 10 employees with the highest salary in the Development department : </p> <p>multiple_join.py<pre><code>from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, ForeignKey, desc, select, func\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# Define the tables\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\ndepartments = Table('departments', metadata, autoload=True, autoload_with=engine)\ndept_emp = Table('dept_emp', metadata, autoload=True, autoload_with=engine)\nsalaries = Table('salaries', metadata, autoload=True, autoload_with=engine)\n# Define the query to select the 10 employees with the highest salary in the Development department\nquery = select([employees.c.emp_no, employees.c.first_name, employees.c.last_name, salaries.c.salary]).\\\n        where(employees.c.emp_no == salaries.c.emp_no).\\\n        where(dept_emp.c.emp_no == employees.c.emp_no).\\\n        where(dept_emp.c.dept_no == departments.c.dept_no).\\\n        where(departments.c.dept_name == 'Development').\\\n        order_by(desc(salaries.c.salary)).\\\n        limit(10).\\\n        select_from(employees.join(salaries).join(dept_emp).join(departments))\n# Execute the query\nresult = engine.execute(query)\n# Print the results\nfor row in result:\nprint(row)\n</code></pre> The query selects the columns <code>emp_no</code>, <code>first_name</code>, <code>last_name</code>, and <code>salary</code> from the <code>employees</code> and <code>salaries</code> tables, respectively. It then joins the <code>dept_emp</code> and <code>departments</code> tables to get only the <code>employees</code> in the Development department, and sorts the result in descending order by salary, and limits the result to the top 10 highest paid <code>employees</code>. </p> <p>Finally, it uses the <code>select_from()</code> method to specify the join conditions between the tables.</p> <p>The execute method is called on the engine object with the query object as an argument, and the results are printed in a loop as usual.</p>"},{"location":"sql/26_python_queries/#sub-queries-and-correlate-function","title":"Sub Queries and <code>correlate()</code> function","text":"<p>In SQLAlchemy, the correlate() function is used to control correlated subqueries, which are subqueries that reference the outer query. A correlated subquery allows you to filter or aggregate data in a subquery based on the results of the outer query.</p> <p>The correlate() function is used to specify which tables in the subquery should be correlated to the outer query. It takes one or more tables as arguments and returns a new Select object that is a correlated subquery.</p> <p>Here's the same example as before modify for using <code>correlate()</code> function :</p> <p>subquery_db.py<pre><code>from sqlalchemy import select, func\nfrom sqlalchemy.orm import correlate\n# define the tables\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nsalaries = Table('salaries', metadata, autoload=True, autoload_with=engine)\ndept_emp = Table('dept_emp', metadata, autoload=True, autoload_with=engine)\n# Define the subquery to calculate average salary of development department employees\nsubquery = select([func.avg(salaries.c.salary)]).\\\n    where(salaries.c.emp_no == employees.c.emp_no).\\\n    where(dept_emp.c.dept_no == 'd001').\\\n    correlate(employees).\\\n    select_from(dept_emp.join(employees, employees.c.emp_no == dept_emp.c.emp_no).\\\n                join(salaries, salaries.c.emp_no == employees.c.emp_no))\n# Define the query to select the 10 most paid employees in development department\nquery = select([employees.c.emp_no, employees.c.first_name, employees.c.last_name, salaries.c.salary]).\\\n    where(dept_emp.c.dept_no == 'd001').\\\n    where(salaries.c.emp_no == employees.c.emp_no).\\\n    where(salaries.c.salary &gt; subquery).\\\n    order_by(desc(salaries.c.salary)).\\\n    limit(10).\\\n    select_from(dept_emp.join(employees, employees.c.emp_no == dept_emp.c.emp_no).\\\n                join(salaries, salaries.c.emp_no == employees.c.emp_no))\n# execute the query and print the results\nresult = engine.execute(query)\nfor row in result:\nprint(row)\n</code></pre> This query is similar to the previous one we discussed, which also selects the 10 most highly paid employees in the development department. However, in this query, we use the <code>correlate()</code> function to manage auto-correlation between tables.</p> <p>The subquery is used to calculate the average salary of employees in the development department. We use the <code>func.avg()</code> function to calculate the average salary and apply two where clauses to filter the salaries of employees in the development department. </p> <p>To handle auto-correlation between tables, we use the <code>correlate()</code> function and pass the employees table as the argument. Finally, we join the <code>dept_emp</code>, <code>employees</code>, and <code>salaries</code> tables together using the <code>join()</code> method.</p> <p>The main query selects the <code>emp_no</code>, <code>first_name</code>, <code>last_name</code>, and <code>salary</code> fields from the <code>employees</code> and <code>salaries</code> tables. We again use the where clause to filter the <code>employees</code> in the development department and use the <code>correlate()</code> function to handle auto-correlation.  We also add a third where clause to compare the salaries of employees in the development department with the average salary calculated by the subquery. </p> <p>Finally, we join the <code>dept_emp</code>, <code>employees</code>, and <code>salaries</code> tables together using the <code>join()</code> method. We sort the results in descending order of salaries and limit the output to the top 10 results.</p>"},{"location":"sql/26_python_queries/#joins-and-correlate","title":"Joins and <code>correlate()</code>","text":"<p>The <code>correlate()</code> function is different from joins in that it allows you to filter or aggregate data in a subquery based on the results of the outer query, without actually joining the tables together. </p> <p>\ud83d\udd0e This can be more efficient than using <code>joins</code> in certain situations, especially when dealing with large datasets. However, correlated subqueries can also be slower than <code>joins</code>, especially if the subquery is complex or returns a large amount of data. It's important to test and optimize your queries to ensure that they perform well for your specific use case.</p>"},{"location":"sql/26_python_queries/#difference-between-the-select_from-and-the-joins-methods","title":"Difference between the <code>select_from()</code> and the joins methods","text":"<p>The <code>select_from()</code> method and the <code>join()</code> method are both used in SQLAlchemy to specify the tables used in a SQL query, but they differ in how they are used and the types of queries they can generate.</p> <p>The <code>join()</code> method is used to specify a join between two or more tables. It generates an <code>INNER JOIN</code> by default, but can be used to generate other types of joins as well. This method allows you to specify the join condition, i.e. the columns used to match rows between the tables. The <code>join()</code> method is useful when you need to combine data from multiple tables into a single query result.</p> <p>The <code>select_from()</code> method, on the other hand, is used to specify the main table(s) used in a SQL query. It is used to specify the primary table or tables that the query will be based on. This method is useful when you need to specify a complex subquery or a nested query, or when you need to select from a view or other non-standard source of data.</p> <p>In general, the <code>join()</code> method is used to combine data from multiple tables, while the <code>select_from()</code> method is used to specify the primary table or tables used in the query. However, both methods can be used together to generate more complex queries that combine data from multiple tables and use subqueries or nested queries to filter or manipulate the data.</p>"},{"location":"sql/26_python_queries/#working-with-view","title":"Working with <code>VIEW</code>","text":"<p>Let's dig a little aroud SQL view concept. </p>"},{"location":"sql/26_python_queries/#what-is-a-view-in-sql","title":"What is a View in SQL?","text":"<p>A view in SQL is a virtual table that is created based on a query. It is a named query that is saved in the database and can be used like a table in other queries. A view can be used to simplify complex queries, filter data, or provide users with access to a subset of data in the database without having to grant access to the underlying tables.</p>"},{"location":"sql/26_python_queries/#creating-a-view","title":"Creating a View","text":"<p>A view is created using the CREATE VIEW statement, which defines the name of the view, the columns to include, and the SELECT statement that defines the query used to create the view. Here's an example:</p> <p><pre><code>CREATE VIEW sales_report AS\nSELECT year, month, sum(revenue) as total_revenue\nFROM sales\nGROUP BY year, month;\n</code></pre> This creates a view called \"sales_report\" that contains three columns: year, month, and total_revenue. The view is based on the sales table, and calculates the total revenue for each month and year.</p>"},{"location":"sql/26_python_queries/#using-a-view","title":"Using a View","text":"<p>Once a view is created, it can be used like any other table in SQL. Here's an example:</p> <p><pre><code>SELECT * FROM sales_report WHERE year = 2022;\n</code></pre> This query uses the \"sales_report\" view to select all records where the year is equal to 2022. The view simplifies the query by hiding the complexity of the underlying data.</p>"},{"location":"sql/26_python_queries/#updating-a-view","title":"Updating a View","text":"<p>A view can be updated using the ALTER VIEW statement. Here's an example: <pre><code>ALTER VIEW sales_report AS\nSELECT year, month, sum(revenue) as total_revenue\nFROM sales\nWHERE year &gt; 2020\nGROUP BY year, month;\n</code></pre> This updates the \"sales_report\" view to only include records where the year is greater than 2020.</p>"},{"location":"sql/26_python_queries/#dropping-a-view","title":"Dropping a View","text":"<p>A view can be dropped using the DROP VIEW statement. Here's an example: <pre><code>DROP VIEW sales_report;\n</code></pre> This deletes the \"sales_report\" view from the database.</p>"},{"location":"sql/26_python_queries/#importance-of-views-in-data-analysis-job","title":"Importance of Views in Data Analysis Job","text":"<p>Views are important in day-to-day data analysis because they simplify complex queries and provide a way to control access to sensitive data. Views allow users to focus on the data that is important to them, without having to understand the underlying database schema or query language. Views can also be used to filter data, hide sensitive information, and provide access to a subset of data in the database.</p> <p>In summary, views in SQL are a powerful tool for simplifying complex queries and providing users with access to a subset of data in the database. They are an important part of day-to-day data analysis and can help improve productivity, accuracy, and security.</p>"},{"location":"sql/26_python_queries/#view-with-sqlalchemy","title":"<code>VIEW</code> with SQLAlchemy","text":"<p>Let's create a python script call <code>view_0.py</code> with a view that shows the number of employees hired each year and just print the result. </p> view_0.py<pre><code>from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, select, text\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# define the tables to reflect the database schema\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\n# create a view that shows the number of employees hired each year\nquery = text(\"\"\"\n    CREATE VIEW employee_hires AS\n    SELECT YEAR(hire_date) AS year, COUNT(*) AS hires\n    FROM employees\n    GROUP BY year;\n\"\"\")\n# execute the view creation query\nwith engine.connect() as conn:\nconn.execute(query)\n# define a select statement to query the view\nemployee_hires_view = select([text(\"year, hires\")]).select_from(text(\"employee_hires\"))\n# execute the select statement and print the results\nwith engine.connect() as conn:\nresult = conn.execute(employee_hires_view)\nfor row in result:\nprint(row)\n</code></pre> <p>In this example, we create a view called employee_hires that shows the number of employees hired each year. We use the <code>text()</code> function from SQLAlchemy to define the SQL query for creating the view. Then, we execute the query using the <code>engine.connect()</code> method.</p> <p>Next, we define a <code>select</code> statement that queries the <code>employee_hires view</code> using the <code>select_from()</code> method and the <code>text()</code> function to specify the table name. Finally, we execute the select statement and print the results using the <code>engine.connect()</code> method.</p> <p>Note that the <code>select_from()</code> method is used to specify the table or view to select data from. In this example, we use the <code>text()</code> function to specify the name of the <code>employee_hires view</code>. This is similar to specifying a table name using the <code>Table()</code> function, but with the added benefit of being able to specify more complex SQL queries using the <code>text()</code> function.</p> <p>Let's take a look at an other example with <code>VIEW</code> for select the 10 most paid employees in development department : </p> view_1.py<pre><code>from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, select, text, func\n# create an engine to connect to the database\nengine = create_engine('mysql://user:password@localhost:3306/employees')\n# create a metadata object to reflect the database schema\nmetadata = MetaData()\n# define the tables to reflect the database schema\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nsalaries = Table('salaries', metadata, autoload=True, autoload_with=engine)\ndept_emp = Table('dept_emp', metadata, autoload=True, autoload_with=engine)\n# drop the existing view if it exists\nwith engine.connect() as conn:\nconn.execute(text(\"DROP VIEW IF EXISTS employee_hires\")) # (1)\n# create a view that shows the number of employees hired each year\nquery = text(\"\"\"\n    CREATE VIEW employee_hires AS\n    SELECT YEAR(hire_date) AS year, COUNT(*) AS hires\n    FROM employees\n    GROUP BY year;\n\"\"\")\n# execute the view creation query\nwith engine.connect() as conn:\nconn.execute(query)\n# define the subquery to calculate average salary of development department employees\nsubquery = select([func.avg(salaries.c.salary)]).\\\n    where(salaries.c.emp_no == employees.c.emp_no).\\\n    where(dept_emp.c.dept_no == 'd001').\\\n    correlate(employees).\\\n    select_from(dept_emp.join(employees, employees.c.emp_no == dept_emp.c.emp_no).\\\n                join(salaries, salaries.c.emp_no == employees.c.emp_no))\n# define the query to select the 10 most paid employees in development department\nquery = select([employees.c.emp_no, employees.c.first_name, employees.c.last_name, salaries.c.salary]).\\\n    where(dept_emp.c.dept_no == 'd001').\\\n    where(salaries.c.emp_no == employees.c.emp_no).\\\n    where(salaries.c.salary &gt; subquery).\\\n    order_by(salaries.c.salary.desc()).\\\n    limit(10).\\\n    select_from(dept_emp.join(employees, employees.c.emp_no == dept_emp.c.emp_no).\\\n                join(salaries, salaries.c.emp_no == employees.c.emp_no))\n# execute the query and print the results\nwith engine.connect() as conn:\nresult = conn.execute(query)\nfor row in result:\nprint(row)\n</code></pre> <ol> <li>\ud83d\udd0e  You may have an error message indicates that the view <code>employee_hires</code> already exists in the database so we deleted it before re write it. You can either drop the existing view before creating it again, or modify the create statement to use <code>CREATE</code> OR <code>REPLACE VIEW</code> which will create the view if it does not exist, or replace the existing view if it does.</li> </ol>"},{"location":"sql/27_python_large_data/","title":"Working with Large Datasets in Python","text":"<p>Working with large datasets can be challenging, especially if you're working with a database that contains millions of records. This is usually the case with companies. </p> <p>In this tutorial, we'll explore some techniques for managing and processing large amounts of data using Python and SQLAlchemy. </p>"},{"location":"sql/27_python_large_data/#1-limiting-results","title":"1. Limiting Results","text":"<p>Like we have seen and used before, one of the simplest ways to work with large datasets is to limit the number of results returned by a query. This is especially useful when you're working with a table that contains millions of records and you only need a small subset of those records for your analysis.</p> <p>In SQLAlchemy, you can limit the number of results returned by a query using the limit method. For example, to select the first 100 records from the employees table, you can use the following code:</p> <pre><code>from sqlalchemy import create_engine, MetaData, Table, select\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nquery = select([employees]).limit(100)\nwith engine.connect() as conn:\nresult = conn.execute(query)\nfor row in result:\nprint(row)\n</code></pre>"},{"location":"sql/27_python_large_data/#2-using-pagination","title":"2. Using Pagination","text":"<p>Another technique for working with large datasets is pagination. Pagination involves breaking up the results of a query into smaller chunks, or pages, and fetching each page separately. This can help to reduce memory usage and improve performance when working with large datasets.</p> <p>In SQLAlchemy, you can use the <code>limit</code> and <code>offset</code> methods to implement pagination. The <code>limit</code> method limits the number of records returned by the query, while the <code>offset</code> method specifies the starting point for the query.</p> <p>For example, to fetch records 101-200 from the <code>employees</code> table, you can use the following code: <pre><code>from sqlalchemy import create_engine, MetaData, Table, select\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nquery = select([employees]).limit(100).offset(100)\nwith engine.connect() as conn:\nresult = conn.execute(query)\nfor row in result:\nprint(row)\n</code></pre></p>"},{"location":"sql/27_python_large_data/#3-chunking-data","title":"3. Chunking Data","text":"<p>Sometimes, even pagination isn't enough to handle really large datasets. In these cases, you can chunk your data into smaller pieces and process each chunk separately. This can help to reduce memory usage and improve performance.</p> <p>In SQLAlchemy, you can use the fetchmany method to fetch a specified number of rows at a time. For example, to fetch 1000 rows at a time from the employees table, you can use the following code:</p> <p><pre><code>from sqlalchemy import create_engine, MetaData, Table, select\nengine = create_engine('mysql://user:password@localhost:3306/employees')\nmetadata = MetaData()\nemployees = Table('employees', metadata, autoload=True, autoload_with=engine)\nquery = select([employees])\nwith engine.connect() as conn:\nchunk_size = 1000\noffset = 0\nwhile True:\nchunk = conn.execute(query.limit(chunk_size).offset(offset))\nresults = chunk.fetchall()\nif not results:\nbreak\nfor row in results:\nprint(row)\noffset += chunk_size\n</code></pre> This code fetches 1000 rows at a time from the employees table and processes each chunk separately.</p>"},{"location":"sql/27_python_large_data/#4-streaming-data","title":"4. Streaming Data","text":"<p>When working with large datasets, it may be useful to stream the data from the database rather than loading the entire dataset into memory. This can be done using the yield_per() method in SQLAlchemy. The yield_per() method will fetch a certain number of rows at a time, allowing you to process the data in smaller chunks.</p> <p>Here is an example of how to use yield_per() to stream data from the employees table in the MySQL employees database:</p> <pre><code>from sqlalchemy.orm import sessionmaker\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\nsession = Session()\n# stream the data from the employees table in chunks of 1000 rows\nquery = session.query(employees).yield_per(1000)\n# process the data\nfor employee in query:\n# do something with the employee data\nprint(employee.emp_no, employee.first_name, employee.last_name)\n</code></pre>"},{"location":"sql/27_python_large_data/#5-batch-processing","title":"5. Batch Processing","text":"<p>When updating or inserting large amounts of data, it can be more efficient to do it in batches rather than one row at a time. This can be done using the add_all() method in SQLAlchemy.</p> <p>Here is an example of how to use add_all() to insert a batch of employees into the employees table: <pre><code>from sqlalchemy.orm import sessionmaker\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\nsession = Session()\n# create a list of employees to insert\nemployees_list = [\n{'emp_no': 10001, 'first_name': 'John', 'last_name': 'Doe'},\n{'emp_no': 10002, 'first_name': 'Jane', 'last_name': 'Smith'},\n# more employees...\n]\n# insert the employees in batches of 1000\nbatch_size = 1000\nfor i in range(0, len(employees_list), batch_size):\nbatch = employees_list[i:i+batch_size]\nsession.add_all([employees(**e) for e in batch])\nsession.commit()\n</code></pre></p>"},{"location":"sql/27_python_large_data/#6-parallel-processing","title":"6. Parallel Processing","text":"<p>Another technique for processing large datasets is to use parallel processing. This can be done using the <code>concurrent.futures</code> module in Python. Here is an example of how to use the <code>ThreadPoolExecutor</code> class to execute a function in parallel on a large dataset:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\nfrom sqlalchemy.orm import sessionmaker\n# create a session to work with the database\nSession = sessionmaker(bind=engine)\nsession = Session()\n# define a function to process an employee record\ndef process_employee(employee):\n# do something with the employee data\nprint(employee.emp_no, employee.first_name, employee.last_name)\n# query the employees table\nquery = session.query(employees)\n# create a ThreadPoolExecutor with 4 threads\nwith ThreadPoolExecutor(max_workers=4) as executor:\n# submit the process_employee function for each row in the query\nfutures = [executor.submit(process_employee, row) for row in query]\n# wait for all the functions to complete\nfor future in futures:\nfuture.result()\n</code></pre> <p>These are just a few techniques for managing and processing large amounts of data in Python and SQLAlchemy. Depending on your specific use case, other techniques such as indexing, partitioning, and caching may also be useful.</p>"},{"location":"sql/28_python_fastapi/","title":"SQLAlchemy and FastAPI","text":""},{"location":"sql/28_python_fastapi/#introduction","title":"Introduction","text":"<p>FastAPI is a popular Python web framework that allows for fast and efficient development of APIs. It includes a built-in support for SQLAlchemy, a powerful SQL toolkit and ORM. SQLAlchemy provides a way to interact with databases in a more pythonic way than using raw SQL, and FastAPI's integration with SQLAlchemy makes it easy to build high-performance web applications with a database backend.</p> <p>In this tutorial, we will use FastAPI and SQLAlchemy to build a RESTful API that interacts with a MySQL database containing employee data.</p>"},{"location":"sql/28_python_fastapi/#why-building-an-api","title":"Why building an API","text":"<p>An API provides a structured and standardized way for applications to communicate with each other. By creating an API for your database, you allow other applications to access the data in a controlled manner. This can provide a number of benefits:</p> <ul> <li>Security: By creating an API, you can implement security measures to protect your database from unauthorized access. You can limit access to certain endpoints and require authentication to access the data.</li> <li>Scalability: An API allows you to separate the front-end and back-end of your application, which makes it easier to scale each component independently. You can also use caching and other techniques to improve performance.</li> <li>Flexibility: By exposing your database through an API, you can allow other applications to access and use the data in a variety of ways. This can lead to new and innovative use cases that you may not have considered.</li> <li>Standardization: By using a standardized API format, such as REST, you make it easier for other developers to understand and use your API. This can help to encourage collaboration and adoption.</li> </ul> <p>In summary, creating an API provides a number of benefits for accessing and managing data. It can help to improve security, scalability, flexibility, and standardization.</p>"},{"location":"sql/28_python_fastapi/#prerequisites","title":"Prerequisites","text":"<p>Before we begin, make sure you have the following installed:</p> <ul> <li>Python 3.6 or later</li> <li>Pip</li> <li>MySQL database</li> <li>MySQL Python connector</li> </ul> <p>To install FastAPI and SQLAlchemy, run the following command: <pre><code>pip install fastapi sqlalchemy\n</code></pre></p>"},{"location":"sql/28_python_fastapi/#setting-up-the-database-in-fastapi","title":"Setting up the Database in FastAPI","text":"<p>For this tutorial, we will be using the MySQL employees database as usual. </p> <p>Once you have the database set up, create a new file <code>main.py</code> and add the following code:</p> <p>main.py<pre><code>from fastapi import FastAPI, HTTPException\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.ext.automap import automap_base\n# create the FastAPI instance\napp = FastAPI()\n# create the database engine\nengine = create_engine(\"mysql://root:root@localhost:3306/employees\")\n# reflect the database schema to an ORM base\nBase = automap_base()\nBase.prepare(engine, reflect=True)\n# map the tables to ORM classes\nEmployees = Base.classes.employees\nDepartments = Base.classes.departments\nDept_Emp = Base.classes.dept_emp\nSalaries = Base.classes.salaries\n# create a function to get a database session\ndef get_db():\ntry:\ndb = Session(bind=engine)\nyield db\nfinally:\ndb.close()\n</code></pre> The new thing in the code is a function called <code>get_db()</code> which is used to create a database session to interact with the database.</p> <p>The function first tries to create a session using <code>Session(bind=engine)</code> and binds the session to the database engine object engine. The yield keyword makes the function a generator function which can be iterated over to yield a database session.</p> <p>When the session is no longer needed, the finally block of the function is executed which closes the database session using <code>db.close()</code>. This ensures that the session is closed properly and any resources associated with the session are released back to the system.</p> <p>Using this function, you can get a database session by calling <code>get_db()</code>, which returns a generator object. You can then iterate over the generator to get a database session, like so: <pre><code>with get_db() as db:\n# interact with the database session here\n</code></pre></p>"},{"location":"sql/28_python_fastapi/#addind-endpoints-to-our-app","title":"Addind Endpoints to our app","text":"<p>In FastAPI, an endpoint or route is a combination of a specific HTTP method (such as GET, POST, PUT, DELETE, etc.) and a URL path that a client can use to communicate with the server and perform some specific action or operation.</p> <p>Endpoints are defined in your FastAPI application using decorated functions that are called view functions. These view functions handle the request/response cycle for a specific endpoint, which includes handling any incoming requests with specific parameters and returning the appropriate response data.</p> <p>In other words, endpoints are the primary building blocks of a FastAPI application, and they determine how clients can interact with your API. They enable you to define a clear and well-structured API that can be easily understood and used by other developers, while also providing a standardized way for clients to communicate with your application.</p>"},{"location":"sql/28_python_fastapi/#endpoint-employees","title":"Endpoint <code>/employees</code>","text":"<p>This route is used to retrieve a list of employees from the database. It returns a JSON object containing the employee's first name, last name, gender, and hire date. It also accepts query parameters for filtering the results by gender and hire date.</p>"},{"location":"sql/28_python_fastapi/#endpoint-employeesemp_no","title":"Endpoint <code>/employees/{emp_no}</code>","text":"<p>This route is used to retrieve information about a specific employee by their employee number. It returns a JSON object containing the employee's <code>first name</code>, <code>last name</code>, <code>gender</code>, and <code>hire date</code>.</p> <p>Let's code this in python : </p> <pre><code># define a route to get the employee data by ID\n@app.get(\"/employees/{emp_no}\")\nasync def get_employee(emp_no: int, db: Session = Depends(get_db)):\nemployee = db.query(Employees).filter(Employees.emp_no == emp_no).first()\nif not employee:\nraise HTTPException(status_code=404, detail=\"Employee not found\")\nreturn employee\n</code></pre>"},{"location":"sql/28_python_fastapi/#endpoint-departments","title":"Endpoint <code>/departments</code>","text":"<p>This route is used to retrieve a list of departments from the database. It returns a JSON object containing the department's name and number.</p>"},{"location":"sql/28_python_fastapi/#endpoint-departmentsdept_no","title":"Endpoint  <code>/departments/{dept_no}</code>","text":"<p>This route is used to retrieve information about a specific department by its department number. It returns a JSON object containing the department's name and number.</p> <p>Let's implement this :  <pre><code># define a route to get the department data by ID\n@app.get(\"/departments/{dept_no}\")\nasync def get_department(dept_no: str, db: Session = Depends(get_db)):\ndepartment = db.query(Departments).filter(Departments.dept_no == dept_no).first()\nif not department:\nraise HTTPException(status_code=404, detail=\"Department not found\")\nreturn department\n</code></pre></p>"},{"location":"sql/28_python_fastapi/#endpoint-employeesemp_nosalaries","title":"Endpoint <code>/employees/{emp_no}/salaries</code>","text":"<p>This route is used to retrieve a list of salaries for a specific employee by their employee number. It returns a JSON object containing the salary amount, start and end dates of the salary period.</p> <pre><code># define a route to get the salary history of an employee by ID\n@app.get(\"/employees/{emp_no}/salaries\")\nasync def get_employee_salaries(emp_no: int, db: Session = Depends(get_db)):\nsalaries = db.query(Salaries).filter(Salaries.emp_no == emp_no).all()\nif not salaries:\nraise HTTPException(status_code=404, detail=\"No salary history found for employee\")\nreturn salaries\n</code></pre>"},{"location":"sql/28_python_fastapi/#writing-our-api","title":"Writing our API","text":"<p>Let's wrap up and add a final endpoint <code>/departments/{dept_no}/employees</code> : </p> main.py<pre><code>from fastapi import FastAPI, HTTPException\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.ext.automap import automap_base\n# create the FastAPI instance\napp = FastAPI()\n# create the database engine\nengine = create_engine(\"mysql://root:root@localhost:3306/employees\")\n# reflect the database schema to an ORM base\nBase = automap_base()\nBase.prepare(engine, reflect=True)\n# map the tables to ORM classes\nEmployees = Base.classes.employees\nDepartments = Base.classes.departments\nDept_Emp = Base.classes.dept_emp\nSalaries = Base.classes.salaries\n# create a function to get a database session\ndef get_db():\ntry:\ndb = Session(bind=engine)\nyield db\nfinally:\ndb.close()\n# define a route to get the employee data by ID\n@app.get(\"/employees/{emp_no}\")\nasync def get_employee(emp_no: int, db: Session = Depends(get_db)):\nemployee = db.query(Employees).filter(Employees.emp_no == emp_no).first()\nif not employee:\nraise HTTPException(status_code=404, detail=\"Employee not found\")\nreturn employee\n# define a route to get the department data by ID\n@app.get(\"/departments/{dept_no}\")\nasync def get_department(dept_no: str, db: Session = Depends(get_db)):\ndepartment = db.query(Departments).filter(Departments.dept_no == dept_no).first()\nif not department:\nraise HTTPException(status_code=404, detail=\"Department not found\")\nreturn department\n# define a route to get the list of employees in a department by ID\n@app.get(\"/departments/{dept_no}/employees\")\nasync def get_department_employees(dept_no: str, db: Session = Depends(get_db)):\nemployees = db.query(Employees).\\\n        join(Dept_Emp, Employees.emp_no == Dept_Emp.emp_no).\\\n        filter(Dept_Emp.dept_no == dept_no).all()\nif not employees:\nraise HTTPException(status_code=404, detail=\"No employees found in department\")\nreturn employees\n# define a route to get the salary history of an employee by ID\n@app.get(\"/employees/{emp_no}/salaries\")\nasync def get_employee_salaries(emp_no: int, db: Session = Depends(get_db)):\nsalaries = db.query(Salaries).filter(Salaries.emp_no == emp_no).all()\nif not salaries:\nraise HTTPException(status_code=404, detail=\"No salary history found for employee\")\nreturn salaries\n</code></pre> <p>To run this script, you can save it as a Python file (e.g. main.py) and then run the following command in your terminal:</p> <pre><code>uvicorn main:app --reload\n</code></pre> <p>This will start a local web server at http://localhost:8000/docs where you can access the different routes defined in the script \ud83e\udd13</p> <p>Go on the first endpoint <code>employees/{emp_no}</code> and click on <code>try it out</code> and take an example employee ID (let's say 10001) you should see this in your browser : </p> <p></p>"},{"location":"sql/29_python_docker_sql/","title":"SQLAlchemy and docker","text":"<p>In this section we will be working with docker.  </p> <p>Do we actually need docker to our journey to SQLAlchemy ? No. The only reason we choose to use Docker, is because, it is fast to setup, secure and lightweight. </p> <p>Docker provides platform which helps us deliver software packages in containers. The software package we need from docker is a database, postgres to be precise.</p> <p>Installing docker is simple, see the installation section if you don't have it installed. For the next part, we will assume you've already installed docker. </p>"},{"location":"sql/29_python_docker_sql/#add-an-existing-sql-database-into-a-container","title":"Add an existing SQL database into a container","text":"<p>In this section we will be looking at an existing database and put it into a docker container in order to query this database with a python script. </p> <p>Here's an example database let's call this script <code>init.sql</code>: </p> init.sql<pre><code>CREATE DATABASE testdb;\nUSE testdb;\nCREATE TABLE users (\nid INT NOT NULL AUTO_INCREMENT,\nname VARCHAR(50) NOT NULL,\nemail VARCHAR(50) NOT NULL,\nPRIMARY KEY (id)\n);\nINSERT INTO users (name, email) VALUES\n('John Doe', 'johndoe@example.com'),\n('Jane Doe', 'janedoe@example.com'),\n('Bob Smith', 'bobsmith@example.com');\nGRANT ALL PRIVILEGES ON testdb.* TO 'user'@'%' IDENTIFIED BY 'user-password' WITH GRANT OPTION;\nFLUSH PRIVILEGES;\n</code></pre> <p>This SQL script is used to create a new database called <code>testdb</code>, create a table called <code>users</code> with three columns <code>id</code>, <code>name</code>, and <code>email</code>, insert three records into the users table, and grant privileges to a user to access the testdb database.</p>"},{"location":"sql/29_python_docker_sql/#what-is-grant-privileges","title":"What is grant privileges","text":"<p>The <code>GRANT ALL PRIVILEGES</code> command is used in MySQL to grant a user all possible privileges on a database or a specific table within a database. This command allows the user to perform any action on the specified database or table, including creating, modifying, and deleting data.</p> <p>Here's a breakdown of the syntax of the <code>GRANT ALL PRIVILEGES</code> command: <pre><code>GRANT ALL PRIVILEGES ON database_name.* TO 'username'@'localhost' IDENTIFIED BY 'password';\nFLUSH PRIVILEGES;\n</code></pre></p> <ul> <li><code>GRANT ALL PRIVILEGES</code> : This command grants all possible privileges to the user.</li> <li><code>ON database_name.*</code> : This specifies the database and any tables within it that the user will have privileges on. The * wildcard character specifies all tables within the database.</li> <li><code>TO 'username'@'localhost'</code> : This specifies the username and the host from which the user can connect to the database.</li> <li><code>IDENTIFIED BY 'password'</code> : This specifies the password for the user.</li> <li><code>FLUSH PRIVILEGES</code> : This line reloads the grant tables in the mysql database to apply the changes made by the GRANT command.</li> </ul> <p>The <code>GRANT ALL PRIVILEGES</code> command is a powerful command that should be used with caution. It is recommended to only grant the necessary privileges to users to minimize the risk of data loss or security breaches.</p> <p>In our case this database is created in order to be connected by a python script and for that we must have a user, is it not recommended to connect the database as root user.</p>"},{"location":"sql/29_python_docker_sql/#write-a-dockerfile-with-initsql-file","title":"Write a Dockerfile with <code>init.sql</code> file","text":"<p>Let's write a <code>Dockerfile</code> for our sql container : </p> <pre><code>FROM mysql:5.6\n# set root password\nENV MYSQL_ROOT_PASSWORD=my-secret-pw\n\n# create database and table\nCOPY init.sql /docker-entrypoint-initdb.d/\n\n# add a new user\nENV MYSQL_USER=user\nENV MYSQL_PASSWORD=user-password\n\nEXPOSE 3306\n</code></pre> <p>As you know in a <code>Dockerfile</code>, the <code>COPY</code> command is used to copy files or directories from the host machine into the Docker container.</p> <p>In the context of our <code>Dockerfile</code>, the line <pre><code>COPY init.sql /docker-entrypoint-initdb.d/ </code></pre> copies the <code>init.sql</code> file from the host machine into the <code>/docker-entrypoint-initdb.d/</code> directory within the Docker container.</p> <p>The <code>/docker-entrypoint-initdb.d/</code> directory is a default directory that is used by the mysql Docker image to automatically execute any SQL scripts that are located in this directory when the container is started up.</p> <p>By copying the <code>init.sql</code> file into the <code>/docker-entrypoint-initdb.d/</code> directory within the Docker container, you are instructing the mysql image to automatically execute this script when the container starts up. This allows you to automatically create our database, tables, and insert data into the database without having to manually execute SQL commands every time the container is started up.</p>"},{"location":"sql/29_python_docker_sql/#run-our-mysql-container","title":"Run our MySQL container","text":"<p>To build our custom MySQL image, you can run the following command in the directory containing the Dockerfile and <code>init.sql</code> script:</p>"},{"location":"sql/29_python_docker_sql/#build-the-image","title":"Build the image","text":"<p><pre><code>docker build -t my-mysql-image .\n</code></pre> This command will build the Docker image using the Dockerfile in the current directory and tag it as <code>my-mysql-image:latest</code>.</p>"},{"location":"sql/29_python_docker_sql/#start-the-container","title":"Start the container","text":"<p>Once the image is built, you can start a new container using the following command: <pre><code>docker run --name mysql-container -d -p 3306:3306 my-mysql-image\n</code></pre> This command will start a new container (named <code>mysql-container</code>) using the custom MySQL image, now we can connect to our container in order to verify if all the options are passed. </p>"},{"location":"sql/29_python_docker_sql/#connect-to-our-container","title":"Connect to our container","text":"<p>Go to your terminal and run this command in order to enter into the container :  <pre><code>docker exec -it mysql-container /bin/bash\n</code></pre> or the equivalent comnmand :  <pre><code>docker exec -it &lt;your-container-id&gt; /bin/bash\n</code></pre> Now that you are in the container we can access the MySQL CLI with the following command :  <pre><code>mysql -uuser -puser-password\n</code></pre> You should see the following prompt  <pre><code>mysql&gt;\n</code></pre> It means that you're currently in the MySQL Shell of the container. You can now view our <code>testdb</code> and <code>users</code> table with the command :  <pre><code>mysql&gt; show databases; </code></pre> you should see this output :  <pre><code>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| testdb             |\n+--------------------+\n2 rows in set (0.00 sec)\n</code></pre> It means our <code>user</code> is able to see our database, you can also do a test query in order to verify the integrity of our database. In this section we have seen how to build a custom MySQL container with a database in it and how to access this database with the docker CLI \ud83d\ude80</p>"},{"location":"sql/29_python_docker_sql/#query-a-docker-mysql-container-with-a-python-script","title":"Query a docker MySQL container with a python script","text":"<p>Now, let's write a python script <code>connect_db.py</code> to connect our database \ud83e\udd73</p> connect_db.py<pre><code>from sqlalchemy import create_engine, MetaData, Table\n# create engine to connect to MySQL\nengine = create_engine('mysql://user:user-password@0.0.0.0:3306/testdb')\n# create metadata object\nmetadata = MetaData()\n# reflect the users table\nusers_table = Table('users', metadata, autoload=True, autoload_with=engine)\n# select all rows from the users table\nselect_query = users_table.select()\n# execute the query\nwith engine.connect() as conn:\nresult = conn.execute(select_query)\nfor row in result:\nprint(row)\n</code></pre> <p>Let's break down the different parts of the script:</p> <ul> <li><code>create_engine('mysql://root:my-secret-pw@0.0.0.0:3306/testdb')</code>: This creates a SQLAlchemy engine that connects to the MySQL database running in the Docker container. The username is \"root\", the password is \"my-secret-pw\", the host is \"localhost\", the port is \"3306\", and the database name is \"testdb\".</li> <li><code>metadata = MetaData()</code> : This creates a metadata object that will be used to reflect the database schema.</li> <li><code>users_table = Table('users', metadata, autoload=True, autoload_with=engine)</code> : This reflects the \"users\" table from the database using the metadata object.</li> <li><code>select_query = users_table.select()</code> : This creates a query that selects all rows from the \"users\" table.</li> <li><code>with engine.connect() as conn</code> : result = conn.execute(select_query): This creates a connection to the database using the engine, executes the select query, and stores the result in a variable.</li> <li><code>for row in result: print(row)</code> : This loops through the result set and prints each row.</li> </ul> <p>This script assumes that you have the necessary dependencies installed, including SQLAlchemy and the MySQL driver for Python. You can install these dependencies using <code>pip</code>: <pre><code>pip install sqlalchemy pymysql\n</code></pre> Note that the driver used to connect to the MySQL database is \"pymysql\", which is a Python MySQL client library that works with SQLAlchemy.</p> <p>If you execute this script, you should see this output :  <pre><code>(1, 'John Doe', 'johndoe@example.com')\n(2, 'Jane Doe', 'janedoe@example.com')\n(3, 'Bob Smith', 'bobsmith@example.com')\n</code></pre></p>"},{"location":"sql/29_python_docker_sql/#next-steps","title":"Next steps","text":"<p>In this section we covered a pretty simple database and python script so for the next steps if you want to upgrade this project you can consider : </p> <ul> <li>Add FastAPI CRUD endpoints to interact with the database </li> <li>Add a better database and <code>init.sql</code> script </li> <li>Wrap-up the project with a <code>docker-compose.yml</code> file </li> <li>Code a dashboard route in FastAPI in order to visualize some data of your database </li> <li>Be creative \ud83d\ude03</li> </ul>"},{"location":"sql/29_python_docker_sql/#wrap-up","title":"Wrap-up","text":"<p>Let's summarize whant we have seen in this section :</p> <ul> <li>Docker provides a consistent and portable environment for running applications, including databases like MySQL.</li> <li>We can use Docker to run a MySQL database in a container by pulling the mysql image and specifying the appropriate environment variables and port mappings.</li> <li>We can use the mysql-connector-python library in Python to connect to a MySQL database and perform SQL queries.</li> <li>We can create a SQL script to create tables and insert data into the MySQL database, and include this script in the Docker image to automatically execute it when the container starts up.</li> <li>We have learned how to write a Dockerfile to define the configuration of a Docker container, and how to use it to build a Docker image.</li> <li>Overall, connecting Docker MySQL and Python provides a more efficient and reliable way to manage and run databases and applications, and reduces the complexity and time involved in setting up and maintaining software installations.</li> </ul>"},{"location":"sql/30_python_projects/","title":"Python wrap-up project","text":""},{"location":"sql/30_python_projects/#project-employee-management-system","title":"Project: Employee Management System","text":""},{"location":"sql/30_python_projects/#description","title":"Description","text":"<p>You are tasked with building an Employee Management System for a company using FastAPI and SQLAlchemy. The system should allow the HR department to manage employee records, including personal information, salary, and department information.</p>"},{"location":"sql/30_python_projects/#requirements","title":"Requirements","text":"<ul> <li>Create three database tables: employees, departments, and salaries. The employees table should have columns for emp_no, first_name, last_name, gender, hire_date, and dept_no. The departments table should have columns for dept_no and dept_name. The salaries table should have columns for emp_no, salary, and from_date and to_date.</li> <li>Implement an endpoint to add new employees to the database. The endpoint should accept a JSON payload containing the employee's personal information and department. The endpoint should validate the data and insert it into the database. If the department does not exist in the departments table, it should be created.</li> <li>Implement an endpoint to update an employee's salary. The endpoint should accept a JSON payload containing the employee's emp_no and new salary. The endpoint should validate the data and update the salaries table accordingly.</li> <li>Implement an endpoint to retrieve a list of employees with their current salary and department. The endpoint should accept an optional query parameter to filter by department. If the parameter is not provided, the endpoint should return all employees.</li> <li>Implement an endpoint to retrieve a list of departments and their total salary budget. The endpoint should calculate the total salary budget for each department based on the current salaries of its employees.</li> <li>Implement an endpoint to delete an employee from the database. The endpoint should accept an emp_no parameter and delete the corresponding record from the employees, salaries, and dept_emp tables.</li> <li>Implement appropriate error handling for each endpoint.</li> <li>Write unit tests for each endpoint.</li> <li>Use FastAPI's dependency injection system to inject the database session into each endpoint.</li> <li>Use SQLAlchemy's built-in ORM features to define the database schema and manage database transactions.</li> <li>The system should incorporate triggers to notify HR personnel when an employee is due for a performance review, salary increase, or other HR-related tasks.</li> <li> <p>The system should be able to join multiple tables to provide HR personnel with a holistic view of employee records and performance. Bonus points :</p> </li> <li> <p>Use Docker to containerize the application and its dependencies.</p> </li> <li>Deploy the application to a cloud platform such as Heroku or AWS Elastic Beanstalk.</li> </ul>"},{"location":"sql/30_python_projects/#example-workflow","title":"Example Workflow:","text":"<ul> <li>HR personnel log in to the system and are presented with a dashboard displaying employee records and performance metrics.</li> <li>HR personnel search for a specific employee record and update their personal information, such as address, phone number, or emergency contact.</li> <li>The system sends a notification to HR personnel when an employee is due for a performance review, prompting them to schedule a meeting with the employee.</li> <li>HR personnel use the system's data analysis tools to identify top-performing employees and provide them with bonuses or promotions.</li> <li>The system generates HR reports that provide insights into employee performance, attendance, and payroll data.</li> </ul> <p>Overall, this project would require a strong understanding of SQL, including views, triggers, and joins, as well as web development with FastAPI and SQLAlchemy. It would also require careful attention to detail and robust error handling to ensure the system is secure, reliable, and scalable (for the bonus point).</p>"},{"location":"sql/30_python_projects/#project-online-bookstore-management-system","title":"Project: Online Bookstore Management System","text":""},{"location":"sql/30_python_projects/#description_1","title":"Description","text":"<p>Build an online bookstore management system using FastAPI and SQLAlchemy. The system should allow users to browse, search, and purchase books online. It should also allow administrators to manage the books, customers, orders, and inventory.</p>"},{"location":"sql/30_python_projects/#requirements_1","title":"Requirements:","text":"<ul> <li>Create a database schema with at least four tables: books, customers, orders, and inventory.</li> <li>Use SQLAlchemy to map the database tables to Python classes.</li> <li>Implement RESTful API endpoints using FastAPI to allow users to browse and search books, place orders, and manage their accounts.</li> <li>Implement a view to show the top 10 best-selling books based on sales data.</li> <li>Implement triggers to update the inventory when orders are placed or cancelled.</li> <li>Implement a view to show the current inventory levels and the books that are running low on stock.</li> <li>Implement joins to retrieve customer order history and book sales data.</li> </ul> <p>Bonus: </p> <ul> <li>Implement authentication and authorization using JWT tokens.</li> <li>Implement an admin panel with secure login for administrators to manage the books, customers, orders, and inventory.</li> <li>Implement email notifications to customers when they place orders or their orders are shipped.</li> </ul> <p>This project will require skills in database design, SQL, Python programming, web development, and system architecture. It will also provide you an opportunity to gain experience with common web development frameworks and tools such as authentication, authorization and email notifications.</p>"},{"location":"sql/30_python_projects/#project-e-commerce-platform","title":"Project: E-commerce platform","text":""},{"location":"sql/30_python_projects/#description_2","title":"Description","text":"<p>Create a web application for an e-commerce platform using SQLAlchemy and FastAPI. The application should have the following features:</p> <ul> <li>User registration and authentication: Users should be able to register for an account and authenticate themselves to access their account information, order history, and other features.</li> <li>Product management: Users with administrative access should be able to add, modify, and delete product listings.</li> <li>Shopping cart: Users should be able to add products to a shopping cart and proceed to checkout to complete their purchase.</li> <li>Order history: Users should be able to view their order history and check the status of their current orders.</li> <li>Search functionality: Users should be able to search for products by name, description, category, and other criteria.</li> </ul>"},{"location":"sql/30_python_projects/#requirements_2","title":"Requirements:","text":"<ul> <li>Use SQLAlchemy to create and manage the database schema.</li> <li>Use FastAPI to create RESTful endpoints for user authentication, product management, shopping cart, order history, and search functionality.</li> <li>Implement CRUD operations for product management.</li> <li>Implement a shopping cart using SQLAlchemy ORM.</li> <li>Use SQLAlchemy to create triggers for order history and updating product inventory.</li> <li>Use SQLAlchemy to create views to provide reports such as total sales and most popular products.</li> <li>Use SQLAlchemy to create joins to combine information from multiple tables.</li> <li>Use Python and SQLAlchemy to seed the database with sample data from generatedata.com </li> <li>Deploy the application to a cloud-based server such as AWS or Heroku.</li> </ul> <p>This project will provide students with experience in building a complex web application using SQLAlchemy and FastAPI, as well as deploying and managing the application on a cloud-based server. They will also gain experience in implementing advanced database features such as triggers, views, and joins.</p>"}]}